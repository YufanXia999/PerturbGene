{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df256e08-6663-45b1-b5b4-73ecc841bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/kevin/Documents\")  # parent of `perturbgene` directory\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import tqdm  # https://discuss.pytorch.org/t/error-while-multiprocessing-in-dataloader/46845/9\n",
    "from braceexpand import braceexpand\n",
    "\n",
    "from perturbgene.data_utils import GeneTokenizer, IterableAnnDataset, EvalJsonDataset, read_h5ad_file\n",
    "from perturbgene.data_utils.data_collators import collate_fn_wrapper\n",
    "from perturbgene.data_utils.tokenization import _prepend_bin, phenotype_to_token\n",
    "from perturbgene.eval_utils import mlm_metrics_wrapper, cls_metrics_wrapper, preprocess_logits_argmax\n",
    "from perturbgene.model import GeneBertForPhenotypicMLM, GeneBertForClassification\n",
    "from perturbgene.inference_utils import get_inference_config, prepare_cell, test_cell, mlm_for_phenotype_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f11ab498-413c-4c0e-84f2-85ee7ffcb80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phenotype_category = \"tissue\"  # category to perform classifcation on\n",
    "phenotype_category = \"cell_type\"\n",
    "\n",
    "model_type = \"mlm\"\n",
    "model_checkpt_path = \"/home/kevin/Documents/perturbgene/outputs/base_v0_1024_mlm_bins1/checkpoint-32000\"\n",
    "# model_checkpt_path = \"/home/kevin/Documents/transformeromics/test_mlm_inference_130_cls_bins1/checkpoint-3200\"\n",
    "\n",
    "# model_type = \"cls\"\n",
    "# model_checkpt_path = \"/home/kevin/Documents/perturbgene/test_cls_inference_130_cls_bins1/checkpoint-3200\"\n",
    "assert model_type in (\"mlm\", \"cls\")\n",
    "\n",
    "# device = \"cpu\"\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# Load tokenizer first, so that we can get the config\n",
    "expected_tokenizer_path = os.path.join(\n",
    "    os.path.dirname(model_checkpt_path),\n",
    "    \"tokenizer.pkl\",\n",
    ")\n",
    "\n",
    "if os.path.isfile(expected_tokenizer_path):\n",
    "    with open(expected_tokenizer_path, \"rb\") as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "else:\n",
    "    print(\"Saved tokenizer not found, creating tokenizer with common parameters\")\n",
    "    tokenizer = GeneTokenizer(get_inference_config(  # change these parameters\n",
    "        bin_edges=[0.1], \n",
    "        pretrained_model_path=\"/dev/null\",  # needs to be a path that exists\n",
    "        max_length=130,        \n",
    "        num_top_genes=128\n",
    "    ))\n",
    "\n",
    "tokenizer.config.vocab_path = os.path.join(\"/home/kevin/Documents/\", tokenizer.config.vocab_path)  # rel path -> abs path\n",
    "config = tokenizer.config\n",
    "\n",
    "if model_type == \"mlm\":\n",
    "    tokenizer.config.binary_label = None\n",
    "    tokenizer.config.phenotype_category = phenotype_category\n",
    "    config = tokenizer.config\n",
    "    \n",
    "    model_class = GeneBertForPhenotypicMLM\n",
    "elif model_type == \"cls\":\n",
    "    assert tokenizer.config.phenotype_category == phenotype_category, tokenizer.config.phenotype_category\n",
    "    \n",
    "    model_class = GeneBertForClassification\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "data_collator = collate_fn_wrapper(tokenizer)\n",
    "compute_metrics = cls_metrics_wrapper(tokenizer)  # always using cls_metrics\n",
    "\n",
    "# Largely copied from IterableAnnDataset\n",
    "phenotype_category_labels = tokenizer.phenotypic_tokens_map[config.phenotype_category]\n",
    "\n",
    "if config.binary_label is None:\n",
    "    label2id = {label: i for i, label in enumerate(phenotype_category_labels)}\n",
    "else:\n",
    "    label2id = {label: int(label == config.binary_label)\n",
    "                     for label in phenotype_category_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6156454a-8f53-49ee-86ac-20f83dec4b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/kevin/Documents/perturbgene/outputs/base_v0_1024_mlm_bins1/checkpoint-32000 were not used when initializing GeneBertForPhenotypicMLM: ['mlm_loss_fct.weight']\n",
      "- This IS expected if you are initializing GeneBertForPhenotypicMLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GeneBertForPhenotypicMLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = model_class.from_pretrained(model_checkpt_path)\n",
    "model.eval()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa42a77-01f6-424a-a3e1-84d2fe24e084",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12cff230-993d-465e-a2ce-adcedcc8eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = read_h5ad_file(\"/home/shared_folder/TabulaSapiens/ranked/Tabula_Sapiens_ranked_47.h5ad\", config.num_top_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf2db16-0276-4b92-9d3d-57398f329a7b",
   "metadata": {},
   "source": [
    "## MLM (for phenotype classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eae1e7-06f2-4755-9b82-a1182ef392ae",
   "metadata": {},
   "source": [
    "### One cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67f976d-f6ef-4317-b461-1abd5367625b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: [CD4-positive,_alpha-beta_memory_T_cell]\n",
      "Label: [CD4-positive,_alpha-beta_memory_T_cell]\n"
     ]
    }
   ],
   "source": [
    "assert model_type == \"mlm\"\n",
    "cell = validation_data[0]\n",
    "\n",
    "top_id = mlm_for_phenotype_cls(cell, phenotype_category, model, tokenizer, data_collator)\n",
    "print(f\"Pred: {tokenizer.flattened_tokens[top_id]}\\n\"\n",
    "      f\"Label: {phenotype_to_token(cell.obs[phenotype_category].item())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad2eed2-ae0d-48f6-b9ab-87208637c58d",
   "metadata": {},
   "source": [
    "### Entire h5ad file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77408247-557f-4113-81e6-ecfd31afdc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 10000/10000 [05:24<00:00, 30.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics={'accuracy': 0.938, 'precision': 0.8227611374546668, 'recall': 0.8150250505737551, 'f1': 0.8188748233019938}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "assert model_type == \"mlm\"\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for cell in tqdm(validation_data):\n",
    "    top_id = mlm_for_phenotype_cls(cell, phenotype_category, model, tokenizer, data_collator)\n",
    "    all_preds.append(phenotype_category_labels.index(tokenizer.flattened_tokens[top_id]))\n",
    "    all_labels.append(phenotype_category_labels.index(phenotype_to_token(cell.obs[phenotype_category].item())))\n",
    "\n",
    "metrics = compute_metrics(transformers.EvalPrediction(\n",
    "    predictions=np.array(all_preds), \n",
    "    label_ids=np.array(all_labels).reshape(-1, 1),\n",
    "))\n",
    "\n",
    "print(f\"{metrics=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef929a-27d8-48e3-b3fc-c9b7074f9f7f",
   "metadata": {},
   "source": [
    "## CLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacc9c8d-d2ed-47cd-b75b-34db73803673",
   "metadata": {},
   "source": [
    "### One cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d680f3e2-2f3e-4f1b-8139-c0490f23f3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phenotype_category='tissue'\n",
      "Pred: [kidney_epithelial_cell]\n",
      "Label: [blood]\n"
     ]
    }
   ],
   "source": [
    "assert model_type == \"cls\"\n",
    "cell = validation_data[0]\n",
    "\n",
    "phenotype_category = config.phenotype_category\n",
    "print(f\"{phenotype_category=}\")\n",
    "\n",
    "prepared_cell = prepare_cell(cell, model_type, tokenizer, label2id)\n",
    "output = test_cell(prepared_cell, model, data_collator)\n",
    "print(f\"Pred: {tokenizer.flattened_tokens[output.logits.argmax(dim=-1).item()]}\\n\"\n",
    "      f\"Label: {phenotype_to_token(cell.obs[phenotype_category].item())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69287dc-ca51-4510-bef7-13b2bfa9b62e",
   "metadata": {},
   "source": [
    "### Entire h5ad file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ec9833c-be30-4bd9-83b5-8d08e4bbca28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 157/157 [00:41<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics={'accuracy': 0.5765, 'precision': 0.5889780711350704, 'recall': 0.5946053679796419, 'f1': 0.5917783421862598}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "assert model_type == \"cls\"\n",
    "eval_batch_size = 64\n",
    "eval_dataset = IterableAnnDataset([\"/home/shared_folder/TabulaSapiens/ranked/Tabula_Sapiens_ranked_47.h5ad\"], config)\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=eval_batch_size,\n",
    "    collate_fn=data_collator,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for batch in tqdm(eval_dataloader):\n",
    "    with torch.no_grad():\n",
    "        preds = model(**{key: val.to(device) for key, val in batch.items()})\n",
    "        all_preds.extend(preds.logits.argmax(dim=-1))\n",
    "        all_labels.extend(batch[\"labels\"])\n",
    "\n",
    "metrics = compute_metrics(transformers.EvalPrediction(\n",
    "    predictions=torch.stack(all_preds).cpu().numpy(), \n",
    "    label_ids=torch.stack(all_labels).cpu().numpy()\n",
    "))\n",
    "print(f\"{metrics=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc44e9e-f726-4662-aa48-1d9a1ed11dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
