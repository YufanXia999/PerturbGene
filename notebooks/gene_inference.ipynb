{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yufan/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"/home/yufan\")  # parent of `perturbgene` directory\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import tqdm  # https://discuss.pytorch.org/t/error-while-multiprocessing-in-dataloader/46845/9\n",
    "from braceexpand import braceexpand\n",
    "from perturbgene.data_utils import GeneTokenizer, IterableAnnDataset, EvalJsonDataset, read_h5ad_file\n",
    "from perturbgene.data_utils.data_collators import collate_fn_wrapper\n",
    "from perturbgene.data_utils.tokenization import _prepend_bin, phenotype_to_token\n",
    "from perturbgene.eval_utils import mlm_metrics_wrapper, cls_metrics_wrapper, preprocess_logits_argmax\n",
    "from perturbgene.model import GeneBertForPhenotypicMLM, GeneBertForClassification, GeneBertModel\n",
    "from perturbgene.inference_utils import get_inference_config, prepare_cell, test_cell, mlm_for_phenotype_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of reduced embeddings: (3007, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Choose one of the methods for dimensionality reduction\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(mean_embeddings)\n",
    "\n",
    "# or t-SNE\n",
    "# tsne = TSNE(n_components=2, random_state=42)\n",
    "# reduced_embeddings = tsne.fit_transform(mean_embeddings)\n",
    "\n",
    "print(\"Shape of reduced embeddings:\", reduced_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = validation_data.obs.compartment[:3007].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tissue_in_publication</th>\n",
       "      <th>assay_ontology_term_id</th>\n",
       "      <th>donor_id</th>\n",
       "      <th>anatomical_information</th>\n",
       "      <th>n_counts_UMIs</th>\n",
       "      <th>n_genes</th>\n",
       "      <th>cell_ontology_class</th>\n",
       "      <th>free_annotation</th>\n",
       "      <th>manually_annotated</th>\n",
       "      <th>compartment</th>\n",
       "      <th>...</th>\n",
       "      <th>tissue_type</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>assay</th>\n",
       "      <th>disease</th>\n",
       "      <th>organism</th>\n",
       "      <th>sex</th>\n",
       "      <th>tissue</th>\n",
       "      <th>self_reported_ethnicity</th>\n",
       "      <th>development_stage</th>\n",
       "      <th>observation_joinid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1</th>\n",
       "      <td>Blood</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>TSP8</td>\n",
       "      <td>nan</td>\n",
       "      <td>7255.0</td>\n",
       "      <td>1748</td>\n",
       "      <td>cd4-positive, alpha-beta memory t cell</td>\n",
       "      <td>cd4-positive, alpha-beta memory t cell</td>\n",
       "      <td>True</td>\n",
       "      <td>immune</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>CD4-positive, alpha-beta memory T cell</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>blood</td>\n",
       "      <td>Hispanic or Latin American</td>\n",
       "      <td>56-year-old human stage</td>\n",
       "      <td>?7jT&lt;Bex3K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1</th>\n",
       "      <td>Trachea</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>TSP2</td>\n",
       "      <td>nan</td>\n",
       "      <td>19285.0</td>\n",
       "      <td>4469</td>\n",
       "      <td>basal cell</td>\n",
       "      <td>basal cell</td>\n",
       "      <td>True</td>\n",
       "      <td>epithelial</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>basal cell</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>trachea</td>\n",
       "      <td>African American or Afro-Caribbean</td>\n",
       "      <td>61-year-old human stage</td>\n",
       "      <td>o{}|6`4{Aq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1</th>\n",
       "      <td>Lymph_Node</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>TSP7</td>\n",
       "      <td>inguinal</td>\n",
       "      <td>7485.0</td>\n",
       "      <td>1938</td>\n",
       "      <td>b cell</td>\n",
       "      <td>B cell</td>\n",
       "      <td>True</td>\n",
       "      <td>immune</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>B cell</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>inguinal lymph node</td>\n",
       "      <td>European</td>\n",
       "      <td>69-year-old human stage</td>\n",
       "      <td>=dwFpiW&lt;g!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1</th>\n",
       "      <td>Blood</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>TSP7</td>\n",
       "      <td>nan</td>\n",
       "      <td>17101.0</td>\n",
       "      <td>4003</td>\n",
       "      <td>classical monocyte</td>\n",
       "      <td>classical monocyte</td>\n",
       "      <td>True</td>\n",
       "      <td>immune</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>classical monocyte</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>blood</td>\n",
       "      <td>European</td>\n",
       "      <td>69-year-old human stage</td>\n",
       "      <td>a?yXpXxB_c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime</th>\n",
       "      <td>Lymph_Node</td>\n",
       "      <td>EFO:0030004</td>\n",
       "      <td>TSP14</td>\n",
       "      <td>nan</td>\n",
       "      <td>3454.0</td>\n",
       "      <td>1559</td>\n",
       "      <td>cd8-positive alpha-beta t cell</td>\n",
       "      <td>CD8-positive alpha-beta thymocyte</td>\n",
       "      <td>True</td>\n",
       "      <td>immune</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>effector CD8-positive, alpha-beta T cell</td>\n",
       "      <td>10x 5' transcription profiling</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>lymph node</td>\n",
       "      <td>European</td>\n",
       "      <td>59-year-old human stage</td>\n",
       "      <td>w%fPX#!Q}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X_1_1</th>\n",
       "      <td>Lung</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>TSP2</td>\n",
       "      <td>proxmedialdistal</td>\n",
       "      <td>2857.0</td>\n",
       "      <td>1262</td>\n",
       "      <td>cd4-positive, alpha-beta t cell</td>\n",
       "      <td>cd4-positive, alpha-beta t cell</td>\n",
       "      <td>True</td>\n",
       "      <td>immune</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>CD4-positive, alpha-beta T cell</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>lung</td>\n",
       "      <td>African American or Afro-Caribbean</td>\n",
       "      <td>61-year-old human stage</td>\n",
       "      <td>L-hKm=oC&amp;(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2</th>\n",
       "      <td>Trachea</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>TSP2</td>\n",
       "      <td>nan</td>\n",
       "      <td>11741.0</td>\n",
       "      <td>3036</td>\n",
       "      <td>basal cell</td>\n",
       "      <td>basal cell</td>\n",
       "      <td>True</td>\n",
       "      <td>epithelial</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>basal cell</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>trachea</td>\n",
       "      <td>African American or Afro-Caribbean</td>\n",
       "      <td>61-year-old human stage</td>\n",
       "      <td>3BR&lt;fN&gt;w}?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1</th>\n",
       "      <td>Prostate</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>TSP8</td>\n",
       "      <td>nan</td>\n",
       "      <td>5226.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>epithelial cell</td>\n",
       "      <td>Other Epithelial Cell</td>\n",
       "      <td>True</td>\n",
       "      <td>epithelial</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>epithelial cell</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>prostate gland</td>\n",
       "      <td>Hispanic or Latin American</td>\n",
       "      <td>56-year-old human stage</td>\n",
       "      <td>+fi&gt;*w`D?&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime</th>\n",
       "      <td>Lymph_Node</td>\n",
       "      <td>EFO:0030004</td>\n",
       "      <td>TSP14</td>\n",
       "      <td>nan</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>1408</td>\n",
       "      <td>cd4-positive alpha-beta t cell</td>\n",
       "      <td>CD4-positive alpha-beta thymocyte</td>\n",
       "      <td>True</td>\n",
       "      <td>immune</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>effector CD4-positive, alpha-beta T cell</td>\n",
       "      <td>10x 5' transcription profiling</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>lymph node</td>\n",
       "      <td>European</td>\n",
       "      <td>59-year-old human stage</td>\n",
       "      <td>G+X9JE=&lt;TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual_10X_1_1</th>\n",
       "      <td>Salivary_Gland</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>TSP14</td>\n",
       "      <td>sublingual</td>\n",
       "      <td>17233.0</td>\n",
       "      <td>4438</td>\n",
       "      <td>acinar cell of salivary gland</td>\n",
       "      <td>Mucinous acini</td>\n",
       "      <td>True</td>\n",
       "      <td>epithelial</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue</td>\n",
       "      <td>acinar cell of salivary gland</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>sublingual gland</td>\n",
       "      <td>European</td>\n",
       "      <td>59-year-old human stage</td>\n",
       "      <td>GIF|hvzlF4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tissue_in_publication  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1                             Blood   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1                         Trachea   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1             Lymph_Node   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                             Blood   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime            Lymph_Node   \n",
       "...                                                                  ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...                  Lung   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2                         Trachea   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1                       Prostate   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime            Lymph_Node   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...        Salivary_Gland   \n",
       "\n",
       "                                                   assay_ontology_term_id  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1                        EFO:0009922   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1                      EFO:0009922   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1             EFO:0009922   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                        EFO:0009922   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime            EFO:0030004   \n",
       "...                                                                   ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...            EFO:0009922   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2                      EFO:0009922   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1                     EFO:0009922   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime            EFO:0030004   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...            EFO:0009922   \n",
       "\n",
       "                                                   donor_id  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1                 TSP8   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1               TSP2   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1      TSP7   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                 TSP7   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime    TSP14   \n",
       "...                                                     ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...     TSP2   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2               TSP2   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1              TSP8   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime    TSP14   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...    TSP14   \n",
       "\n",
       "                                                   anatomical_information  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1                                nan   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1                              nan   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1                inguinal   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                                nan   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime                    nan   \n",
       "...                                                                   ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...       proxmedialdistal   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2                              nan   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1                             nan   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime                    nan   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...             sublingual   \n",
       "\n",
       "                                                    n_counts_UMIs  n_genes  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1                     7255.0     1748   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1                  19285.0     4469   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1          7485.0     1938   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                    17101.0     4003   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime         3454.0     1559   \n",
       "...                                                           ...      ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...         2857.0     1262   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2                  11741.0     3036   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1                  5226.0     1620   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime         3595.0     1408   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...        17233.0     4438   \n",
       "\n",
       "                                                                       cell_ontology_class  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1              cd4-positive, alpha-beta memory t cell   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1                                        basal cell   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1                                   b cell   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                                  classical monocyte   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime          cd8-positive alpha-beta t cell   \n",
       "...                                                                                    ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...         cd4-positive, alpha-beta t cell   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2                                        basal cell   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1                                  epithelial cell   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime          cd4-positive alpha-beta t cell   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...           acinar cell of salivary gland   \n",
       "\n",
       "                                                                           free_annotation  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1              cd4-positive, alpha-beta memory t cell   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1                                        basal cell   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1                                   B cell   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                                  classical monocyte   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime       CD8-positive alpha-beta thymocyte   \n",
       "...                                                                                    ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...         cd4-positive, alpha-beta t cell   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2                                        basal cell   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1                            Other Epithelial Cell   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime       CD4-positive alpha-beta thymocyte   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...                          Mucinous acini   \n",
       "\n",
       "                                                    manually_annotated  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1                            True   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1                          True   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1                 True   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                            True   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime                True   \n",
       "...                                                                ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...                True   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2                          True   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1                         True   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime                True   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...                True   \n",
       "\n",
       "                                                   compartment  ...  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1                  immune  ...   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1            epithelial  ...   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1       immune  ...   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                  immune  ...   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime      immune  ...   \n",
       "...                                                        ...  ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...      immune  ...   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2            epithelial  ...   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1           epithelial  ...   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime      immune  ...   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...  epithelial  ...   \n",
       "\n",
       "                                                   tissue_type  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1                  tissue   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1                tissue   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1       tissue   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                  tissue   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime      tissue   \n",
       "...                                                        ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...      tissue   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2                tissue   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1               tissue   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime      tissue   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...      tissue   \n",
       "\n",
       "                                                                                   cell_type  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1                CD4-positive, alpha-beta memory T cell   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1                                          basal cell   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1                                     B cell   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                                    classical monocyte   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime  effector CD8-positive, alpha-beta T cell   \n",
       "...                                                                                      ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...           CD4-positive, alpha-beta T cell   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2                                          basal cell   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1                                    epithelial cell   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime  effector CD4-positive, alpha-beta T cell   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...             acinar cell of salivary gland   \n",
       "\n",
       "                                                                             assay  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1                                   10x 3' v3   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1                                 10x 3' v3   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1                        10x 3' v3   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                                   10x 3' v3   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime  10x 5' transcription profiling   \n",
       "...                                                                            ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...                       10x 3' v3   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2                                 10x 3' v3   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1                                10x 3' v3   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime  10x 5' transcription profiling   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...                       10x 3' v3   \n",
       "\n",
       "                                                   disease      organism  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1              normal  Homo sapiens   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1            normal  Homo sapiens   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1   normal  Homo sapiens   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1              normal  Homo sapiens   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime  normal  Homo sapiens   \n",
       "...                                                    ...           ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...  normal  Homo sapiens   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2            normal  Homo sapiens   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1           normal  Homo sapiens   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime  normal  Homo sapiens   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...  normal  Homo sapiens   \n",
       "\n",
       "                                                       sex  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1                male   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1            female   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1   female   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1              female   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime    male   \n",
       "...                                                    ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...  female   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2            female   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1             male   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime    male   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...    male   \n",
       "\n",
       "                                                                 tissue  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1                            blood   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1                        trachea   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1   inguinal lymph node   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                            blood   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime           lymph node   \n",
       "...                                                                 ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...                 lung   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2                        trachea   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1                prostate gland   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime           lymph node   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...     sublingual gland   \n",
       "\n",
       "                                                               self_reported_ethnicity  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1                      Hispanic or Latin American   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1            African American or Afro-Caribbean   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1                             European   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                                        European   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime                            European   \n",
       "...                                                                                ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...  African American or Afro-Caribbean   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2            African American or Afro-Caribbean   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1                   Hispanic or Latin American   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime                            European   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...                            European   \n",
       "\n",
       "                                                          development_stage  \\\n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1              56-year-old human stage   \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1            61-year-old human stage   \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1   69-year-old human stage   \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1              69-year-old human stage   \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime  59-year-old human stage   \n",
       "...                                                                     ...   \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...  61-year-old human stage   \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2            61-year-old human stage   \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1           56-year-old human stage   \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime  59-year-old human stage   \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...  59-year-old human stage   \n",
       "\n",
       "                                                   observation_joinid  \n",
       "TCATGAGCATTCAGCA_TSP8_Blood_NA_10X_1_1                     ?7jT<Bex3K  \n",
       "TTACGTTCAAGCACCC_TSP2_Trachea_NA_10X_1_1                   o{}|6`4{Aq  \n",
       "GCCATGGAGCACTGGA_TSP7_LymphNodes_Inguinal_10X_1_1          =dwFpiW<g!  \n",
       "ATGACCACACCCATAA_TSP7_Blood_NA_10X_1_1                     a?yXpXxB_c  \n",
       "GCTCCTAGTTCAGTAC_TSP14_LymphNode_NA_10X_2_1_5Prime         w%fPX#!Q}}  \n",
       "...                                                               ...  \n",
       "TCGGATAGTTATAGAG_TSP2_Lung_proxmedialdistal_10X...         L-hKm=oC&(  \n",
       "ACGGTTACAAGCGATG_TSP2_Trachea_NA_10X_1_2                   3BR<fN>w}?  \n",
       "CGGAACCCATTGAGCT_TSP8_Prostate_NA_10X_1_1                  +fi>*w`D?<  \n",
       "AAGGTTCAGTCAAGGC_TSP14_LymphNode_NA_10X_2_1_5Prime         G+X9JE=<TD  \n",
       "GTTGTAGCACGTACTA_TSP14_SalivaryGland_Sublingual...         GIF|hvzlF4  \n",
       "\n",
       "[100 rows x 29 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data[:100].obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainMLMConfig(subcommand='mlm', bin_edges=[0.1, 1.08888889, 2.07777778, 3.06666667, 4.05555556, 5.04444444, 6.03333333, 7.02222222, 8.01111111, 9.0], bin_edges_path=None, pretrained_model_path='perturbgene/model_configs/distilbert_large.json', model_arch=None, shard_size=10000, eval_data_paths=['perturbgene/ranked/Tabula_Sapiens_ranked_47.h5ad'], max_length=10000, num_top_genes=58604, vocab_path='/home/yufan/perturbgene/data/phenotypic_tokens_map.json', included_phenotypes=['cell_type', 'sex', 'tissue'], use_flash_attn=True, output_dir='output_2gpu_mlm_015gene_050pheno_vastai', per_device_eval_batch_size=32, dataloader_num_workers=4, auto_find_batch_size=True, train_data_paths=['perturbgene/ranked/Tabula_Sapiens_ranked_0.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_1.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_2.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_3.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_4.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_5.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_6.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_7.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_8.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_9.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_10.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_11.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_12.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_13.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_14.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_15.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_16.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_17.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_18.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_19.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_20.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_21.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_22.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_23.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_24.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_25.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_26.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_27.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_28.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_29.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_30.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_31.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_32.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_33.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_34.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_35.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_36.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_37.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_38.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_39.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_40.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_41.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_42.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_43.h5ad'], num_hidden_layers=12, num_attention_heads=16, num_train_epochs=25, per_device_train_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.05, warmup_ratio=0.1, save_steps=5000, eval_steps=5000, gene_mask_prob=0.15, phenotype_mask_prob=0.5)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneBertModel(\n",
       "  (embeddings): PositionlessEmbeddings(\n",
       "    (word_embeddings): Embedding(268, 1024, padding_idx=3)\n",
       "    (token_type_embeddings): Embedding(58610, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'Component 1': reduced_embeddings[:100, 0],\n",
    "    'Component 2': reduced_embeddings[:100, 1],\n",
    "    'Label': labels[:100]\n",
    "})\n",
    "\n",
    "# Plot using seaborn\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='Component 1', y='Component 2', hue='Label', palette='viridis', data=df, s=100)\n",
    "plt.title('2D Projection of Mean Embeddings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpt_path = \"/storage_bizon/bizon_filesystem/output_2gpu_mlm_015gene_050pheno_vastai_10000_mlm_bins10/checkpoint-305000\"\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# Load tokenizer first, so that we can get the config\n",
    "expected_tokenizer_path = os.path.join(\n",
    "    os.path.dirname(model_checkpt_path),\n",
    "    \"tokenizer.pkl\",\n",
    ")\n",
    "\n",
    "if os.path.isfile(expected_tokenizer_path):\n",
    "    with open(expected_tokenizer_path, \"rb\") as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "else:\n",
    "    print(\"Saved tokenizer not found, creating tokenizer with common parameters\")\n",
    "    tokenizer = GeneTokenizer(get_inference_config(  # change these parameters\n",
    "        bin_edges=[0.1], \n",
    "        pretrained_model_path=model_checkpt_path,  # needs to be a path that exists\n",
    "        max_length=130,        \n",
    "        num_top_genes=128\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.config.vocab_path = os.path.join(\"/home/yufan/\", tokenizer.config.vocab_path)  # rel path -> abs path\n",
    "config = tokenizer.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TrainMLMConfig' object has no attribute 'phenotype_category'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m compute_metrics \u001b[38;5;241m=\u001b[39m cls_metrics_wrapper(tokenizer)  \u001b[38;5;66;03m# always using cls_metrics\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Largely copied from IterableAnnDataset\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m phenotype_category_labels \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mphenotypic_tokens_map[\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphenotype_category\u001b[49m]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mbinary_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     label2id \u001b[38;5;241m=\u001b[39m {label: i \u001b[38;5;28;01mfor\u001b[39;00m i, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(phenotype_category_labels)}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TrainMLMConfig' object has no attribute 'phenotype_category'"
     ]
    }
   ],
   "source": [
    "model_checkpt_path = \"/storage_bizon/bizon_filesystem/output_2gpu_mlm_015gene_050pheno_vastai_10000_mlm_bins10/checkpoint-305000\"\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# Load tokenizer first, so that we can get the config\n",
    "expected_tokenizer_path = os.path.join(\n",
    "    os.path.dirname(model_checkpt_path),\n",
    "    \"tokenizer.pkl\",\n",
    ")\n",
    "\n",
    "if os.path.isfile(expected_tokenizer_path):\n",
    "    with open(expected_tokenizer_path, \"rb\") as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "else:\n",
    "    print(\"Saved tokenizer not found, creating tokenizer with common parameters\")\n",
    "    tokenizer = GeneTokenizer(get_inference_config(  # change these parameters\n",
    "        bin_edges=[0.1], \n",
    "        pretrained_model_path=model_checkpt_path,  # needs to be a path that exists\n",
    "        max_length=130,        \n",
    "        num_top_genes=128\n",
    "    ))\n",
    "\n",
    "tokenizer.config.vocab_path = os.path.join(\"/home/yufan/\", tokenizer.config.vocab_path)  # rel path -> abs path\n",
    "config = tokenizer.config\n",
    "\n",
    "model_class = GeneBertModel\n",
    "\n",
    "data_collator = collate_fn_wrapper(tokenizer)\n",
    "compute_metrics = cls_metrics_wrapper(tokenizer)  # always using cls_metrics\n",
    "\n",
    "# Largely copied from IterableAnnDataset\n",
    "phenotype_category_labels = tokenizer.phenotypic_tokens_map[config.phenotype_category]\n",
    "\n",
    "if config.binary_label is None:\n",
    "    label2id = {label: i for i, label in enumerate(phenotype_category_labels)}\n",
    "else:\n",
    "    label2id = {label: int(label == config.binary_label)\n",
    "                     for label in phenotype_category_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainMLMConfig(subcommand='mlm', bin_edges=[0.1, 1.08888889, 2.07777778, 3.06666667, 4.05555556, 5.04444444, 6.03333333, 7.02222222, 8.01111111, 9.0], bin_edges_path=None, pretrained_model_path='perturbgene/model_configs/distilbert_large.json', model_arch=None, shard_size=10000, eval_data_paths=['perturbgene/ranked/Tabula_Sapiens_ranked_47.h5ad'], max_length=10000, num_top_genes=58604, vocab_path='/home/yufan/perturbgene/data/phenotypic_tokens_map.json', included_phenotypes=['cell_type', 'sex', 'tissue'], use_flash_attn=True, output_dir='output_2gpu_mlm_015gene_050pheno_vastai', per_device_eval_batch_size=32, dataloader_num_workers=4, auto_find_batch_size=True, train_data_paths=['perturbgene/ranked/Tabula_Sapiens_ranked_0.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_1.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_2.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_3.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_4.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_5.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_6.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_7.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_8.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_9.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_10.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_11.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_12.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_13.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_14.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_15.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_16.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_17.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_18.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_19.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_20.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_21.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_22.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_23.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_24.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_25.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_26.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_27.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_28.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_29.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_30.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_31.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_32.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_33.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_34.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_35.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_36.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_37.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_38.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_39.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_40.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_41.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_42.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_43.h5ad'], num_hidden_layers=12, num_attention_heads=16, num_train_epochs=25, per_device_train_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.05, warmup_ratio=0.1, save_steps=5000, eval_steps=5000, gene_mask_prob=0.15, phenotype_mask_prob=0.5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneBertModel(\n",
       "  (embeddings): PositionlessEmbeddings(\n",
       "    (word_embeddings): Embedding(268, 1024, padding_idx=3)\n",
       "    (token_type_embeddings): Embedding(58610, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GeneBertModel.from_pretrained(\n",
    "    model_checkpt_path\n",
    "    ).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perturbgene.data_utils.read import read_h5ad_cloudflare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239432396\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import anndata\n",
    "\n",
    "def read_h5ad_cloudflare(file_url: str, local_path: str) -> anndata.AnnData:\n",
    "    # Send a HEAD request to get the file size\n",
    "    head_response = requests.head(file_url)\n",
    "    if head_response.status_code != 200:\n",
    "        print(\"Failed to fetch the file headers.\")\n",
    "        return None\n",
    "\n",
    "    # Get the file size from headers\n",
    "    file_size = int(head_response.headers.get('Content-Length', 0))\n",
    "    print(file_size)\n",
    "    # Check if the file is larger than 10 MB (10 * 1024 * 1024 bytes)\n",
    "    if file_size > 300 * 1024 * 1024:\n",
    "        print(\"File is larger than 10 MB, download skipped.\")\n",
    "        return None\n",
    "\n",
    "    # Fetch the file if size is within the limit\n",
    "    response = requests.get(file_url)\n",
    "    if response.status_code == 200:\n",
    "        # Write the binary content of the response to a local file\n",
    "        with open(local_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        # Load the AnnData object from the saved file\n",
    "        return anndata.read_h5ad(local_path)\n",
    "    else:\n",
    "        print(\"Failed to fetch the AnnData file.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "file_url = 'https://pub-8978012207224952a747e641910bcb1c.r2.dev/ranked/Tabula_Sapiens_ranked_47.h5ad'\n",
    "local_path = 'Tabula_Sapiens_ranked_47.h5ad'\n",
    "adata = read_h5ad_cloudflare(file_url, local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = read_h5ad_file(\"Tabula_Sapiens_ranked_47.h5ad\", config.num_top_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainMLMConfig(subcommand='mlm', bin_edges=[0.1, 1.08888889, 2.07777778, 3.06666667, 4.05555556, 5.04444444, 6.03333333, 7.02222222, 8.01111111, 9.0], bin_edges_path=None, pretrained_model_path='perturbgene/model_configs/distilbert_large.json', model_arch=None, shard_size=10000, eval_data_paths=['perturbgene/ranked/Tabula_Sapiens_ranked_47.h5ad'], max_length=10000, num_top_genes=58604, vocab_path='/home/yufan/perturbgene/data/phenotypic_tokens_map.json', included_phenotypes=['cell_type', 'sex', 'tissue'], use_flash_attn=True, output_dir='output_2gpu_mlm_015gene_050pheno_vastai', per_device_eval_batch_size=32, dataloader_num_workers=4, auto_find_batch_size=True, train_data_paths=['perturbgene/ranked/Tabula_Sapiens_ranked_0.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_1.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_2.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_3.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_4.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_5.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_6.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_7.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_8.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_9.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_10.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_11.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_12.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_13.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_14.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_15.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_16.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_17.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_18.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_19.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_20.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_21.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_22.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_23.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_24.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_25.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_26.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_27.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_28.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_29.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_30.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_31.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_32.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_33.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_34.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_35.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_36.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_37.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_38.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_39.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_40.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_41.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_42.h5ad', 'perturbgene/ranked/Tabula_Sapiens_ranked_43.h5ad'], num_hidden_layers=12, num_attention_heads=16, num_train_epochs=25, per_device_train_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.05, warmup_ratio=0.1, save_steps=5000, eval_steps=5000, gene_mask_prob=0.15, phenotype_mask_prob=0.5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mmodel_type\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m cell \u001b[38;5;241m=\u001b[39m validation_data[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m output, top_id \u001b[38;5;241m=\u001b[39m mlm_for_phenotype_cls(cell, phenotype_category, model, tokenizer, data_collator)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_type' is not defined"
     ]
    }
   ],
   "source": [
    "assert model_type == \"mlm\"\n",
    "cell = validation_data[0]\n",
    "\n",
    "output, top_id = mlm_for_phenotype_cls(cell, phenotype_category, model, tokenizer, data_collator)\n",
    "print(f\"Pred: {tokenizer.flattened_tokens[top_id]}\\n\"\n",
    "      f\"Label: {phenotype_to_token(cell.obs[phenotype_category].item())}\")\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1758, 268])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_cell = prepare_cell(cell, \"mlm\", tokenizer)\n",
    "output = test_cell(prepared_cell, model, data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function perturbgene.data_utils.data_collators.collate_fn_wrapper.<locals>.collate_fn(examples: List[Dict[str, Any]]) -> dict[str, torch.Tensor]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [25:32<00:00,  6.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics={'accuracy': 0.9385, 'precision': 0.736286260292851, 'recall': 0.7355059843552131, 'f1': 0.7358959154909885}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "assert model_type == \"mlm\"\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for cell in tqdm(validation_data):\n",
    "    top_id = mlm_for_phenotype_cls(cell, phenotype_category, model, tokenizer, data_collator)\n",
    "    all_preds.append(phenotype_category_labels.index(tokenizer.flattened_tokens[top_id]))\n",
    "    all_labels.append(phenotype_category_labels.index(phenotype_to_token(cell.obs[phenotype_category].item())))\n",
    "\n",
    "metrics = compute_metrics(transformers.EvalPrediction(\n",
    "    predictions=np.array(all_preds), \n",
    "    label_ids=np.array(all_labels).reshape(-1, 1),\n",
    "))\n",
    "\n",
    "print(f\"{metrics=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boltons'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/yufan/polygene\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolygene\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference_gene_bert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_embeddings\n",
      "File \u001b[0;32m~/polygene/inference_gene_bert.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchEncoding\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdadc_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgene_bert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeneBertForMaskedLM\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgene_tokenizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeneTokenizer\n",
      "File \u001b[0;32m~/polygene/data_utils/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright Contributors to the Cellarium project.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdadc_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IterableDistributedAnnDataCollectionDataset\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed_anndata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     DistributedAnnDataCollection,\n\u001b[1;32m      7\u001b[0m     DistributedAnnDataCollectionView,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mread\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_h5ad_file, read_h5ad_gcs, read_h5ad_local, read_h5ad_url\n",
      "File \u001b[0;32m~/polygene/data_utils/dadc_dataset.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedTokenizer\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed_anndata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedAnnDataCollection\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_rank_and_num_replicas, get_worker_info\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "File \u001b[0;32m~/polygene/data_utils/distributed_anndata.py:18\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manndata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Index, _normalize_indices\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manndata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulti_files\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_anncollection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     14\u001b[0m     AnnCollection,\n\u001b[1;32m     15\u001b[0m     AnnCollectionView,\n\u001b[1;32m     16\u001b[0m     ConvertType,\n\u001b[1;32m     17\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mboltons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcacheutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LRU\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbraceexpand\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m braceexpand\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mread\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_h5ad_file\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'boltons'"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(eval_dataloader):\n",
    "    with torch.no_grad():\n",
    "        preds = GeneBertModel(**{key: val.to(device) for key, val in batch.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_space(prepared_cell, model):\n",
    "    # Function to extract latent space representation from the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.distilbert(\n",
    "            input_ids=prepared_cell[\"input_ids\"].to(device),\n",
    "            token_type_ids=prepared_cell.get(\"token_type_ids\").to(device),\n",
    "            attention_mask=prepared_cell.get(\"attention_mask\").to(device)\n",
    "        )\n",
    "    # outputs.last_hidden_state contains the latent space representations\n",
    "    return outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2206, 1024])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = validation_data[1000]\n",
    "prepared_cell = prepare_cell(cell, \"mlm\", tokenizer)\n",
    "batched_cell = data_collator([prepared_cell])  # batch with 1 cell\n",
    "with torch.no_grad():\n",
    "    output = model(**{key: val.to(model.device) for key, val in batched_cell.items()}, output_hidden_states=True)\n",
    "embeddings = torch.unbind(output.hidden_states[-1].detach().cpu(), dim=0)\n",
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs Ã— n_vars = 1 Ã— 58604\n",
       "    obs: 'tissue_in_publication', 'assay_ontology_term_id', 'donor_id', 'anatomical_information', 'n_counts_UMIs', 'n_genes', 'cell_ontology_class', 'free_annotation', 'manually_annotated', 'compartment', 'sex_ontology_term_id', 'disease_ontology_term_id', 'is_primary_data', 'organism_ontology_term_id', 'suspension_type', 'cell_type_ontology_term_id', 'tissue_ontology_term_id', 'development_stage_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'tissue_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid'\n",
       "    var: 'feature_type', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
       "    uns: '_scvi', '_training_mode', 'citation', 'dendrogram_cell_type_tissue', 'dendrogram_computational_compartment_assignment', 'dendrogram_consensus_prediction', 'dendrogram_tissue_cell_type', 'donor_id_colors', 'hvg', 'log1p', 'neighbors', 'schema_reference', 'schema_version', 'tissue_in_publication_colors', 'title', 'umap'\n",
       "    obsm: 'X_pca', 'X_scvi', 'X_scvi_umap', 'X_umap'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49513, 49547, 49563, 49638, 49674, 49687, 49740, 49824, 49827, 49830,\n",
       "         49839, 49850, 49859, 49864, 49868, 49875, 49915, 49916, 49945, 49953,\n",
       "         49963, 50022, 50074, 50089, 50100, 50118, 50123, 50125, 50133, 50146,\n",
       "         50152, 50154, 50161, 50164, 50185, 50194, 50267, 50518, 50540, 50545,\n",
       "         50589, 50595, 50623, 50625, 50652, 50653, 50754, 50786, 50791, 50809,\n",
       "         50815, 50817, 50818, 50819, 50846, 50869, 50873, 50876, 50878, 50918,\n",
       "         50920, 50939, 50959, 50969, 51038, 51104, 51106, 51135, 51200, 51207,\n",
       "         51214, 51219, 51231, 51248, 51275, 51307, 51309, 51315, 51340, 51365,\n",
       "         51370, 51374, 51376, 51399, 51404, 51406, 51427, 51429, 51488, 51498,\n",
       "         51521, 51549, 51635, 51648, 51734, 51740, 51747, 51846, 51848, 51860,\n",
       "         51866, 51871, 51958, 52004, 52021, 52061, 52086, 52127, 52159, 52169,\n",
       "         52173, 52178, 52182, 52191, 52208, 52262, 52329, 52358, 52380, 52430,\n",
       "         52451, 52458, 52494, 52519, 52545, 52553, 52561, 52635, 52663, 52686,\n",
       "         52704, 52778, 52787, 52789, 52790, 52816, 52832, 52836, 52846, 52902,\n",
       "         52906, 52970, 52971, 52983, 52998, 53008, 53045, 53047, 53052, 53060,\n",
       "         53111, 53112, 53118, 53153, 53209, 53235, 53298, 53308, 53310, 53360,\n",
       "         53393, 53474, 53603, 53664, 53665, 53674, 53805, 53920, 53968, 53977,\n",
       "         53988, 54006, 54033, 54079, 54091, 54092, 54128, 54151, 54197, 54202,\n",
       "         54205, 54263, 54305, 54318, 54321, 54412, 54418, 54533, 54536, 54556,\n",
       "         54653, 54656, 54780, 54832, 54904, 54912, 54929, 54933, 54969, 55018,\n",
       "         55065, 55096, 55112, 55120, 55183, 55188, 55216, 55239, 55252, 55263,\n",
       "         55269, 55273, 55298, 55320, 55352, 55363, 55374, 55375, 55392, 55397,\n",
       "         55424, 55426, 55475, 55490, 55506, 55535, 55557, 55568, 55579, 55659,\n",
       "         55761, 55783, 55816, 55821, 55822, 55838, 55881, 55922, 55927, 55965,\n",
       "         56105, 56106, 56126, 56148, 56166, 56175, 56245, 56272, 56328, 56334,\n",
       "         56364, 56554, 56555, 56595, 56622, 56631, 56714, 56725, 56731, 56746,\n",
       "         56749, 56785, 56790, 56833, 56863, 56868, 56886, 56902, 57015, 57067,\n",
       "         57086, 57345, 57381, 57383, 57399, 57403, 57462, 57553, 57557, 57662,\n",
       "         57940, 57953, 57956, 57961, 57977, 57980, 57983, 57985, 57989, 57994,\n",
       "         58574, 58576, 58578, 58582, 58588, 58591, 58593, 58594, 58595, 58597,\n",
       "         58599, 58600, 58604, 58607, 58608,     0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_cell['token_type_ids'][:,1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[258, 258, 259, 258, 259, 258, 259, 258, 258, 259, 258, 258, 258, 260,\n",
       "         258, 258, 258, 258, 258, 259, 258, 258, 259, 259, 259, 258, 258, 259,\n",
       "         258, 258, 258, 258, 258, 258, 258, 258, 258, 258, 258, 259, 258, 259,\n",
       "         258, 259, 259, 258, 258, 258, 258, 258, 260, 259, 259, 259, 258, 261,\n",
       "         258, 258, 258, 258, 259, 258, 260, 258, 259, 263, 260, 260, 258, 258,\n",
       "         258, 258, 260, 259, 258, 259, 259, 262, 258, 258, 258, 260, 258, 258,\n",
       "         259, 258, 258, 259, 258, 258, 258, 259, 258, 259, 258, 259, 259, 259,\n",
       "         258, 258, 258, 258, 258, 258, 258, 258, 258, 258, 258, 258, 258, 258,\n",
       "         259, 258, 259, 258, 258, 258, 259, 258, 258, 258, 258, 260, 258, 258,\n",
       "         259, 259, 259, 258, 258, 258, 258, 258, 258, 258, 259, 258, 258, 259,\n",
       "         259, 258, 258, 258, 258, 258, 259, 260, 258, 258, 258, 258, 258, 259,\n",
       "         258, 258, 259, 260, 258, 260, 258, 258, 259, 259, 258, 258, 258, 258,\n",
       "         259, 258, 258, 259, 258, 259, 259, 258, 258, 258, 259, 258, 258, 260,\n",
       "         258, 258, 259, 259, 259, 258, 258, 258, 258, 258, 259, 258, 258, 258,\n",
       "         259, 258, 259, 258, 258, 260, 258, 259, 258, 258, 259, 258, 258, 258,\n",
       "         259, 259, 258, 258, 260, 259, 259, 258, 259, 258, 258, 258, 258, 259,\n",
       "         258, 259, 258, 258, 258, 258, 258, 258, 258, 258, 261, 258, 258, 258,\n",
       "         258, 261, 259, 258, 258, 259, 259, 259, 258, 259, 258, 258, 258, 258,\n",
       "         258, 258, 258, 261, 259, 258, 258, 258, 260, 259, 259, 258, 258, 258,\n",
       "         258, 258, 259, 258, 258, 259, 259, 258, 259, 258, 258, 258, 258, 259,\n",
       "         259, 259, 258, 259, 259, 258, 260, 258, 258, 258, 263, 264, 261, 262,\n",
       "         263, 263, 259, 263, 263, 263, 259, 262, 261, 263, 258,   1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_cell['token_'][:,1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     1,     4,  ..., 58607, 58608,     0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_cell['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 161, 210,  ..., 263, 258,   1]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_cell['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2654,  1.6988,  0.1701,  ...,  1.3653,  1.2699, -1.0515],\n",
       "         [-1.4573,  1.1436,  0.4946,  ...,  0.8807,  0.8994, -1.1519],\n",
       "         [-0.7816,  2.2156,  1.2931,  ...,  0.7454,  0.6117, -0.4987],\n",
       "         ...,\n",
       "         [-0.5899,  0.4999,  0.2759,  ..., -1.1132,  1.5720, -0.5061],\n",
       "         [ 0.9489, -1.1173,  1.0066,  ...,  1.0103,  0.8209, -0.9867],\n",
       "         [ 0.5455,  2.1979,  0.4103,  ...,  1.3668, -0.2371, -1.1109]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2654,  1.6988,  0.1701,  ...,  1.3653,  1.2699, -1.0515],\n",
       "         [-1.4573,  1.1436,  0.4946,  ...,  0.8807,  0.8994, -1.1519],\n",
       "         [-0.7816,  2.2156,  1.2931,  ...,  0.7454,  0.6117, -0.4987],\n",
       "         ...,\n",
       "         [-0.5899,  0.4999,  0.2759,  ..., -1.1132,  1.5720, -0.5061],\n",
       "         [ 0.9489, -1.1173,  1.0066,  ...,  1.0103,  0.8209, -0.9867],\n",
       "         [ 0.5455,  2.1979,  0.4103,  ...,  1.3668, -0.2371, -1.1109]]),)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3480, 1024])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 3007/10000 [07:44<18:00,  6.47it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      7\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{key: val\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m batched_cell\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[0;32m----> 8\u001b[0m     emb_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Move to CPU\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Stack the list of embeddings into a single tensor\u001b[39;00m\n\u001b[1;32m     11\u001b[0m stacked_embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(emb_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "emb_list = []\n",
    "\n",
    "for cell in tqdm(validation_data):\n",
    "    prepared_cell = prepare_cell(cell, \"mlm\", tokenizer)\n",
    "    batched_cell = data_collator([prepared_cell])\n",
    "    with torch.no_grad():\n",
    "        output = model(**{key: val.to(model.device) for key, val in batched_cell.items()})\n",
    "    emb_list.append(output.last_hidden_state.cpu())  # Move to CPU\n",
    "\n",
    "# Stack the list of embeddings into a single tensor\n",
    "stacked_embeddings = torch.stack(emb_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 3655/10000 [08:46<15:13,  6.95it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.13 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m batched_cell \u001b[38;5;241m=\u001b[39m data_collator([prepared_cell])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatched_cell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m emb_list\u001b[38;5;241m.\u001b[39mappend(output\u001b[38;5;241m.\u001b[39mlast_hidden_state)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/perturbgene/model.py:134\u001b[0m, in \u001b[0;36mGeneBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, token_type_ids)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(input_shape, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# (bs, seq_length)\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:571\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    563\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    564\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    565\u001b[0m         hidden_state,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m         output_attentions,\n\u001b[1;32m    569\u001b[0m     )\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 571\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:497\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;124;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    506\u001b[0m     sa_output, sa_weights \u001b[38;5;241m=\u001b[39m sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:229\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    227\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(q, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m))  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[1;32m    228\u001b[0m mask \u001b[38;5;241m=\u001b[39m (mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mview(mask_reshp)\u001b[38;5;241m.\u001b[39mexpand_as(scores)  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[1;32m    233\u001b[0m weights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[1;32m    234\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(weights)  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.13 GiB. GPU "
     ]
    }
   ],
   "source": [
    "emb_list = []\n",
    "for cell in tqdm(validation_data):\n",
    "    prepared_cell = prepare_cell(cell, \"mlm\", tokenizer)\n",
    "    batched_cell = data_collator([prepared_cell])\n",
    "    with torch.no_grad():\n",
    "        output = model(**{key: val.to(model.device) for key, val in batched_cell.items()})\n",
    "    emb_list.append(output.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã— n_vars = 10000 Ã— 58604\n",
       "    obs: 'tissue_in_publication', 'assay_ontology_term_id', 'donor_id', 'anatomical_information', 'n_counts_UMIs', 'n_genes', 'cell_ontology_class', 'free_annotation', 'manually_annotated', 'compartment', 'sex_ontology_term_id', 'disease_ontology_term_id', 'is_primary_data', 'organism_ontology_term_id', 'suspension_type', 'cell_type_ontology_term_id', 'tissue_ontology_term_id', 'development_stage_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'tissue_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid'\n",
       "    var: 'feature_type', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
       "    uns: '_scvi', '_training_mode', 'citation', 'dendrogram_cell_type_tissue', 'dendrogram_computational_compartment_assignment', 'dendrogram_consensus_prediction', 'dendrogram_tissue_cell_type', 'donor_id_colors', 'hvg', 'log1p', 'neighbors', 'schema_reference', 'schema_version', 'tissue_in_publication_colors', 'title', 'umap'\n",
       "    obsm: 'X_pca', 'X_scvi', 'X_scvi_umap', 'X_umap'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1758, 1024])\n",
      "torch.Size([1, 4477, 1024])\n",
      "torch.Size([1, 1944, 1024])\n",
      "torch.Size([1, 4007, 1024])\n",
      "torch.Size([1, 1569, 1024])\n",
      "torch.Size([1, 4196, 1024])\n",
      "torch.Size([1, 1820, 1024])\n",
      "torch.Size([1, 2792, 1024])\n",
      "torch.Size([1, 1998, 1024])\n",
      "torch.Size([1, 948, 1024])\n",
      "torch.Size([1, 1924, 1024])\n",
      "torch.Size([1, 2472, 1024])\n",
      "torch.Size([1, 2622, 1024])\n",
      "torch.Size([1, 4308, 1024])\n",
      "torch.Size([1, 2939, 1024])\n",
      "torch.Size([1, 5940, 1024])\n",
      "torch.Size([1, 2205, 1024])\n",
      "torch.Size([1, 1914, 1024])\n",
      "torch.Size([1, 4679, 1024])\n",
      "torch.Size([1, 1607, 1024])\n",
      "torch.Size([1, 3237, 1024])\n",
      "torch.Size([1, 1486, 1024])\n",
      "torch.Size([1, 3019, 1024])\n",
      "torch.Size([1, 6135, 1024])\n",
      "torch.Size([1, 2115, 1024])\n",
      "torch.Size([1, 3125, 1024])\n",
      "torch.Size([1, 1377, 1024])\n",
      "torch.Size([1, 2642, 1024])\n",
      "torch.Size([1, 4932, 1024])\n",
      "torch.Size([1, 3457, 1024])\n",
      "torch.Size([1, 4277, 1024])\n",
      "torch.Size([1, 1348, 1024])\n",
      "torch.Size([1, 1667, 1024])\n",
      "torch.Size([1, 5350, 1024])\n",
      "torch.Size([1, 900, 1024])\n",
      "torch.Size([1, 2380, 1024])\n",
      "torch.Size([1, 1924, 1024])\n",
      "torch.Size([1, 1414, 1024])\n",
      "torch.Size([1, 1892, 1024])\n",
      "torch.Size([1, 1723, 1024])\n",
      "torch.Size([1, 2669, 1024])\n",
      "torch.Size([1, 4341, 1024])\n",
      "torch.Size([1, 3251, 1024])\n",
      "torch.Size([1, 1656, 1024])\n",
      "torch.Size([1, 2584, 1024])\n",
      "torch.Size([1, 4046, 1024])\n",
      "torch.Size([1, 1522, 1024])\n",
      "torch.Size([1, 4477, 1024])\n",
      "torch.Size([1, 2777, 1024])\n",
      "torch.Size([1, 247, 1024])\n",
      "torch.Size([1, 1663, 1024])\n",
      "torch.Size([1, 2642, 1024])\n",
      "torch.Size([1, 1872, 1024])\n",
      "torch.Size([1, 3596, 1024])\n",
      "torch.Size([1, 3252, 1024])\n",
      "torch.Size([1, 4742, 1024])\n",
      "torch.Size([1, 2545, 1024])\n",
      "torch.Size([1, 1336, 1024])\n",
      "torch.Size([1, 2320, 1024])\n",
      "torch.Size([1, 1271, 1024])\n",
      "torch.Size([1, 5315, 1024])\n",
      "torch.Size([1, 2916, 1024])\n",
      "torch.Size([1, 2076, 1024])\n",
      "torch.Size([1, 3224, 1024])\n",
      "torch.Size([1, 1829, 1024])\n",
      "torch.Size([1, 2591, 1024])\n",
      "torch.Size([1, 4269, 1024])\n",
      "torch.Size([1, 3708, 1024])\n",
      "torch.Size([1, 2944, 1024])\n",
      "torch.Size([1, 1987, 1024])\n",
      "torch.Size([1, 2601, 1024])\n",
      "torch.Size([1, 2960, 1024])\n",
      "torch.Size([1, 2539, 1024])\n",
      "torch.Size([1, 1633, 1024])\n",
      "torch.Size([1, 3258, 1024])\n",
      "torch.Size([1, 2122, 1024])\n",
      "torch.Size([1, 1588, 1024])\n",
      "torch.Size([1, 1838, 1024])\n",
      "torch.Size([1, 1559, 1024])\n",
      "torch.Size([1, 3452, 1024])\n",
      "torch.Size([1, 1699, 1024])\n",
      "torch.Size([1, 2300, 1024])\n",
      "torch.Size([1, 1209, 1024])\n",
      "torch.Size([1, 2176, 1024])\n",
      "torch.Size([1, 2475, 1024])\n",
      "torch.Size([1, 517, 1024])\n",
      "torch.Size([1, 3093, 1024])\n",
      "torch.Size([1, 1475, 1024])\n",
      "torch.Size([1, 1302, 1024])\n",
      "torch.Size([1, 2889, 1024])\n",
      "torch.Size([1, 855, 1024])\n",
      "torch.Size([1, 2000, 1024])\n",
      "torch.Size([1, 1803, 1024])\n",
      "torch.Size([1, 3168, 1024])\n",
      "torch.Size([1, 5357, 1024])\n",
      "torch.Size([1, 1279, 1024])\n",
      "torch.Size([1, 3044, 1024])\n",
      "torch.Size([1, 1638, 1024])\n",
      "torch.Size([1, 1417, 1024])\n",
      "torch.Size([1, 4440, 1024])\n",
      "torch.Size([1, 1694, 1024])\n",
      "torch.Size([1, 1641, 1024])\n",
      "torch.Size([1, 3494, 1024])\n",
      "torch.Size([1, 1848, 1024])\n",
      "torch.Size([1, 597, 1024])\n",
      "torch.Size([1, 4092, 1024])\n",
      "torch.Size([1, 2161, 1024])\n",
      "torch.Size([1, 4118, 1024])\n",
      "torch.Size([1, 6243, 1024])\n",
      "torch.Size([1, 2409, 1024])\n",
      "torch.Size([1, 2656, 1024])\n",
      "torch.Size([1, 5234, 1024])\n",
      "torch.Size([1, 2029, 1024])\n",
      "torch.Size([1, 5797, 1024])\n",
      "torch.Size([1, 2167, 1024])\n",
      "torch.Size([1, 1371, 1024])\n",
      "torch.Size([1, 1247, 1024])\n",
      "torch.Size([1, 5066, 1024])\n",
      "torch.Size([1, 1457, 1024])\n",
      "torch.Size([1, 1482, 1024])\n",
      "torch.Size([1, 1488, 1024])\n",
      "torch.Size([1, 1788, 1024])\n",
      "torch.Size([1, 2007, 1024])\n",
      "torch.Size([1, 521, 1024])\n",
      "torch.Size([1, 5554, 1024])\n",
      "torch.Size([1, 1460, 1024])\n",
      "torch.Size([1, 2639, 1024])\n",
      "torch.Size([1, 3967, 1024])\n",
      "torch.Size([1, 902, 1024])\n",
      "torch.Size([1, 2392, 1024])\n",
      "torch.Size([1, 3343, 1024])\n",
      "torch.Size([1, 3544, 1024])\n",
      "torch.Size([1, 2266, 1024])\n",
      "torch.Size([1, 1140, 1024])\n",
      "torch.Size([1, 5657, 1024])\n",
      "torch.Size([1, 3532, 1024])\n",
      "torch.Size([1, 1556, 1024])\n",
      "torch.Size([1, 2136, 1024])\n",
      "torch.Size([1, 2553, 1024])\n",
      "torch.Size([1, 2726, 1024])\n",
      "torch.Size([1, 8059, 1024])\n",
      "torch.Size([1, 551, 1024])\n",
      "torch.Size([1, 1920, 1024])\n",
      "torch.Size([1, 1012, 1024])\n",
      "torch.Size([1, 1811, 1024])\n",
      "torch.Size([1, 2715, 1024])\n",
      "torch.Size([1, 2518, 1024])\n",
      "torch.Size([1, 4146, 1024])\n",
      "torch.Size([1, 1272, 1024])\n",
      "torch.Size([1, 1673, 1024])\n",
      "torch.Size([1, 1768, 1024])\n",
      "torch.Size([1, 3402, 1024])\n",
      "torch.Size([1, 2342, 1024])\n",
      "torch.Size([1, 1716, 1024])\n",
      "torch.Size([1, 3330, 1024])\n",
      "torch.Size([1, 1581, 1024])\n",
      "torch.Size([1, 6760, 1024])\n",
      "torch.Size([1, 757, 1024])\n",
      "torch.Size([1, 1628, 1024])\n",
      "torch.Size([1, 2559, 1024])\n",
      "torch.Size([1, 7853, 1024])\n",
      "torch.Size([1, 3598, 1024])\n",
      "torch.Size([1, 1754, 1024])\n",
      "torch.Size([1, 1369, 1024])\n",
      "torch.Size([1, 309, 1024])\n",
      "torch.Size([1, 419, 1024])\n",
      "torch.Size([1, 1602, 1024])\n",
      "torch.Size([1, 1962, 1024])\n",
      "torch.Size([1, 2357, 1024])\n",
      "torch.Size([1, 2015, 1024])\n",
      "torch.Size([1, 1535, 1024])\n",
      "torch.Size([1, 3735, 1024])\n",
      "torch.Size([1, 1469, 1024])\n",
      "torch.Size([1, 1864, 1024])\n",
      "torch.Size([1, 2482, 1024])\n",
      "torch.Size([1, 2337, 1024])\n",
      "torch.Size([1, 2078, 1024])\n",
      "torch.Size([1, 1813, 1024])\n",
      "torch.Size([1, 3806, 1024])\n",
      "torch.Size([1, 2123, 1024])\n",
      "torch.Size([1, 893, 1024])\n",
      "torch.Size([1, 8269, 1024])\n",
      "torch.Size([1, 1309, 1024])\n",
      "torch.Size([1, 1802, 1024])\n",
      "torch.Size([1, 1248, 1024])\n",
      "torch.Size([1, 883, 1024])\n",
      "torch.Size([1, 3965, 1024])\n",
      "torch.Size([1, 2872, 1024])\n",
      "torch.Size([1, 4595, 1024])\n",
      "torch.Size([1, 5121, 1024])\n",
      "torch.Size([1, 2735, 1024])\n",
      "torch.Size([1, 5131, 1024])\n",
      "torch.Size([1, 3817, 1024])\n",
      "torch.Size([1, 4991, 1024])\n",
      "torch.Size([1, 1240, 1024])\n",
      "torch.Size([1, 1160, 1024])\n",
      "torch.Size([1, 2857, 1024])\n",
      "torch.Size([1, 1396, 1024])\n",
      "torch.Size([1, 1116, 1024])\n",
      "torch.Size([1, 1617, 1024])\n",
      "torch.Size([1, 4035, 1024])\n",
      "torch.Size([1, 3287, 1024])\n",
      "torch.Size([1, 6732, 1024])\n",
      "torch.Size([1, 1307, 1024])\n",
      "torch.Size([1, 1725, 1024])\n",
      "torch.Size([1, 1189, 1024])\n",
      "torch.Size([1, 5751, 1024])\n",
      "torch.Size([1, 2484, 1024])\n",
      "torch.Size([1, 1580, 1024])\n",
      "torch.Size([1, 2592, 1024])\n",
      "torch.Size([1, 1268, 1024])\n",
      "torch.Size([1, 6734, 1024])\n",
      "torch.Size([1, 1859, 1024])\n",
      "torch.Size([1, 912, 1024])\n",
      "torch.Size([1, 1942, 1024])\n",
      "torch.Size([1, 3219, 1024])\n",
      "torch.Size([1, 1576, 1024])\n",
      "torch.Size([1, 1144, 1024])\n",
      "torch.Size([1, 1616, 1024])\n",
      "torch.Size([1, 1531, 1024])\n",
      "torch.Size([1, 1204, 1024])\n",
      "torch.Size([1, 1767, 1024])\n",
      "torch.Size([1, 2211, 1024])\n",
      "torch.Size([1, 5167, 1024])\n",
      "torch.Size([1, 2749, 1024])\n",
      "torch.Size([1, 4019, 1024])\n",
      "torch.Size([1, 417, 1024])\n",
      "torch.Size([1, 3427, 1024])\n",
      "torch.Size([1, 1282, 1024])\n",
      "torch.Size([1, 1227, 1024])\n",
      "torch.Size([1, 1882, 1024])\n",
      "torch.Size([1, 1910, 1024])\n",
      "torch.Size([1, 615, 1024])\n",
      "torch.Size([1, 1906, 1024])\n",
      "torch.Size([1, 2063, 1024])\n",
      "torch.Size([1, 1369, 1024])\n",
      "torch.Size([1, 1301, 1024])\n",
      "torch.Size([1, 5698, 1024])\n",
      "torch.Size([1, 4135, 1024])\n",
      "torch.Size([1, 1300, 1024])\n",
      "torch.Size([1, 1717, 1024])\n",
      "torch.Size([1, 5592, 1024])\n",
      "torch.Size([1, 3486, 1024])\n",
      "torch.Size([1, 4070, 1024])\n",
      "torch.Size([1, 2217, 1024])\n",
      "torch.Size([1, 376, 1024])\n",
      "torch.Size([1, 2276, 1024])\n",
      "torch.Size([1, 3989, 1024])\n",
      "torch.Size([1, 1649, 1024])\n",
      "torch.Size([1, 1800, 1024])\n",
      "torch.Size([1, 2222, 1024])\n",
      "torch.Size([1, 3704, 1024])\n",
      "torch.Size([1, 2776, 1024])\n",
      "torch.Size([1, 2987, 1024])\n",
      "torch.Size([1, 6048, 1024])\n",
      "torch.Size([1, 2283, 1024])\n",
      "torch.Size([1, 2076, 1024])\n",
      "torch.Size([1, 2209, 1024])\n",
      "torch.Size([1, 1447, 1024])\n",
      "torch.Size([1, 1428, 1024])\n",
      "torch.Size([1, 2443, 1024])\n",
      "torch.Size([1, 2195, 1024])\n",
      "torch.Size([1, 2819, 1024])\n",
      "torch.Size([1, 2730, 1024])\n",
      "torch.Size([1, 2280, 1024])\n",
      "torch.Size([1, 1985, 1024])\n",
      "torch.Size([1, 1418, 1024])\n",
      "torch.Size([1, 934, 1024])\n",
      "torch.Size([1, 1415, 1024])\n",
      "torch.Size([1, 3310, 1024])\n",
      "torch.Size([1, 3002, 1024])\n",
      "torch.Size([1, 2554, 1024])\n",
      "torch.Size([1, 2717, 1024])\n",
      "torch.Size([1, 2186, 1024])\n",
      "torch.Size([1, 1416, 1024])\n",
      "torch.Size([1, 1659, 1024])\n",
      "torch.Size([1, 3417, 1024])\n",
      "torch.Size([1, 2970, 1024])\n",
      "torch.Size([1, 5571, 1024])\n",
      "torch.Size([1, 4044, 1024])\n",
      "torch.Size([1, 4079, 1024])\n",
      "torch.Size([1, 1888, 1024])\n",
      "torch.Size([1, 2017, 1024])\n",
      "torch.Size([1, 1381, 1024])\n",
      "torch.Size([1, 1829, 1024])\n",
      "torch.Size([1, 1370, 1024])\n",
      "torch.Size([1, 2541, 1024])\n",
      "torch.Size([1, 2637, 1024])\n",
      "torch.Size([1, 2113, 1024])\n",
      "torch.Size([1, 1787, 1024])\n",
      "torch.Size([1, 1696, 1024])\n",
      "torch.Size([1, 1068, 1024])\n",
      "torch.Size([1, 4083, 1024])\n",
      "torch.Size([1, 1530, 1024])\n",
      "torch.Size([1, 6054, 1024])\n",
      "torch.Size([1, 2628, 1024])\n",
      "torch.Size([1, 2877, 1024])\n",
      "torch.Size([1, 4375, 1024])\n",
      "torch.Size([1, 2452, 1024])\n",
      "torch.Size([1, 1308, 1024])\n",
      "torch.Size([1, 1109, 1024])\n",
      "torch.Size([1, 1371, 1024])\n",
      "torch.Size([1, 1505, 1024])\n",
      "torch.Size([1, 1309, 1024])\n",
      "torch.Size([1, 1481, 1024])\n",
      "torch.Size([1, 2141, 1024])\n",
      "torch.Size([1, 1649, 1024])\n",
      "torch.Size([1, 2483, 1024])\n",
      "torch.Size([1, 1499, 1024])\n",
      "torch.Size([1, 675, 1024])\n",
      "torch.Size([1, 1309, 1024])\n",
      "torch.Size([1, 1465, 1024])\n",
      "torch.Size([1, 1885, 1024])\n",
      "torch.Size([1, 3293, 1024])\n",
      "torch.Size([1, 3350, 1024])\n",
      "torch.Size([1, 2590, 1024])\n",
      "torch.Size([1, 943, 1024])\n",
      "torch.Size([1, 2193, 1024])\n",
      "torch.Size([1, 3282, 1024])\n",
      "torch.Size([1, 1942, 1024])\n",
      "torch.Size([1, 3920, 1024])\n",
      "torch.Size([1, 2339, 1024])\n",
      "torch.Size([1, 6345, 1024])\n",
      "torch.Size([1, 1324, 1024])\n",
      "torch.Size([1, 3365, 1024])\n",
      "torch.Size([1, 5140, 1024])\n",
      "torch.Size([1, 2020, 1024])\n",
      "torch.Size([1, 4639, 1024])\n",
      "torch.Size([1, 3017, 1024])\n",
      "torch.Size([1, 3151, 1024])\n",
      "torch.Size([1, 4227, 1024])\n",
      "torch.Size([1, 1171, 1024])\n",
      "torch.Size([1, 2395, 1024])\n",
      "torch.Size([1, 4451, 1024])\n",
      "torch.Size([1, 3887, 1024])\n",
      "torch.Size([1, 2781, 1024])\n",
      "torch.Size([1, 1880, 1024])\n",
      "torch.Size([1, 2772, 1024])\n",
      "torch.Size([1, 2206, 1024])\n",
      "torch.Size([1, 1328, 1024])\n",
      "torch.Size([1, 2247, 1024])\n",
      "torch.Size([1, 2166, 1024])\n",
      "torch.Size([1, 785, 1024])\n",
      "torch.Size([1, 1401, 1024])\n",
      "torch.Size([1, 2132, 1024])\n",
      "torch.Size([1, 2053, 1024])\n",
      "torch.Size([1, 3320, 1024])\n",
      "torch.Size([1, 3205, 1024])\n",
      "torch.Size([1, 2434, 1024])\n",
      "torch.Size([1, 1469, 1024])\n",
      "torch.Size([1, 1544, 1024])\n",
      "torch.Size([1, 2846, 1024])\n",
      "torch.Size([1, 2450, 1024])\n",
      "torch.Size([1, 2305, 1024])\n",
      "torch.Size([1, 1650, 1024])\n",
      "torch.Size([1, 379, 1024])\n",
      "torch.Size([1, 3293, 1024])\n",
      "torch.Size([1, 1085, 1024])\n",
      "torch.Size([1, 533, 1024])\n",
      "torch.Size([1, 2496, 1024])\n",
      "torch.Size([1, 1422, 1024])\n",
      "torch.Size([1, 5192, 1024])\n",
      "torch.Size([1, 1245, 1024])\n",
      "torch.Size([1, 1381, 1024])\n",
      "torch.Size([1, 1160, 1024])\n",
      "torch.Size([1, 1778, 1024])\n",
      "torch.Size([1, 1269, 1024])\n",
      "torch.Size([1, 2119, 1024])\n",
      "torch.Size([1, 1394, 1024])\n",
      "torch.Size([1, 1402, 1024])\n",
      "torch.Size([1, 1564, 1024])\n",
      "torch.Size([1, 2337, 1024])\n",
      "torch.Size([1, 2527, 1024])\n",
      "torch.Size([1, 4454, 1024])\n",
      "torch.Size([1, 1392, 1024])\n",
      "torch.Size([1, 3202, 1024])\n",
      "torch.Size([1, 4355, 1024])\n",
      "torch.Size([1, 1143, 1024])\n",
      "torch.Size([1, 3900, 1024])\n",
      "torch.Size([1, 2217, 1024])\n",
      "torch.Size([1, 1809, 1024])\n",
      "torch.Size([1, 1632, 1024])\n",
      "torch.Size([1, 2214, 1024])\n",
      "torch.Size([1, 6625, 1024])\n",
      "torch.Size([1, 5656, 1024])\n",
      "torch.Size([1, 2022, 1024])\n",
      "torch.Size([1, 2225, 1024])\n",
      "torch.Size([1, 3504, 1024])\n",
      "torch.Size([1, 2258, 1024])\n",
      "torch.Size([1, 8711, 1024])\n",
      "torch.Size([1, 2384, 1024])\n",
      "torch.Size([1, 1895, 1024])\n",
      "torch.Size([1, 2183, 1024])\n",
      "torch.Size([1, 1803, 1024])\n",
      "torch.Size([1, 1884, 1024])\n",
      "torch.Size([1, 3684, 1024])\n",
      "torch.Size([1, 3727, 1024])\n",
      "torch.Size([1, 1434, 1024])\n",
      "torch.Size([1, 2084, 1024])\n",
      "torch.Size([1, 2759, 1024])\n",
      "torch.Size([1, 1887, 1024])\n",
      "torch.Size([1, 2440, 1024])\n",
      "torch.Size([1, 2312, 1024])\n",
      "torch.Size([1, 3155, 1024])\n",
      "torch.Size([1, 3775, 1024])\n",
      "torch.Size([1, 1800, 1024])\n",
      "torch.Size([1, 6917, 1024])\n",
      "torch.Size([1, 2890, 1024])\n",
      "torch.Size([1, 1440, 1024])\n",
      "torch.Size([1, 2936, 1024])\n",
      "torch.Size([1, 7373, 1024])\n",
      "torch.Size([1, 3551, 1024])\n",
      "torch.Size([1, 2156, 1024])\n",
      "torch.Size([1, 2698, 1024])\n",
      "torch.Size([1, 3021, 1024])\n",
      "torch.Size([1, 1677, 1024])\n",
      "torch.Size([1, 1441, 1024])\n",
      "torch.Size([1, 7481, 1024])\n",
      "torch.Size([1, 1532, 1024])\n",
      "torch.Size([1, 2408, 1024])\n",
      "torch.Size([1, 2738, 1024])\n",
      "torch.Size([1, 1078, 1024])\n",
      "torch.Size([1, 1651, 1024])\n",
      "torch.Size([1, 4546, 1024])\n",
      "torch.Size([1, 2562, 1024])\n",
      "torch.Size([1, 1224, 1024])\n",
      "torch.Size([1, 1995, 1024])\n",
      "torch.Size([1, 1384, 1024])\n",
      "torch.Size([1, 4351, 1024])\n",
      "torch.Size([1, 2210, 1024])\n",
      "torch.Size([1, 1976, 1024])\n",
      "torch.Size([1, 1345, 1024])\n",
      "torch.Size([1, 1447, 1024])\n",
      "torch.Size([1, 1447, 1024])\n",
      "torch.Size([1, 2998, 1024])\n",
      "torch.Size([1, 1746, 1024])\n",
      "torch.Size([1, 2183, 1024])\n",
      "torch.Size([1, 3939, 1024])\n",
      "torch.Size([1, 3242, 1024])\n",
      "torch.Size([1, 2760, 1024])\n",
      "torch.Size([1, 1663, 1024])\n",
      "torch.Size([1, 2178, 1024])\n",
      "torch.Size([1, 438, 1024])\n",
      "torch.Size([1, 2215, 1024])\n",
      "torch.Size([1, 4000, 1024])\n",
      "torch.Size([1, 2790, 1024])\n",
      "torch.Size([1, 1859, 1024])\n",
      "torch.Size([1, 384, 1024])\n",
      "torch.Size([1, 3081, 1024])\n",
      "torch.Size([1, 5397, 1024])\n",
      "torch.Size([1, 2376, 1024])\n",
      "torch.Size([1, 1729, 1024])\n",
      "torch.Size([1, 1270, 1024])\n",
      "torch.Size([1, 509, 1024])\n",
      "torch.Size([1, 2209, 1024])\n",
      "torch.Size([1, 1985, 1024])\n",
      "torch.Size([1, 1741, 1024])\n",
      "torch.Size([1, 3378, 1024])\n",
      "torch.Size([1, 5417, 1024])\n",
      "torch.Size([1, 1313, 1024])\n",
      "torch.Size([1, 2384, 1024])\n",
      "torch.Size([1, 3426, 1024])\n",
      "torch.Size([1, 2034, 1024])\n",
      "torch.Size([1, 2137, 1024])\n",
      "torch.Size([1, 1738, 1024])\n",
      "torch.Size([1, 1425, 1024])\n",
      "torch.Size([1, 2595, 1024])\n",
      "torch.Size([1, 1930, 1024])\n",
      "torch.Size([1, 7814, 1024])\n",
      "torch.Size([1, 2697, 1024])\n",
      "torch.Size([1, 2742, 1024])\n",
      "torch.Size([1, 1117, 1024])\n",
      "torch.Size([1, 4498, 1024])\n",
      "torch.Size([1, 3561, 1024])\n",
      "torch.Size([1, 2305, 1024])\n",
      "torch.Size([1, 1623, 1024])\n",
      "torch.Size([1, 1479, 1024])\n",
      "torch.Size([1, 3779, 1024])\n",
      "torch.Size([1, 4014, 1024])\n",
      "torch.Size([1, 1732, 1024])\n",
      "torch.Size([1, 294, 1024])\n",
      "torch.Size([1, 2616, 1024])\n",
      "torch.Size([1, 1623, 1024])\n",
      "torch.Size([1, 3578, 1024])\n",
      "torch.Size([1, 2551, 1024])\n",
      "torch.Size([1, 1037, 1024])\n",
      "torch.Size([1, 3030, 1024])\n",
      "torch.Size([1, 1744, 1024])\n",
      "torch.Size([1, 2515, 1024])\n",
      "torch.Size([1, 2873, 1024])\n",
      "torch.Size([1, 2808, 1024])\n",
      "torch.Size([1, 2259, 1024])\n",
      "torch.Size([1, 1663, 1024])\n",
      "torch.Size([1, 2375, 1024])\n",
      "torch.Size([1, 2610, 1024])\n",
      "torch.Size([1, 2561, 1024])\n",
      "torch.Size([1, 3085, 1024])\n",
      "torch.Size([1, 4546, 1024])\n",
      "torch.Size([1, 723, 1024])\n",
      "torch.Size([1, 1500, 1024])\n",
      "torch.Size([1, 1786, 1024])\n",
      "torch.Size([1, 1102, 1024])\n",
      "torch.Size([1, 1808, 1024])\n",
      "torch.Size([1, 6114, 1024])\n",
      "torch.Size([1, 5337, 1024])\n",
      "torch.Size([1, 2187, 1024])\n",
      "torch.Size([1, 1643, 1024])\n",
      "torch.Size([1, 1178, 1024])\n",
      "torch.Size([1, 911, 1024])\n",
      "torch.Size([1, 3477, 1024])\n",
      "torch.Size([1, 2684, 1024])\n",
      "torch.Size([1, 1483, 1024])\n",
      "torch.Size([1, 5387, 1024])\n",
      "torch.Size([1, 511, 1024])\n",
      "torch.Size([1, 1428, 1024])\n",
      "torch.Size([1, 3424, 1024])\n",
      "torch.Size([1, 1852, 1024])\n",
      "torch.Size([1, 1499, 1024])\n",
      "torch.Size([1, 1701, 1024])\n",
      "torch.Size([1, 2838, 1024])\n",
      "torch.Size([1, 2728, 1024])\n",
      "torch.Size([1, 2950, 1024])\n",
      "torch.Size([1, 3746, 1024])\n",
      "torch.Size([1, 1963, 1024])\n",
      "torch.Size([1, 3479, 1024])\n",
      "torch.Size([1, 1954, 1024])\n",
      "torch.Size([1, 865, 1024])\n",
      "torch.Size([1, 3317, 1024])\n",
      "torch.Size([1, 2330, 1024])\n",
      "torch.Size([1, 2046, 1024])\n",
      "torch.Size([1, 3649, 1024])\n",
      "torch.Size([1, 4525, 1024])\n",
      "torch.Size([1, 1686, 1024])\n",
      "torch.Size([1, 1133, 1024])\n",
      "torch.Size([1, 3050, 1024])\n",
      "torch.Size([1, 1650, 1024])\n",
      "torch.Size([1, 4359, 1024])\n",
      "torch.Size([1, 2354, 1024])\n",
      "torch.Size([1, 1737, 1024])\n",
      "torch.Size([1, 4574, 1024])\n",
      "torch.Size([1, 1872, 1024])\n",
      "torch.Size([1, 2554, 1024])\n",
      "torch.Size([1, 2047, 1024])\n",
      "torch.Size([1, 2913, 1024])\n",
      "torch.Size([1, 1760, 1024])\n",
      "torch.Size([1, 1618, 1024])\n",
      "torch.Size([1, 2581, 1024])\n",
      "torch.Size([1, 2410, 1024])\n",
      "torch.Size([1, 4051, 1024])\n",
      "torch.Size([1, 3815, 1024])\n",
      "torch.Size([1, 1281, 1024])\n",
      "torch.Size([1, 1705, 1024])\n",
      "torch.Size([1, 2698, 1024])\n",
      "torch.Size([1, 833, 1024])\n",
      "torch.Size([1, 805, 1024])\n",
      "torch.Size([1, 2271, 1024])\n",
      "torch.Size([1, 1919, 1024])\n",
      "torch.Size([1, 3479, 1024])\n",
      "torch.Size([1, 2183, 1024])\n",
      "torch.Size([1, 2423, 1024])\n",
      "torch.Size([1, 2583, 1024])\n",
      "torch.Size([1, 2620, 1024])\n",
      "torch.Size([1, 882, 1024])\n",
      "torch.Size([1, 2088, 1024])\n",
      "torch.Size([1, 3108, 1024])\n",
      "torch.Size([1, 2641, 1024])\n",
      "torch.Size([1, 2227, 1024])\n",
      "torch.Size([1, 1829, 1024])\n",
      "torch.Size([1, 1405, 1024])\n",
      "torch.Size([1, 540, 1024])\n",
      "torch.Size([1, 2861, 1024])\n",
      "torch.Size([1, 1648, 1024])\n",
      "torch.Size([1, 2004, 1024])\n",
      "torch.Size([1, 3285, 1024])\n",
      "torch.Size([1, 2350, 1024])\n",
      "torch.Size([1, 867, 1024])\n",
      "torch.Size([1, 1572, 1024])\n",
      "torch.Size([1, 2120, 1024])\n",
      "torch.Size([1, 1931, 1024])\n",
      "torch.Size([1, 2268, 1024])\n",
      "torch.Size([1, 3452, 1024])\n",
      "torch.Size([1, 1356, 1024])\n",
      "torch.Size([1, 485, 1024])\n",
      "torch.Size([1, 1393, 1024])\n",
      "torch.Size([1, 1136, 1024])\n",
      "torch.Size([1, 2532, 1024])\n",
      "torch.Size([1, 1506, 1024])\n",
      "torch.Size([1, 3210, 1024])\n",
      "torch.Size([1, 2683, 1024])\n",
      "torch.Size([1, 1912, 1024])\n",
      "torch.Size([1, 6076, 1024])\n",
      "torch.Size([1, 1210, 1024])\n",
      "torch.Size([1, 3144, 1024])\n",
      "torch.Size([1, 2598, 1024])\n",
      "torch.Size([1, 499, 1024])\n",
      "torch.Size([1, 1739, 1024])\n",
      "torch.Size([1, 2759, 1024])\n",
      "torch.Size([1, 4306, 1024])\n",
      "torch.Size([1, 1738, 1024])\n",
      "torch.Size([1, 2224, 1024])\n",
      "torch.Size([1, 1301, 1024])\n",
      "torch.Size([1, 421, 1024])\n",
      "torch.Size([1, 1919, 1024])\n",
      "torch.Size([1, 2207, 1024])\n",
      "torch.Size([1, 2051, 1024])\n",
      "torch.Size([1, 1966, 1024])\n",
      "torch.Size([1, 4250, 1024])\n",
      "torch.Size([1, 2005, 1024])\n",
      "torch.Size([1, 2476, 1024])\n",
      "torch.Size([1, 1098, 1024])\n",
      "torch.Size([1, 5131, 1024])\n",
      "torch.Size([1, 1491, 1024])\n",
      "torch.Size([1, 1268, 1024])\n",
      "torch.Size([1, 2350, 1024])\n",
      "torch.Size([1, 736, 1024])\n",
      "torch.Size([1, 6491, 1024])\n",
      "torch.Size([1, 2120, 1024])\n",
      "torch.Size([1, 1395, 1024])\n",
      "torch.Size([1, 1591, 1024])\n",
      "torch.Size([1, 3701, 1024])\n",
      "torch.Size([1, 2737, 1024])\n",
      "torch.Size([1, 4393, 1024])\n",
      "torch.Size([1, 1868, 1024])\n",
      "torch.Size([1, 1327, 1024])\n",
      "torch.Size([1, 3744, 1024])\n",
      "torch.Size([1, 2659, 1024])\n",
      "torch.Size([1, 1428, 1024])\n",
      "torch.Size([1, 1696, 1024])\n",
      "torch.Size([1, 1666, 1024])\n",
      "torch.Size([1, 2410, 1024])\n",
      "torch.Size([1, 1691, 1024])\n",
      "torch.Size([1, 2867, 1024])\n",
      "torch.Size([1, 3750, 1024])\n",
      "torch.Size([1, 2668, 1024])\n",
      "torch.Size([1, 1907, 1024])\n",
      "torch.Size([1, 2369, 1024])\n",
      "torch.Size([1, 1709, 1024])\n",
      "torch.Size([1, 305, 1024])\n",
      "torch.Size([1, 2801, 1024])\n",
      "torch.Size([1, 1485, 1024])\n",
      "torch.Size([1, 8347, 1024])\n",
      "torch.Size([1, 326, 1024])\n",
      "torch.Size([1, 1570, 1024])\n",
      "torch.Size([1, 3828, 1024])\n",
      "torch.Size([1, 1883, 1024])\n",
      "torch.Size([1, 2625, 1024])\n",
      "torch.Size([1, 2179, 1024])\n",
      "torch.Size([1, 5411, 1024])\n",
      "torch.Size([1, 1635, 1024])\n",
      "torch.Size([1, 3594, 1024])\n",
      "torch.Size([1, 3570, 1024])\n",
      "torch.Size([1, 1589, 1024])\n",
      "torch.Size([1, 1295, 1024])\n",
      "torch.Size([1, 2948, 1024])\n",
      "torch.Size([1, 584, 1024])\n",
      "torch.Size([1, 3007, 1024])\n",
      "torch.Size([1, 2165, 1024])\n",
      "torch.Size([1, 4270, 1024])\n",
      "torch.Size([1, 901, 1024])\n",
      "torch.Size([1, 3808, 1024])\n",
      "torch.Size([1, 2537, 1024])\n",
      "torch.Size([1, 4518, 1024])\n",
      "torch.Size([1, 1532, 1024])\n",
      "torch.Size([1, 1583, 1024])\n",
      "torch.Size([1, 2290, 1024])\n",
      "torch.Size([1, 1981, 1024])\n",
      "torch.Size([1, 2204, 1024])\n",
      "torch.Size([1, 5190, 1024])\n",
      "torch.Size([1, 1652, 1024])\n",
      "torch.Size([1, 1665, 1024])\n",
      "torch.Size([1, 2753, 1024])\n",
      "torch.Size([1, 1936, 1024])\n",
      "torch.Size([1, 1911, 1024])\n",
      "torch.Size([1, 4311, 1024])\n",
      "torch.Size([1, 4199, 1024])\n",
      "torch.Size([1, 4197, 1024])\n",
      "torch.Size([1, 2061, 1024])\n",
      "torch.Size([1, 1390, 1024])\n",
      "torch.Size([1, 1477, 1024])\n",
      "torch.Size([1, 2099, 1024])\n",
      "torch.Size([1, 1653, 1024])\n",
      "torch.Size([1, 2794, 1024])\n",
      "torch.Size([1, 359, 1024])\n",
      "torch.Size([1, 1181, 1024])\n",
      "torch.Size([1, 1780, 1024])\n",
      "torch.Size([1, 1949, 1024])\n",
      "torch.Size([1, 1078, 1024])\n",
      "torch.Size([1, 1436, 1024])\n",
      "torch.Size([1, 3071, 1024])\n",
      "torch.Size([1, 3088, 1024])\n",
      "torch.Size([1, 4855, 1024])\n",
      "torch.Size([1, 3097, 1024])\n",
      "torch.Size([1, 1527, 1024])\n",
      "torch.Size([1, 8555, 1024])\n",
      "torch.Size([1, 4350, 1024])\n",
      "torch.Size([1, 3458, 1024])\n",
      "torch.Size([1, 5048, 1024])\n",
      "torch.Size([1, 2468, 1024])\n",
      "torch.Size([1, 2176, 1024])\n",
      "torch.Size([1, 5457, 1024])\n",
      "torch.Size([1, 1370, 1024])\n",
      "torch.Size([1, 1500, 1024])\n",
      "torch.Size([1, 932, 1024])\n",
      "torch.Size([1, 1671, 1024])\n",
      "torch.Size([1, 1252, 1024])\n",
      "torch.Size([1, 2914, 1024])\n",
      "torch.Size([1, 1986, 1024])\n",
      "torch.Size([1, 5888, 1024])\n",
      "torch.Size([1, 4706, 1024])\n",
      "torch.Size([1, 3435, 1024])\n",
      "torch.Size([1, 1311, 1024])\n",
      "torch.Size([1, 1737, 1024])\n",
      "torch.Size([1, 1948, 1024])\n",
      "torch.Size([1, 3298, 1024])\n",
      "torch.Size([1, 2528, 1024])\n",
      "torch.Size([1, 1711, 1024])\n",
      "torch.Size([1, 4050, 1024])\n",
      "torch.Size([1, 7180, 1024])\n",
      "torch.Size([1, 1565, 1024])\n",
      "torch.Size([1, 1877, 1024])\n",
      "torch.Size([1, 5857, 1024])\n",
      "torch.Size([1, 1617, 1024])\n",
      "torch.Size([1, 1583, 1024])\n",
      "torch.Size([1, 2579, 1024])\n",
      "torch.Size([1, 1544, 1024])\n",
      "torch.Size([1, 1538, 1024])\n",
      "torch.Size([1, 3440, 1024])\n",
      "torch.Size([1, 1716, 1024])\n",
      "torch.Size([1, 6048, 1024])\n",
      "torch.Size([1, 5564, 1024])\n",
      "torch.Size([1, 1511, 1024])\n",
      "torch.Size([1, 3680, 1024])\n",
      "torch.Size([1, 3297, 1024])\n",
      "torch.Size([1, 1195, 1024])\n",
      "torch.Size([1, 448, 1024])\n",
      "torch.Size([1, 2925, 1024])\n",
      "torch.Size([1, 3155, 1024])\n",
      "torch.Size([1, 1661, 1024])\n",
      "torch.Size([1, 396, 1024])\n",
      "torch.Size([1, 3817, 1024])\n",
      "torch.Size([1, 1208, 1024])\n",
      "torch.Size([1, 1578, 1024])\n",
      "torch.Size([1, 3381, 1024])\n",
      "torch.Size([1, 1758, 1024])\n",
      "torch.Size([1, 1856, 1024])\n",
      "torch.Size([1, 1197, 1024])\n",
      "torch.Size([1, 2607, 1024])\n",
      "torch.Size([1, 5487, 1024])\n",
      "torch.Size([1, 1575, 1024])\n",
      "torch.Size([1, 2909, 1024])\n",
      "torch.Size([1, 1273, 1024])\n",
      "torch.Size([1, 465, 1024])\n",
      "torch.Size([1, 2012, 1024])\n",
      "torch.Size([1, 1609, 1024])\n",
      "torch.Size([1, 2299, 1024])\n",
      "torch.Size([1, 1211, 1024])\n",
      "torch.Size([1, 1790, 1024])\n",
      "torch.Size([1, 2503, 1024])\n",
      "torch.Size([1, 2217, 1024])\n",
      "torch.Size([1, 6075, 1024])\n",
      "torch.Size([1, 2204, 1024])\n",
      "torch.Size([1, 1514, 1024])\n",
      "torch.Size([1, 1704, 1024])\n",
      "torch.Size([1, 3744, 1024])\n",
      "torch.Size([1, 3874, 1024])\n",
      "torch.Size([1, 5869, 1024])\n",
      "torch.Size([1, 1594, 1024])\n",
      "torch.Size([1, 4981, 1024])\n",
      "torch.Size([1, 1397, 1024])\n",
      "torch.Size([1, 1615, 1024])\n",
      "torch.Size([1, 1287, 1024])\n",
      "torch.Size([1, 2890, 1024])\n",
      "torch.Size([1, 3292, 1024])\n",
      "torch.Size([1, 2013, 1024])\n",
      "torch.Size([1, 2272, 1024])\n",
      "torch.Size([1, 3845, 1024])\n",
      "torch.Size([1, 1092, 1024])\n",
      "torch.Size([1, 1818, 1024])\n",
      "torch.Size([1, 3181, 1024])\n",
      "torch.Size([1, 3038, 1024])\n",
      "torch.Size([1, 3322, 1024])\n",
      "torch.Size([1, 3291, 1024])\n",
      "torch.Size([1, 1536, 1024])\n",
      "torch.Size([1, 1815, 1024])\n",
      "torch.Size([1, 2797, 1024])\n",
      "torch.Size([1, 2821, 1024])\n",
      "torch.Size([1, 2002, 1024])\n",
      "torch.Size([1, 1731, 1024])\n",
      "torch.Size([1, 3040, 1024])\n",
      "torch.Size([1, 2908, 1024])\n",
      "torch.Size([1, 1422, 1024])\n",
      "torch.Size([1, 1883, 1024])\n",
      "torch.Size([1, 2363, 1024])\n",
      "torch.Size([1, 1164, 1024])\n",
      "torch.Size([1, 4636, 1024])\n",
      "torch.Size([1, 1304, 1024])\n",
      "torch.Size([1, 2139, 1024])\n",
      "torch.Size([1, 1580, 1024])\n",
      "torch.Size([1, 2943, 1024])\n",
      "torch.Size([1, 1152, 1024])\n",
      "torch.Size([1, 3483, 1024])\n",
      "torch.Size([1, 3941, 1024])\n",
      "torch.Size([1, 1442, 1024])\n",
      "torch.Size([1, 1249, 1024])\n",
      "torch.Size([1, 2203, 1024])\n",
      "torch.Size([1, 7059, 1024])\n",
      "torch.Size([1, 1428, 1024])\n",
      "torch.Size([1, 2551, 1024])\n",
      "torch.Size([1, 5836, 1024])\n",
      "torch.Size([1, 2891, 1024])\n",
      "torch.Size([1, 7475, 1024])\n",
      "torch.Size([1, 3849, 1024])\n",
      "torch.Size([1, 2630, 1024])\n",
      "torch.Size([1, 3253, 1024])\n",
      "torch.Size([1, 3096, 1024])\n",
      "torch.Size([1, 2190, 1024])\n",
      "torch.Size([1, 3399, 1024])\n",
      "torch.Size([1, 3159, 1024])\n",
      "torch.Size([1, 1641, 1024])\n",
      "torch.Size([1, 3718, 1024])\n",
      "torch.Size([1, 2280, 1024])\n",
      "torch.Size([1, 7260, 1024])\n",
      "torch.Size([1, 3243, 1024])\n",
      "torch.Size([1, 4198, 1024])\n",
      "torch.Size([1, 4158, 1024])\n",
      "torch.Size([1, 2010, 1024])\n",
      "torch.Size([1, 1407, 1024])\n",
      "torch.Size([1, 8462, 1024])\n",
      "torch.Size([1, 1721, 1024])\n",
      "torch.Size([1, 1874, 1024])\n",
      "torch.Size([1, 5558, 1024])\n",
      "torch.Size([1, 4165, 1024])\n",
      "torch.Size([1, 5134, 1024])\n",
      "torch.Size([1, 2270, 1024])\n",
      "torch.Size([1, 5719, 1024])\n",
      "torch.Size([1, 1041, 1024])\n",
      "torch.Size([1, 1807, 1024])\n",
      "torch.Size([1, 284, 1024])\n",
      "torch.Size([1, 1467, 1024])\n",
      "torch.Size([1, 3334, 1024])\n",
      "torch.Size([1, 2833, 1024])\n",
      "torch.Size([1, 4211, 1024])\n",
      "torch.Size([1, 3894, 1024])\n",
      "torch.Size([1, 1430, 1024])\n",
      "torch.Size([1, 1692, 1024])\n",
      "torch.Size([1, 292, 1024])\n",
      "torch.Size([1, 1552, 1024])\n",
      "torch.Size([1, 440, 1024])\n",
      "torch.Size([1, 1340, 1024])\n",
      "torch.Size([1, 1909, 1024])\n",
      "torch.Size([1, 3188, 1024])\n",
      "torch.Size([1, 6002, 1024])\n",
      "torch.Size([1, 1926, 1024])\n",
      "torch.Size([1, 5573, 1024])\n",
      "torch.Size([1, 4308, 1024])\n",
      "torch.Size([1, 3691, 1024])\n",
      "torch.Size([1, 1586, 1024])\n",
      "torch.Size([1, 2247, 1024])\n",
      "torch.Size([1, 4742, 1024])\n",
      "torch.Size([1, 5104, 1024])\n",
      "torch.Size([1, 676, 1024])\n",
      "torch.Size([1, 4654, 1024])\n",
      "torch.Size([1, 1575, 1024])\n",
      "torch.Size([1, 2206, 1024])\n",
      "torch.Size([1, 3469, 1024])\n",
      "torch.Size([1, 4022, 1024])\n",
      "torch.Size([1, 1526, 1024])\n",
      "torch.Size([1, 1768, 1024])\n",
      "torch.Size([1, 4199, 1024])\n",
      "torch.Size([1, 5827, 1024])\n",
      "torch.Size([1, 363, 1024])\n",
      "torch.Size([1, 1769, 1024])\n",
      "torch.Size([1, 790, 1024])\n",
      "torch.Size([1, 1090, 1024])\n",
      "torch.Size([1, 1666, 1024])\n",
      "torch.Size([1, 1627, 1024])\n",
      "torch.Size([1, 3768, 1024])\n",
      "torch.Size([1, 3235, 1024])\n",
      "torch.Size([1, 3141, 1024])\n",
      "torch.Size([1, 1146, 1024])\n",
      "torch.Size([1, 565, 1024])\n",
      "torch.Size([1, 5137, 1024])\n",
      "torch.Size([1, 1553, 1024])\n",
      "torch.Size([1, 2066, 1024])\n",
      "torch.Size([1, 3743, 1024])\n",
      "torch.Size([1, 2189, 1024])\n",
      "torch.Size([1, 2196, 1024])\n",
      "torch.Size([1, 1897, 1024])\n",
      "torch.Size([1, 1368, 1024])\n",
      "torch.Size([1, 2726, 1024])\n",
      "torch.Size([1, 6058, 1024])\n",
      "torch.Size([1, 2537, 1024])\n",
      "torch.Size([1, 1483, 1024])\n",
      "torch.Size([1, 2539, 1024])\n",
      "torch.Size([1, 1397, 1024])\n",
      "torch.Size([1, 3502, 1024])\n",
      "torch.Size([1, 4675, 1024])\n",
      "torch.Size([1, 3808, 1024])\n",
      "torch.Size([1, 2536, 1024])\n",
      "torch.Size([1, 4427, 1024])\n",
      "torch.Size([1, 1852, 1024])\n",
      "torch.Size([1, 1595, 1024])\n",
      "torch.Size([1, 3766, 1024])\n",
      "torch.Size([1, 4148, 1024])\n",
      "torch.Size([1, 2109, 1024])\n",
      "torch.Size([1, 5329, 1024])\n",
      "torch.Size([1, 1386, 1024])\n",
      "torch.Size([1, 3343, 1024])\n",
      "torch.Size([1, 3349, 1024])\n",
      "torch.Size([1, 1444, 1024])\n",
      "torch.Size([1, 2219, 1024])\n",
      "torch.Size([1, 1445, 1024])\n",
      "torch.Size([1, 1931, 1024])\n",
      "torch.Size([1, 1388, 1024])\n",
      "torch.Size([1, 1990, 1024])\n",
      "torch.Size([1, 2008, 1024])\n",
      "torch.Size([1, 2101, 1024])\n",
      "torch.Size([1, 2020, 1024])\n",
      "torch.Size([1, 2403, 1024])\n",
      "torch.Size([1, 376, 1024])\n",
      "torch.Size([1, 2424, 1024])\n",
      "torch.Size([1, 1720, 1024])\n",
      "torch.Size([1, 2174, 1024])\n",
      "torch.Size([1, 3197, 1024])\n",
      "torch.Size([1, 4339, 1024])\n",
      "torch.Size([1, 4641, 1024])\n",
      "torch.Size([1, 5257, 1024])\n",
      "torch.Size([1, 810, 1024])\n",
      "torch.Size([1, 1317, 1024])\n",
      "torch.Size([1, 1635, 1024])\n",
      "torch.Size([1, 3161, 1024])\n",
      "torch.Size([1, 3172, 1024])\n",
      "torch.Size([1, 416, 1024])\n",
      "torch.Size([1, 1585, 1024])\n",
      "torch.Size([1, 5228, 1024])\n",
      "torch.Size([1, 2350, 1024])\n",
      "torch.Size([1, 5007, 1024])\n",
      "torch.Size([1, 1627, 1024])\n",
      "torch.Size([1, 3243, 1024])\n",
      "torch.Size([1, 3371, 1024])\n",
      "torch.Size([1, 1832, 1024])\n",
      "torch.Size([1, 755, 1024])\n",
      "torch.Size([1, 1887, 1024])\n",
      "torch.Size([1, 3324, 1024])\n",
      "torch.Size([1, 2103, 1024])\n",
      "torch.Size([1, 1314, 1024])\n",
      "torch.Size([1, 2465, 1024])\n",
      "torch.Size([1, 3345, 1024])\n",
      "torch.Size([1, 229, 1024])\n",
      "torch.Size([1, 2247, 1024])\n",
      "torch.Size([1, 1756, 1024])\n",
      "torch.Size([1, 2017, 1024])\n",
      "torch.Size([1, 253, 1024])\n",
      "torch.Size([1, 4754, 1024])\n",
      "torch.Size([1, 1677, 1024])\n",
      "torch.Size([1, 3064, 1024])\n",
      "torch.Size([1, 1981, 1024])\n",
      "torch.Size([1, 5780, 1024])\n",
      "torch.Size([1, 1349, 1024])\n",
      "torch.Size([1, 3128, 1024])\n",
      "torch.Size([1, 3187, 1024])\n",
      "torch.Size([1, 2053, 1024])\n",
      "torch.Size([1, 4185, 1024])\n",
      "torch.Size([1, 1302, 1024])\n",
      "torch.Size([1, 2809, 1024])\n",
      "torch.Size([1, 4184, 1024])\n",
      "torch.Size([1, 1746, 1024])\n",
      "torch.Size([1, 2258, 1024])\n",
      "torch.Size([1, 3034, 1024])\n",
      "torch.Size([1, 3079, 1024])\n",
      "torch.Size([1, 1862, 1024])\n",
      "torch.Size([1, 6317, 1024])\n",
      "torch.Size([1, 2887, 1024])\n",
      "torch.Size([1, 1474, 1024])\n",
      "torch.Size([1, 1778, 1024])\n",
      "torch.Size([1, 5453, 1024])\n",
      "torch.Size([1, 2753, 1024])\n",
      "torch.Size([1, 1683, 1024])\n",
      "torch.Size([1, 289, 1024])\n",
      "torch.Size([1, 2294, 1024])\n",
      "torch.Size([1, 3429, 1024])\n",
      "torch.Size([1, 507, 1024])\n",
      "torch.Size([1, 2876, 1024])\n",
      "torch.Size([1, 2466, 1024])\n",
      "torch.Size([1, 2869, 1024])\n",
      "torch.Size([1, 1412, 1024])\n",
      "torch.Size([1, 3576, 1024])\n",
      "torch.Size([1, 1901, 1024])\n",
      "torch.Size([1, 4645, 1024])\n",
      "torch.Size([1, 2223, 1024])\n",
      "torch.Size([1, 3502, 1024])\n",
      "torch.Size([1, 1713, 1024])\n",
      "torch.Size([1, 5844, 1024])\n",
      "torch.Size([1, 4449, 1024])\n",
      "torch.Size([1, 4679, 1024])\n",
      "torch.Size([1, 1184, 1024])\n",
      "torch.Size([1, 2503, 1024])\n",
      "torch.Size([1, 2328, 1024])\n",
      "torch.Size([1, 2869, 1024])\n",
      "torch.Size([1, 4410, 1024])\n",
      "torch.Size([1, 2206, 1024])\n",
      "torch.Size([1, 1147, 1024])\n",
      "torch.Size([1, 3273, 1024])\n",
      "torch.Size([1, 6086, 1024])\n",
      "torch.Size([1, 2869, 1024])\n",
      "torch.Size([1, 1731, 1024])\n",
      "torch.Size([1, 1895, 1024])\n",
      "torch.Size([1, 1823, 1024])\n",
      "torch.Size([1, 2750, 1024])\n",
      "torch.Size([1, 3307, 1024])\n",
      "torch.Size([1, 1969, 1024])\n",
      "torch.Size([1, 2417, 1024])\n",
      "torch.Size([1, 3606, 1024])\n",
      "torch.Size([1, 3737, 1024])\n",
      "torch.Size([1, 3400, 1024])\n",
      "torch.Size([1, 3579, 1024])\n",
      "torch.Size([1, 1466, 1024])\n",
      "torch.Size([1, 3942, 1024])\n",
      "torch.Size([1, 1757, 1024])\n",
      "torch.Size([1, 815, 1024])\n",
      "torch.Size([1, 1605, 1024])\n",
      "torch.Size([1, 5730, 1024])\n",
      "torch.Size([1, 3612, 1024])\n",
      "torch.Size([1, 1650, 1024])\n",
      "torch.Size([1, 2280, 1024])\n",
      "torch.Size([1, 2293, 1024])\n",
      "torch.Size([1, 1871, 1024])\n",
      "torch.Size([1, 3750, 1024])\n",
      "torch.Size([1, 2641, 1024])\n",
      "torch.Size([1, 1605, 1024])\n",
      "torch.Size([1, 1484, 1024])\n",
      "torch.Size([1, 542, 1024])\n",
      "torch.Size([1, 1600, 1024])\n",
      "torch.Size([1, 1880, 1024])\n",
      "torch.Size([1, 2397, 1024])\n",
      "torch.Size([1, 4823, 1024])\n",
      "torch.Size([1, 4595, 1024])\n",
      "torch.Size([1, 1543, 1024])\n",
      "torch.Size([1, 1151, 1024])\n",
      "torch.Size([1, 1819, 1024])\n",
      "torch.Size([1, 1991, 1024])\n",
      "torch.Size([1, 2410, 1024])\n",
      "torch.Size([1, 628, 1024])\n",
      "torch.Size([1, 3107, 1024])\n",
      "torch.Size([1, 1468, 1024])\n",
      "torch.Size([1, 2170, 1024])\n",
      "torch.Size([1, 1377, 1024])\n",
      "torch.Size([1, 3456, 1024])\n",
      "torch.Size([1, 3355, 1024])\n",
      "torch.Size([1, 1072, 1024])\n",
      "torch.Size([1, 4311, 1024])\n",
      "torch.Size([1, 6040, 1024])\n",
      "torch.Size([1, 2194, 1024])\n",
      "torch.Size([1, 1243, 1024])\n",
      "torch.Size([1, 1897, 1024])\n",
      "torch.Size([1, 5302, 1024])\n",
      "torch.Size([1, 2300, 1024])\n",
      "torch.Size([1, 1833, 1024])\n",
      "torch.Size([1, 2171, 1024])\n",
      "torch.Size([1, 1114, 1024])\n",
      "torch.Size([1, 3377, 1024])\n",
      "torch.Size([1, 1963, 1024])\n",
      "torch.Size([1, 485, 1024])\n",
      "torch.Size([1, 3319, 1024])\n",
      "torch.Size([1, 4317, 1024])\n",
      "torch.Size([1, 3558, 1024])\n",
      "torch.Size([1, 1490, 1024])\n",
      "torch.Size([1, 386, 1024])\n",
      "torch.Size([1, 2981, 1024])\n",
      "torch.Size([1, 1289, 1024])\n",
      "torch.Size([1, 4370, 1024])\n",
      "torch.Size([1, 2959, 1024])\n",
      "torch.Size([1, 3421, 1024])\n",
      "torch.Size([1, 2590, 1024])\n",
      "torch.Size([1, 2730, 1024])\n",
      "torch.Size([1, 3882, 1024])\n",
      "torch.Size([1, 3581, 1024])\n",
      "torch.Size([1, 1503, 1024])\n",
      "torch.Size([1, 1131, 1024])\n",
      "torch.Size([1, 3260, 1024])\n",
      "torch.Size([1, 1263, 1024])\n",
      "torch.Size([1, 2620, 1024])\n",
      "torch.Size([1, 6605, 1024])\n",
      "torch.Size([1, 2119, 1024])\n",
      "torch.Size([1, 2841, 1024])\n",
      "torch.Size([1, 1160, 1024])\n",
      "torch.Size([1, 3883, 1024])\n",
      "torch.Size([1, 3256, 1024])\n",
      "torch.Size([1, 5255, 1024])\n",
      "torch.Size([1, 2621, 1024])\n",
      "torch.Size([1, 1676, 1024])\n",
      "torch.Size([1, 3164, 1024])\n",
      "torch.Size([1, 3157, 1024])\n",
      "torch.Size([1, 1483, 1024])\n",
      "torch.Size([1, 1749, 1024])\n",
      "torch.Size([1, 2467, 1024])\n",
      "torch.Size([1, 5750, 1024])\n",
      "torch.Size([1, 1217, 1024])\n",
      "torch.Size([1, 3935, 1024])\n",
      "torch.Size([1, 3288, 1024])\n",
      "torch.Size([1, 1878, 1024])\n",
      "torch.Size([1, 1692, 1024])\n",
      "torch.Size([1, 1376, 1024])\n",
      "torch.Size([1, 5547, 1024])\n",
      "torch.Size([1, 3609, 1024])\n",
      "torch.Size([1, 476, 1024])\n",
      "torch.Size([1, 2569, 1024])\n",
      "torch.Size([1, 5408, 1024])\n",
      "torch.Size([1, 252, 1024])\n",
      "torch.Size([1, 3777, 1024])\n",
      "torch.Size([1, 2403, 1024])\n",
      "torch.Size([1, 3837, 1024])\n",
      "torch.Size([1, 1907, 1024])\n",
      "torch.Size([1, 5962, 1024])\n",
      "torch.Size([1, 2276, 1024])\n",
      "torch.Size([1, 3289, 1024])\n",
      "torch.Size([1, 2843, 1024])\n",
      "torch.Size([1, 2604, 1024])\n",
      "torch.Size([1, 930, 1024])\n",
      "torch.Size([1, 1728, 1024])\n",
      "torch.Size([1, 2099, 1024])\n",
      "torch.Size([1, 6672, 1024])\n",
      "torch.Size([1, 2218, 1024])\n",
      "torch.Size([1, 615, 1024])\n",
      "torch.Size([1, 2663, 1024])\n",
      "torch.Size([1, 3127, 1024])\n",
      "torch.Size([1, 1723, 1024])\n",
      "torch.Size([1, 2515, 1024])\n",
      "torch.Size([1, 1600, 1024])\n",
      "torch.Size([1, 1505, 1024])\n",
      "torch.Size([1, 1491, 1024])\n",
      "torch.Size([1, 2698, 1024])\n",
      "torch.Size([1, 1263, 1024])\n",
      "torch.Size([1, 1812, 1024])\n",
      "torch.Size([1, 2857, 1024])\n",
      "torch.Size([1, 2332, 1024])\n",
      "torch.Size([1, 1333, 1024])\n",
      "torch.Size([1, 1667, 1024])\n",
      "torch.Size([1, 6744, 1024])\n",
      "torch.Size([1, 1504, 1024])\n",
      "torch.Size([1, 1344, 1024])\n",
      "torch.Size([1, 1720, 1024])\n",
      "torch.Size([1, 1627, 1024])\n",
      "torch.Size([1, 1332, 1024])\n",
      "torch.Size([1, 1116, 1024])\n",
      "torch.Size([1, 3456, 1024])\n",
      "torch.Size([1, 3036, 1024])\n",
      "torch.Size([1, 1550, 1024])\n",
      "torch.Size([1, 2167, 1024])\n",
      "torch.Size([1, 1254, 1024])\n",
      "torch.Size([1, 1319, 1024])\n",
      "torch.Size([1, 1939, 1024])\n",
      "torch.Size([1, 3380, 1024])\n",
      "torch.Size([1, 1376, 1024])\n",
      "torch.Size([1, 2187, 1024])\n",
      "torch.Size([1, 558, 1024])\n",
      "torch.Size([1, 1484, 1024])\n",
      "torch.Size([1, 1412, 1024])\n",
      "torch.Size([1, 1342, 1024])\n",
      "torch.Size([1, 1262, 1024])\n",
      "torch.Size([1, 3026, 1024])\n",
      "torch.Size([1, 1608, 1024])\n",
      "torch.Size([1, 2006, 1024])\n",
      "torch.Size([1, 1418, 1024])\n",
      "torch.Size([1, 2333, 1024])\n",
      "torch.Size([1, 2133, 1024])\n",
      "torch.Size([1, 2130, 1024])\n",
      "torch.Size([1, 2503, 1024])\n",
      "torch.Size([1, 1142, 1024])\n",
      "torch.Size([1, 4319, 1024])\n",
      "torch.Size([1, 1922, 1024])\n",
      "torch.Size([1, 4989, 1024])\n",
      "torch.Size([1, 1555, 1024])\n",
      "torch.Size([1, 2216, 1024])\n",
      "torch.Size([1, 1884, 1024])\n",
      "torch.Size([1, 1521, 1024])\n",
      "torch.Size([1, 4872, 1024])\n",
      "torch.Size([1, 2134, 1024])\n",
      "torch.Size([1, 1685, 1024])\n",
      "torch.Size([1, 823, 1024])\n",
      "torch.Size([1, 2019, 1024])\n",
      "torch.Size([1, 1515, 1024])\n",
      "torch.Size([1, 634, 1024])\n",
      "torch.Size([1, 1964, 1024])\n",
      "torch.Size([1, 1413, 1024])\n",
      "torch.Size([1, 2108, 1024])\n",
      "torch.Size([1, 1958, 1024])\n",
      "torch.Size([1, 2338, 1024])\n",
      "torch.Size([1, 4780, 1024])\n",
      "torch.Size([1, 2511, 1024])\n",
      "torch.Size([1, 1361, 1024])\n",
      "torch.Size([1, 821, 1024])\n",
      "torch.Size([1, 3562, 1024])\n",
      "torch.Size([1, 2170, 1024])\n",
      "torch.Size([1, 2864, 1024])\n",
      "torch.Size([1, 1282, 1024])\n",
      "torch.Size([1, 1390, 1024])\n",
      "torch.Size([1, 3019, 1024])\n",
      "torch.Size([1, 3066, 1024])\n",
      "torch.Size([1, 826, 1024])\n",
      "torch.Size([1, 1802, 1024])\n",
      "torch.Size([1, 1335, 1024])\n",
      "torch.Size([1, 1347, 1024])\n",
      "torch.Size([1, 4670, 1024])\n",
      "torch.Size([1, 598, 1024])\n",
      "torch.Size([1, 1647, 1024])\n",
      "torch.Size([1, 3074, 1024])\n",
      "torch.Size([1, 566, 1024])\n",
      "torch.Size([1, 2585, 1024])\n",
      "torch.Size([1, 1997, 1024])\n",
      "torch.Size([1, 3600, 1024])\n",
      "torch.Size([1, 1468, 1024])\n",
      "torch.Size([1, 5619, 1024])\n",
      "torch.Size([1, 1253, 1024])\n",
      "torch.Size([1, 2266, 1024])\n",
      "torch.Size([1, 4353, 1024])\n",
      "torch.Size([1, 1124, 1024])\n",
      "torch.Size([1, 5151, 1024])\n",
      "torch.Size([1, 1711, 1024])\n",
      "torch.Size([1, 2866, 1024])\n",
      "torch.Size([1, 1205, 1024])\n",
      "torch.Size([1, 575, 1024])\n",
      "torch.Size([1, 1435, 1024])\n",
      "torch.Size([1, 1396, 1024])\n",
      "torch.Size([1, 2109, 1024])\n",
      "torch.Size([1, 1666, 1024])\n",
      "torch.Size([1, 1542, 1024])\n",
      "torch.Size([1, 2984, 1024])\n",
      "torch.Size([1, 2390, 1024])\n",
      "torch.Size([1, 2277, 1024])\n",
      "torch.Size([1, 1974, 1024])\n",
      "torch.Size([1, 1760, 1024])\n",
      "torch.Size([1, 1742, 1024])\n",
      "torch.Size([1, 1668, 1024])\n",
      "torch.Size([1, 2867, 1024])\n",
      "torch.Size([1, 1347, 1024])\n",
      "torch.Size([1, 2222, 1024])\n",
      "torch.Size([1, 4950, 1024])\n",
      "torch.Size([1, 1349, 1024])\n",
      "torch.Size([1, 4621, 1024])\n",
      "torch.Size([1, 2760, 1024])\n",
      "torch.Size([1, 1803, 1024])\n",
      "torch.Size([1, 1640, 1024])\n",
      "torch.Size([1, 1951, 1024])\n",
      "torch.Size([1, 2047, 1024])\n",
      "torch.Size([1, 2554, 1024])\n",
      "torch.Size([1, 4937, 1024])\n",
      "torch.Size([1, 5060, 1024])\n",
      "torch.Size([1, 6059, 1024])\n",
      "torch.Size([1, 1660, 1024])\n",
      "torch.Size([1, 946, 1024])\n",
      "torch.Size([1, 4935, 1024])\n",
      "torch.Size([1, 2534, 1024])\n",
      "torch.Size([1, 927, 1024])\n",
      "torch.Size([1, 2450, 1024])\n",
      "torch.Size([1, 3604, 1024])\n",
      "torch.Size([1, 6255, 1024])\n",
      "torch.Size([1, 1448, 1024])\n",
      "torch.Size([1, 1839, 1024])\n",
      "torch.Size([1, 1905, 1024])\n",
      "torch.Size([1, 4825, 1024])\n",
      "torch.Size([1, 2390, 1024])\n",
      "torch.Size([1, 5573, 1024])\n",
      "torch.Size([1, 1093, 1024])\n",
      "torch.Size([1, 6328, 1024])\n",
      "torch.Size([1, 1467, 1024])\n",
      "torch.Size([1, 4721, 1024])\n",
      "torch.Size([1, 776, 1024])\n",
      "torch.Size([1, 1808, 1024])\n",
      "torch.Size([1, 1158, 1024])\n",
      "torch.Size([1, 2935, 1024])\n",
      "torch.Size([1, 3859, 1024])\n",
      "torch.Size([1, 1425, 1024])\n",
      "torch.Size([1, 1487, 1024])\n",
      "torch.Size([1, 3038, 1024])\n",
      "torch.Size([1, 1343, 1024])\n",
      "torch.Size([1, 3268, 1024])\n",
      "torch.Size([1, 447, 1024])\n",
      "torch.Size([1, 1155, 1024])\n",
      "torch.Size([1, 2613, 1024])\n",
      "torch.Size([1, 2097, 1024])\n",
      "torch.Size([1, 1569, 1024])\n",
      "torch.Size([1, 1462, 1024])\n",
      "torch.Size([1, 1847, 1024])\n",
      "torch.Size([1, 1961, 1024])\n",
      "torch.Size([1, 1497, 1024])\n",
      "torch.Size([1, 1717, 1024])\n",
      "torch.Size([1, 5866, 1024])\n",
      "torch.Size([1, 1821, 1024])\n",
      "torch.Size([1, 4255, 1024])\n",
      "torch.Size([1, 1759, 1024])\n",
      "torch.Size([1, 2789, 1024])\n",
      "torch.Size([1, 1542, 1024])\n",
      "torch.Size([1, 1367, 1024])\n",
      "torch.Size([1, 1030, 1024])\n",
      "torch.Size([1, 1638, 1024])\n",
      "torch.Size([1, 2166, 1024])\n",
      "torch.Size([1, 2529, 1024])\n",
      "torch.Size([1, 534, 1024])\n",
      "torch.Size([1, 5194, 1024])\n",
      "torch.Size([1, 5292, 1024])\n",
      "torch.Size([1, 1234, 1024])\n",
      "torch.Size([1, 1638, 1024])\n",
      "torch.Size([1, 4561, 1024])\n",
      "torch.Size([1, 6876, 1024])\n",
      "torch.Size([1, 1929, 1024])\n",
      "torch.Size([1, 1554, 1024])\n",
      "torch.Size([1, 1795, 1024])\n",
      "torch.Size([1, 4032, 1024])\n",
      "torch.Size([1, 3305, 1024])\n",
      "torch.Size([1, 2090, 1024])\n",
      "torch.Size([1, 2744, 1024])\n",
      "torch.Size([1, 3263, 1024])\n",
      "torch.Size([1, 3945, 1024])\n",
      "torch.Size([1, 3477, 1024])\n",
      "torch.Size([1, 984, 1024])\n",
      "torch.Size([1, 3765, 1024])\n",
      "torch.Size([1, 3772, 1024])\n",
      "torch.Size([1, 1238, 1024])\n",
      "torch.Size([1, 2701, 1024])\n",
      "torch.Size([1, 1683, 1024])\n",
      "torch.Size([1, 714, 1024])\n",
      "torch.Size([1, 1751, 1024])\n",
      "torch.Size([1, 7827, 1024])\n",
      "torch.Size([1, 903, 1024])\n",
      "torch.Size([1, 2478, 1024])\n",
      "torch.Size([1, 6840, 1024])\n",
      "torch.Size([1, 1686, 1024])\n",
      "torch.Size([1, 1179, 1024])\n",
      "torch.Size([1, 2049, 1024])\n",
      "torch.Size([1, 4068, 1024])\n",
      "torch.Size([1, 1134, 1024])\n",
      "torch.Size([1, 1153, 1024])\n",
      "torch.Size([1, 2544, 1024])\n",
      "torch.Size([1, 1407, 1024])\n",
      "torch.Size([1, 994, 1024])\n",
      "torch.Size([1, 6098, 1024])\n",
      "torch.Size([1, 1462, 1024])\n",
      "torch.Size([1, 2675, 1024])\n",
      "torch.Size([1, 2149, 1024])\n",
      "torch.Size([1, 3229, 1024])\n",
      "torch.Size([1, 1915, 1024])\n",
      "torch.Size([1, 2935, 1024])\n",
      "torch.Size([1, 1511, 1024])\n",
      "torch.Size([1, 1650, 1024])\n",
      "torch.Size([1, 2556, 1024])\n",
      "torch.Size([1, 5807, 1024])\n",
      "torch.Size([1, 681, 1024])\n",
      "torch.Size([1, 2715, 1024])\n",
      "torch.Size([1, 1672, 1024])\n",
      "torch.Size([1, 3112, 1024])\n",
      "torch.Size([1, 1468, 1024])\n",
      "torch.Size([1, 2712, 1024])\n",
      "torch.Size([1, 3214, 1024])\n",
      "torch.Size([1, 2751, 1024])\n",
      "torch.Size([1, 1553, 1024])\n",
      "torch.Size([1, 1019, 1024])\n",
      "torch.Size([1, 1504, 1024])\n",
      "torch.Size([1, 1923, 1024])\n",
      "torch.Size([1, 5314, 1024])\n",
      "torch.Size([1, 2694, 1024])\n",
      "torch.Size([1, 5564, 1024])\n",
      "torch.Size([1, 1650, 1024])\n",
      "torch.Size([1, 1247, 1024])\n",
      "torch.Size([1, 2828, 1024])\n",
      "torch.Size([1, 2444, 1024])\n",
      "torch.Size([1, 2821, 1024])\n",
      "torch.Size([1, 3227, 1024])\n",
      "torch.Size([1, 1634, 1024])\n",
      "torch.Size([1, 1284, 1024])\n",
      "torch.Size([1, 2861, 1024])\n",
      "torch.Size([1, 2904, 1024])\n",
      "torch.Size([1, 1296, 1024])\n",
      "torch.Size([1, 1877, 1024])\n",
      "torch.Size([1, 4742, 1024])\n",
      "torch.Size([1, 1284, 1024])\n",
      "torch.Size([1, 5172, 1024])\n",
      "torch.Size([1, 2631, 1024])\n",
      "torch.Size([1, 1183, 1024])\n",
      "torch.Size([1, 2681, 1024])\n",
      "torch.Size([1, 2972, 1024])\n",
      "torch.Size([1, 326, 1024])\n",
      "torch.Size([1, 2589, 1024])\n",
      "torch.Size([1, 1583, 1024])\n",
      "torch.Size([1, 854, 1024])\n",
      "torch.Size([1, 2023, 1024])\n",
      "torch.Size([1, 1421, 1024])\n",
      "torch.Size([1, 2144, 1024])\n",
      "torch.Size([1, 1276, 1024])\n",
      "torch.Size([1, 379, 1024])\n",
      "torch.Size([1, 1943, 1024])\n",
      "torch.Size([1, 3988, 1024])\n",
      "torch.Size([1, 2315, 1024])\n",
      "torch.Size([1, 1247, 1024])\n",
      "torch.Size([1, 4478, 1024])\n",
      "torch.Size([1, 6845, 1024])\n",
      "torch.Size([1, 1930, 1024])\n",
      "torch.Size([1, 596, 1024])\n",
      "torch.Size([1, 2243, 1024])\n",
      "torch.Size([1, 3356, 1024])\n",
      "torch.Size([1, 1642, 1024])\n",
      "torch.Size([1, 2150, 1024])\n",
      "torch.Size([1, 1272, 1024])\n",
      "torch.Size([1, 1242, 1024])\n",
      "torch.Size([1, 1489, 1024])\n",
      "torch.Size([1, 958, 1024])\n",
      "torch.Size([1, 2113, 1024])\n",
      "torch.Size([1, 1618, 1024])\n",
      "torch.Size([1, 2297, 1024])\n",
      "torch.Size([1, 582, 1024])\n",
      "torch.Size([1, 3889, 1024])\n",
      "torch.Size([1, 2226, 1024])\n",
      "torch.Size([1, 1578, 1024])\n",
      "torch.Size([1, 2031, 1024])\n",
      "torch.Size([1, 2131, 1024])\n",
      "torch.Size([1, 1585, 1024])\n",
      "torch.Size([1, 1083, 1024])\n",
      "torch.Size([1, 1767, 1024])\n",
      "torch.Size([1, 1808, 1024])\n",
      "torch.Size([1, 1691, 1024])\n",
      "torch.Size([1, 3301, 1024])\n",
      "torch.Size([1, 2828, 1024])\n",
      "torch.Size([1, 498, 1024])\n",
      "torch.Size([1, 4409, 1024])\n",
      "torch.Size([1, 4100, 1024])\n",
      "torch.Size([1, 4267, 1024])\n",
      "torch.Size([1, 3636, 1024])\n",
      "torch.Size([1, 1555, 1024])\n",
      "torch.Size([1, 1827, 1024])\n",
      "torch.Size([1, 2112, 1024])\n",
      "torch.Size([1, 3297, 1024])\n",
      "torch.Size([1, 4097, 1024])\n",
      "torch.Size([1, 5803, 1024])\n",
      "torch.Size([1, 5396, 1024])\n",
      "torch.Size([1, 3571, 1024])\n",
      "torch.Size([1, 1761, 1024])\n",
      "torch.Size([1, 3918, 1024])\n",
      "torch.Size([1, 3819, 1024])\n",
      "torch.Size([1, 4699, 1024])\n",
      "torch.Size([1, 1813, 1024])\n",
      "torch.Size([1, 5240, 1024])\n",
      "torch.Size([1, 1217, 1024])\n",
      "torch.Size([1, 2013, 1024])\n",
      "torch.Size([1, 6691, 1024])\n",
      "torch.Size([1, 3379, 1024])\n",
      "torch.Size([1, 2667, 1024])\n",
      "torch.Size([1, 1624, 1024])\n",
      "torch.Size([1, 5551, 1024])\n",
      "torch.Size([1, 4000, 1024])\n",
      "torch.Size([1, 5654, 1024])\n",
      "torch.Size([1, 1699, 1024])\n",
      "torch.Size([1, 3027, 1024])\n",
      "torch.Size([1, 1491, 1024])\n",
      "torch.Size([1, 6123, 1024])\n",
      "torch.Size([1, 732, 1024])\n",
      "torch.Size([1, 2458, 1024])\n",
      "torch.Size([1, 4329, 1024])\n",
      "torch.Size([1, 748, 1024])\n",
      "torch.Size([1, 1572, 1024])\n",
      "torch.Size([1, 2434, 1024])\n",
      "torch.Size([1, 1214, 1024])\n",
      "torch.Size([1, 4062, 1024])\n",
      "torch.Size([1, 1762, 1024])\n",
      "torch.Size([1, 2484, 1024])\n",
      "torch.Size([1, 2426, 1024])\n",
      "torch.Size([1, 1716, 1024])\n",
      "torch.Size([1, 3946, 1024])\n",
      "torch.Size([1, 2535, 1024])\n",
      "torch.Size([1, 2684, 1024])\n",
      "torch.Size([1, 953, 1024])\n",
      "torch.Size([1, 3809, 1024])\n",
      "torch.Size([1, 1222, 1024])\n",
      "torch.Size([1, 1994, 1024])\n",
      "torch.Size([1, 481, 1024])\n",
      "torch.Size([1, 2822, 1024])\n",
      "torch.Size([1, 3054, 1024])\n",
      "torch.Size([1, 3414, 1024])\n",
      "torch.Size([1, 1777, 1024])\n",
      "torch.Size([1, 4792, 1024])\n",
      "torch.Size([1, 2051, 1024])\n",
      "torch.Size([1, 4743, 1024])\n",
      "torch.Size([1, 1764, 1024])\n",
      "torch.Size([1, 1746, 1024])\n",
      "torch.Size([1, 1875, 1024])\n",
      "torch.Size([1, 1874, 1024])\n",
      "torch.Size([1, 1638, 1024])\n",
      "torch.Size([1, 3496, 1024])\n",
      "torch.Size([1, 6836, 1024])\n",
      "torch.Size([1, 1885, 1024])\n",
      "torch.Size([1, 647, 1024])\n",
      "torch.Size([1, 1256, 1024])\n",
      "torch.Size([1, 3211, 1024])\n",
      "torch.Size([1, 1209, 1024])\n",
      "torch.Size([1, 4399, 1024])\n",
      "torch.Size([1, 3166, 1024])\n",
      "torch.Size([1, 1222, 1024])\n",
      "torch.Size([1, 3054, 1024])\n",
      "torch.Size([1, 6143, 1024])\n",
      "torch.Size([1, 2308, 1024])\n",
      "torch.Size([1, 6104, 1024])\n",
      "torch.Size([1, 7758, 1024])\n",
      "torch.Size([1, 1537, 1024])\n",
      "torch.Size([1, 6660, 1024])\n",
      "torch.Size([1, 1679, 1024])\n",
      "torch.Size([1, 4831, 1024])\n",
      "torch.Size([1, 1596, 1024])\n",
      "torch.Size([1, 2660, 1024])\n",
      "torch.Size([1, 1559, 1024])\n",
      "torch.Size([1, 5034, 1024])\n",
      "torch.Size([1, 2014, 1024])\n",
      "torch.Size([1, 1600, 1024])\n",
      "torch.Size([1, 2906, 1024])\n",
      "torch.Size([1, 1894, 1024])\n",
      "torch.Size([1, 1470, 1024])\n",
      "torch.Size([1, 1150, 1024])\n",
      "torch.Size([1, 2007, 1024])\n",
      "torch.Size([1, 2285, 1024])\n",
      "torch.Size([1, 3301, 1024])\n",
      "torch.Size([1, 3988, 1024])\n",
      "torch.Size([1, 4853, 1024])\n",
      "torch.Size([1, 2795, 1024])\n",
      "torch.Size([1, 1287, 1024])\n",
      "torch.Size([1, 564, 1024])\n",
      "torch.Size([1, 1608, 1024])\n",
      "torch.Size([1, 7900, 1024])\n",
      "torch.Size([1, 1614, 1024])\n",
      "torch.Size([1, 8994, 1024])\n",
      "torch.Size([1, 1790, 1024])\n",
      "torch.Size([1, 1472, 1024])\n",
      "torch.Size([1, 1583, 1024])\n",
      "torch.Size([1, 1073, 1024])\n",
      "torch.Size([1, 4223, 1024])\n",
      "torch.Size([1, 3082, 1024])\n",
      "torch.Size([1, 1815, 1024])\n",
      "torch.Size([1, 2498, 1024])\n",
      "torch.Size([1, 2582, 1024])\n",
      "torch.Size([1, 1059, 1024])\n",
      "torch.Size([1, 4041, 1024])\n",
      "torch.Size([1, 5172, 1024])\n",
      "torch.Size([1, 1808, 1024])\n",
      "torch.Size([1, 3762, 1024])\n",
      "torch.Size([1, 1650, 1024])\n",
      "torch.Size([1, 1874, 1024])\n",
      "torch.Size([1, 2607, 1024])\n",
      "torch.Size([1, 4252, 1024])\n",
      "torch.Size([1, 492, 1024])\n",
      "torch.Size([1, 2177, 1024])\n",
      "torch.Size([1, 1956, 1024])\n",
      "torch.Size([1, 4118, 1024])\n",
      "torch.Size([1, 1452, 1024])\n",
      "torch.Size([1, 1917, 1024])\n",
      "torch.Size([1, 5934, 1024])\n",
      "torch.Size([1, 6363, 1024])\n",
      "torch.Size([1, 1946, 1024])\n",
      "torch.Size([1, 2537, 1024])\n",
      "torch.Size([1, 2842, 1024])\n",
      "torch.Size([1, 3764, 1024])\n",
      "torch.Size([1, 2138, 1024])\n",
      "torch.Size([1, 1985, 1024])\n",
      "torch.Size([1, 1270, 1024])\n",
      "torch.Size([1, 1496, 1024])\n",
      "torch.Size([1, 2089, 1024])\n",
      "torch.Size([1, 5682, 1024])\n",
      "torch.Size([1, 2421, 1024])\n",
      "torch.Size([1, 2247, 1024])\n",
      "torch.Size([1, 1648, 1024])\n",
      "torch.Size([1, 1708, 1024])\n",
      "torch.Size([1, 1699, 1024])\n",
      "torch.Size([1, 2559, 1024])\n",
      "torch.Size([1, 5712, 1024])\n",
      "torch.Size([1, 1704, 1024])\n",
      "torch.Size([1, 1778, 1024])\n",
      "torch.Size([1, 3939, 1024])\n",
      "torch.Size([1, 3060, 1024])\n",
      "torch.Size([1, 7894, 1024])\n",
      "torch.Size([1, 3889, 1024])\n",
      "torch.Size([1, 5301, 1024])\n",
      "torch.Size([1, 522, 1024])\n",
      "torch.Size([1, 6041, 1024])\n",
      "torch.Size([1, 4729, 1024])\n",
      "torch.Size([1, 2007, 1024])\n",
      "torch.Size([1, 2888, 1024])\n",
      "torch.Size([1, 4554, 1024])\n",
      "torch.Size([1, 2164, 1024])\n",
      "torch.Size([1, 3140, 1024])\n",
      "torch.Size([1, 6277, 1024])\n",
      "torch.Size([1, 1497, 1024])\n",
      "torch.Size([1, 3995, 1024])\n",
      "torch.Size([1, 1282, 1024])\n",
      "torch.Size([1, 3374, 1024])\n",
      "torch.Size([1, 560, 1024])\n",
      "torch.Size([1, 4110, 1024])\n",
      "torch.Size([1, 4133, 1024])\n",
      "torch.Size([1, 1628, 1024])\n",
      "torch.Size([1, 8689, 1024])\n",
      "torch.Size([1, 1734, 1024])\n",
      "torch.Size([1, 2189, 1024])\n",
      "torch.Size([1, 1916, 1024])\n",
      "torch.Size([1, 3797, 1024])\n",
      "torch.Size([1, 552, 1024])\n",
      "torch.Size([1, 1103, 1024])\n",
      "torch.Size([1, 2698, 1024])\n",
      "torch.Size([1, 1573, 1024])\n",
      "torch.Size([1, 4443, 1024])\n",
      "torch.Size([1, 6335, 1024])\n",
      "torch.Size([1, 1175, 1024])\n",
      "torch.Size([1, 1554, 1024])\n",
      "torch.Size([1, 3250, 1024])\n",
      "torch.Size([1, 3302, 1024])\n",
      "torch.Size([1, 3123, 1024])\n",
      "torch.Size([1, 2965, 1024])\n",
      "torch.Size([1, 1946, 1024])\n",
      "torch.Size([1, 6201, 1024])\n",
      "torch.Size([1, 1237, 1024])\n",
      "torch.Size([1, 1945, 1024])\n",
      "torch.Size([1, 2076, 1024])\n",
      "torch.Size([1, 291, 1024])\n",
      "torch.Size([1, 5704, 1024])\n",
      "torch.Size([1, 1803, 1024])\n",
      "torch.Size([1, 1813, 1024])\n",
      "torch.Size([1, 2522, 1024])\n",
      "torch.Size([1, 1897, 1024])\n",
      "torch.Size([1, 5921, 1024])\n",
      "torch.Size([1, 2209, 1024])\n",
      "torch.Size([1, 341, 1024])\n",
      "torch.Size([1, 1408, 1024])\n",
      "torch.Size([1, 3130, 1024])\n",
      "torch.Size([1, 1507, 1024])\n",
      "torch.Size([1, 575, 1024])\n",
      "torch.Size([1, 6457, 1024])\n",
      "torch.Size([1, 5132, 1024])\n",
      "torch.Size([1, 1037, 1024])\n",
      "torch.Size([1, 2597, 1024])\n",
      "torch.Size([1, 2544, 1024])\n",
      "torch.Size([1, 3973, 1024])\n",
      "torch.Size([1, 2457, 1024])\n",
      "torch.Size([1, 1281, 1024])\n",
      "torch.Size([1, 1790, 1024])\n",
      "torch.Size([1, 777, 1024])\n",
      "torch.Size([1, 1455, 1024])\n",
      "torch.Size([1, 1705, 1024])\n",
      "torch.Size([1, 4927, 1024])\n",
      "torch.Size([1, 4415, 1024])\n",
      "torch.Size([1, 1248, 1024])\n",
      "torch.Size([1, 2430, 1024])\n",
      "torch.Size([1, 3425, 1024])\n",
      "torch.Size([1, 1487, 1024])\n",
      "torch.Size([1, 3265, 1024])\n",
      "torch.Size([1, 2777, 1024])\n",
      "torch.Size([1, 887, 1024])\n",
      "torch.Size([1, 5837, 1024])\n",
      "torch.Size([1, 1698, 1024])\n",
      "torch.Size([1, 1896, 1024])\n",
      "torch.Size([1, 1342, 1024])\n",
      "torch.Size([1, 1640, 1024])\n",
      "torch.Size([1, 6207, 1024])\n",
      "torch.Size([1, 3746, 1024])\n",
      "torch.Size([1, 2518, 1024])\n",
      "torch.Size([1, 2871, 1024])\n",
      "torch.Size([1, 3434, 1024])\n",
      "torch.Size([1, 2641, 1024])\n",
      "torch.Size([1, 1416, 1024])\n",
      "torch.Size([1, 3066, 1024])\n",
      "torch.Size([1, 471, 1024])\n",
      "torch.Size([1, 3031, 1024])\n",
      "torch.Size([1, 2115, 1024])\n",
      "torch.Size([1, 3173, 1024])\n",
      "torch.Size([1, 1665, 1024])\n",
      "torch.Size([1, 1558, 1024])\n",
      "torch.Size([1, 3452, 1024])\n",
      "torch.Size([1, 1038, 1024])\n",
      "torch.Size([1, 962, 1024])\n",
      "torch.Size([1, 3089, 1024])\n",
      "torch.Size([1, 591, 1024])\n",
      "torch.Size([1, 1601, 1024])\n",
      "torch.Size([1, 1653, 1024])\n",
      "torch.Size([1, 1569, 1024])\n",
      "torch.Size([1, 1444, 1024])\n",
      "torch.Size([1, 1339, 1024])\n",
      "torch.Size([1, 1906, 1024])\n",
      "torch.Size([1, 1755, 1024])\n",
      "torch.Size([1, 3312, 1024])\n",
      "torch.Size([1, 1654, 1024])\n",
      "torch.Size([1, 4749, 1024])\n",
      "torch.Size([1, 3977, 1024])\n",
      "torch.Size([1, 1895, 1024])\n",
      "torch.Size([1, 1359, 1024])\n",
      "torch.Size([1, 1629, 1024])\n",
      "torch.Size([1, 5480, 1024])\n",
      "torch.Size([1, 472, 1024])\n",
      "torch.Size([1, 3548, 1024])\n",
      "torch.Size([1, 2785, 1024])\n",
      "torch.Size([1, 6506, 1024])\n",
      "torch.Size([1, 279, 1024])\n",
      "torch.Size([1, 1900, 1024])\n",
      "torch.Size([1, 1529, 1024])\n",
      "torch.Size([1, 1377, 1024])\n",
      "torch.Size([1, 1333, 1024])\n",
      "torch.Size([1, 1974, 1024])\n",
      "torch.Size([1, 3072, 1024])\n",
      "torch.Size([1, 4576, 1024])\n",
      "torch.Size([1, 1430, 1024])\n",
      "torch.Size([1, 954, 1024])\n",
      "torch.Size([1, 7059, 1024])\n",
      "torch.Size([1, 2224, 1024])\n",
      "torch.Size([1, 3942, 1024])\n",
      "torch.Size([1, 2424, 1024])\n",
      "torch.Size([1, 5407, 1024])\n",
      "torch.Size([1, 969, 1024])\n",
      "torch.Size([1, 1038, 1024])\n",
      "torch.Size([1, 3887, 1024])\n",
      "torch.Size([1, 1667, 1024])\n",
      "torch.Size([1, 2638, 1024])\n",
      "torch.Size([1, 3459, 1024])\n",
      "torch.Size([1, 1515, 1024])\n",
      "torch.Size([1, 1771, 1024])\n",
      "torch.Size([1, 1752, 1024])\n",
      "torch.Size([1, 1416, 1024])\n",
      "torch.Size([1, 2344, 1024])\n",
      "torch.Size([1, 1475, 1024])\n",
      "torch.Size([1, 1562, 1024])\n",
      "torch.Size([1, 1050, 1024])\n",
      "torch.Size([1, 6698, 1024])\n",
      "torch.Size([1, 768, 1024])\n",
      "torch.Size([1, 1349, 1024])\n",
      "torch.Size([1, 2259, 1024])\n",
      "torch.Size([1, 3736, 1024])\n",
      "torch.Size([1, 725, 1024])\n",
      "torch.Size([1, 1726, 1024])\n",
      "torch.Size([1, 4808, 1024])\n",
      "torch.Size([1, 2440, 1024])\n",
      "torch.Size([1, 1293, 1024])\n",
      "torch.Size([1, 4960, 1024])\n",
      "torch.Size([1, 2468, 1024])\n",
      "torch.Size([1, 1531, 1024])\n",
      "torch.Size([1, 2450, 1024])\n",
      "torch.Size([1, 3032, 1024])\n",
      "torch.Size([1, 5574, 1024])\n",
      "torch.Size([1, 5671, 1024])\n",
      "torch.Size([1, 2120, 1024])\n",
      "torch.Size([1, 2461, 1024])\n",
      "torch.Size([1, 3836, 1024])\n",
      "torch.Size([1, 3971, 1024])\n",
      "torch.Size([1, 5344, 1024])\n",
      "torch.Size([1, 6357, 1024])\n",
      "torch.Size([1, 2107, 1024])\n",
      "torch.Size([1, 2907, 1024])\n",
      "torch.Size([1, 4391, 1024])\n",
      "torch.Size([1, 2629, 1024])\n",
      "torch.Size([1, 5196, 1024])\n",
      "torch.Size([1, 5778, 1024])\n",
      "torch.Size([1, 3430, 1024])\n",
      "torch.Size([1, 1762, 1024])\n",
      "torch.Size([1, 7626, 1024])\n",
      "torch.Size([1, 1415, 1024])\n",
      "torch.Size([1, 2038, 1024])\n",
      "torch.Size([1, 2789, 1024])\n",
      "torch.Size([1, 1769, 1024])\n",
      "torch.Size([1, 330, 1024])\n",
      "torch.Size([1, 1721, 1024])\n",
      "torch.Size([1, 3039, 1024])\n",
      "torch.Size([1, 3227, 1024])\n",
      "torch.Size([1, 3153, 1024])\n",
      "torch.Size([1, 5831, 1024])\n",
      "torch.Size([1, 4175, 1024])\n",
      "torch.Size([1, 602, 1024])\n",
      "torch.Size([1, 586, 1024])\n",
      "torch.Size([1, 3985, 1024])\n",
      "torch.Size([1, 2295, 1024])\n",
      "torch.Size([1, 5039, 1024])\n",
      "torch.Size([1, 2168, 1024])\n",
      "torch.Size([1, 3603, 1024])\n",
      "torch.Size([1, 2084, 1024])\n",
      "torch.Size([1, 1916, 1024])\n",
      "torch.Size([1, 3590, 1024])\n",
      "torch.Size([1, 1347, 1024])\n",
      "torch.Size([1, 5102, 1024])\n",
      "torch.Size([1, 1926, 1024])\n",
      "torch.Size([1, 4014, 1024])\n",
      "torch.Size([1, 2380, 1024])\n",
      "torch.Size([1, 4920, 1024])\n",
      "torch.Size([1, 4152, 1024])\n",
      "torch.Size([1, 1638, 1024])\n",
      "torch.Size([1, 2299, 1024])\n",
      "torch.Size([1, 1992, 1024])\n",
      "torch.Size([1, 1663, 1024])\n",
      "torch.Size([1, 2922, 1024])\n",
      "torch.Size([1, 1607, 1024])\n",
      "torch.Size([1, 1461, 1024])\n",
      "torch.Size([1, 1592, 1024])\n",
      "torch.Size([1, 4005, 1024])\n",
      "torch.Size([1, 1910, 1024])\n",
      "torch.Size([1, 302, 1024])\n",
      "torch.Size([1, 3007, 1024])\n",
      "torch.Size([1, 3666, 1024])\n",
      "torch.Size([1, 3111, 1024])\n",
      "torch.Size([1, 3389, 1024])\n",
      "torch.Size([1, 1152, 1024])\n",
      "torch.Size([1, 3565, 1024])\n",
      "torch.Size([1, 931, 1024])\n",
      "torch.Size([1, 1250, 1024])\n",
      "torch.Size([1, 1459, 1024])\n",
      "torch.Size([1, 944, 1024])\n",
      "torch.Size([1, 1605, 1024])\n",
      "torch.Size([1, 4497, 1024])\n",
      "torch.Size([1, 347, 1024])\n",
      "torch.Size([1, 7077, 1024])\n",
      "torch.Size([1, 1373, 1024])\n",
      "torch.Size([1, 1822, 1024])\n",
      "torch.Size([1, 1664, 1024])\n",
      "torch.Size([1, 6812, 1024])\n",
      "torch.Size([1, 1550, 1024])\n",
      "torch.Size([1, 2138, 1024])\n",
      "torch.Size([1, 3844, 1024])\n",
      "torch.Size([1, 4777, 1024])\n",
      "torch.Size([1, 3071, 1024])\n",
      "torch.Size([1, 2009, 1024])\n",
      "torch.Size([1, 1491, 1024])\n",
      "torch.Size([1, 1957, 1024])\n",
      "torch.Size([1, 2182, 1024])\n",
      "torch.Size([1, 4480, 1024])\n",
      "torch.Size([1, 3808, 1024])\n",
      "torch.Size([1, 3672, 1024])\n",
      "torch.Size([1, 3073, 1024])\n",
      "torch.Size([1, 1296, 1024])\n",
      "torch.Size([1, 4575, 1024])\n",
      "torch.Size([1, 5842, 1024])\n",
      "torch.Size([1, 1790, 1024])\n",
      "torch.Size([1, 2502, 1024])\n",
      "torch.Size([1, 1675, 1024])\n",
      "torch.Size([1, 3814, 1024])\n",
      "torch.Size([1, 1948, 1024])\n",
      "torch.Size([1, 2268, 1024])\n",
      "torch.Size([1, 2693, 1024])\n",
      "torch.Size([1, 1421, 1024])\n",
      "torch.Size([1, 2151, 1024])\n",
      "torch.Size([1, 3352, 1024])\n",
      "torch.Size([1, 2232, 1024])\n",
      "torch.Size([1, 1625, 1024])\n",
      "torch.Size([1, 2296, 1024])\n",
      "torch.Size([1, 2162, 1024])\n",
      "torch.Size([1, 1172, 1024])\n",
      "torch.Size([1, 2097, 1024])\n",
      "torch.Size([1, 5633, 1024])\n",
      "torch.Size([1, 2068, 1024])\n",
      "torch.Size([1, 1653, 1024])\n",
      "torch.Size([1, 1492, 1024])\n",
      "torch.Size([1, 2905, 1024])\n",
      "torch.Size([1, 1349, 1024])\n",
      "torch.Size([1, 1714, 1024])\n",
      "torch.Size([1, 1258, 1024])\n",
      "torch.Size([1, 5132, 1024])\n",
      "torch.Size([1, 2800, 1024])\n",
      "torch.Size([1, 2897, 1024])\n",
      "torch.Size([1, 3658, 1024])\n",
      "torch.Size([1, 1285, 1024])\n",
      "torch.Size([1, 2141, 1024])\n",
      "torch.Size([1, 2282, 1024])\n",
      "torch.Size([1, 3191, 1024])\n",
      "torch.Size([1, 3249, 1024])\n",
      "torch.Size([1, 683, 1024])\n",
      "torch.Size([1, 5734, 1024])\n",
      "torch.Size([1, 2660, 1024])\n",
      "torch.Size([1, 1482, 1024])\n",
      "torch.Size([1, 4471, 1024])\n",
      "torch.Size([1, 1843, 1024])\n",
      "torch.Size([1, 3504, 1024])\n",
      "torch.Size([1, 2445, 1024])\n",
      "torch.Size([1, 437, 1024])\n",
      "torch.Size([1, 2111, 1024])\n",
      "torch.Size([1, 1578, 1024])\n",
      "torch.Size([1, 1973, 1024])\n",
      "torch.Size([1, 1569, 1024])\n",
      "torch.Size([1, 1522, 1024])\n",
      "torch.Size([1, 4491, 1024])\n",
      "torch.Size([1, 1849, 1024])\n",
      "torch.Size([1, 2320, 1024])\n",
      "torch.Size([1, 3182, 1024])\n",
      "torch.Size([1, 6457, 1024])\n",
      "torch.Size([1, 1716, 1024])\n",
      "torch.Size([1, 3069, 1024])\n",
      "torch.Size([1, 3880, 1024])\n",
      "torch.Size([1, 1759, 1024])\n",
      "torch.Size([1, 1551, 1024])\n",
      "torch.Size([1, 1109, 1024])\n",
      "torch.Size([1, 3770, 1024])\n",
      "torch.Size([1, 1178, 1024])\n",
      "torch.Size([1, 1663, 1024])\n",
      "torch.Size([1, 2843, 1024])\n",
      "torch.Size([1, 1289, 1024])\n",
      "torch.Size([1, 4295, 1024])\n",
      "torch.Size([1, 1781, 1024])\n",
      "torch.Size([1, 1976, 1024])\n",
      "torch.Size([1, 1129, 1024])\n",
      "torch.Size([1, 1585, 1024])\n",
      "torch.Size([1, 3629, 1024])\n",
      "torch.Size([1, 2334, 1024])\n",
      "torch.Size([1, 2557, 1024])\n",
      "torch.Size([1, 4609, 1024])\n",
      "torch.Size([1, 1375, 1024])\n",
      "torch.Size([1, 388, 1024])\n",
      "torch.Size([1, 4740, 1024])\n",
      "torch.Size([1, 8442, 1024])\n",
      "torch.Size([1, 2901, 1024])\n",
      "torch.Size([1, 1931, 1024])\n",
      "torch.Size([1, 1269, 1024])\n",
      "torch.Size([1, 1244, 1024])\n",
      "torch.Size([1, 1297, 1024])\n",
      "torch.Size([1, 2195, 1024])\n",
      "torch.Size([1, 2556, 1024])\n",
      "torch.Size([1, 2506, 1024])\n",
      "torch.Size([1, 1608, 1024])\n",
      "torch.Size([1, 1415, 1024])\n",
      "torch.Size([1, 1700, 1024])\n",
      "torch.Size([1, 3891, 1024])\n",
      "torch.Size([1, 2540, 1024])\n",
      "torch.Size([1, 2423, 1024])\n",
      "torch.Size([1, 2452, 1024])\n",
      "torch.Size([1, 1960, 1024])\n",
      "torch.Size([1, 1457, 1024])\n",
      "torch.Size([1, 468, 1024])\n",
      "torch.Size([1, 1913, 1024])\n",
      "torch.Size([1, 1380, 1024])\n",
      "torch.Size([1, 1294, 1024])\n",
      "torch.Size([1, 3285, 1024])\n",
      "torch.Size([1, 1782, 1024])\n",
      "torch.Size([1, 3110, 1024])\n",
      "torch.Size([1, 1200, 1024])\n",
      "torch.Size([1, 4616, 1024])\n",
      "torch.Size([1, 1949, 1024])\n",
      "torch.Size([1, 3133, 1024])\n",
      "torch.Size([1, 3499, 1024])\n",
      "torch.Size([1, 2537, 1024])\n",
      "torch.Size([1, 1243, 1024])\n",
      "torch.Size([1, 1173, 1024])\n",
      "torch.Size([1, 4115, 1024])\n",
      "torch.Size([1, 2756, 1024])\n",
      "torch.Size([1, 1246, 1024])\n",
      "torch.Size([1, 1084, 1024])\n",
      "torch.Size([1, 1233, 1024])\n",
      "torch.Size([1, 4118, 1024])\n",
      "torch.Size([1, 1300, 1024])\n",
      "torch.Size([1, 2351, 1024])\n",
      "torch.Size([1, 3354, 1024])\n",
      "torch.Size([1, 3331, 1024])\n",
      "torch.Size([1, 1900, 1024])\n",
      "torch.Size([1, 2022, 1024])\n",
      "torch.Size([1, 3094, 1024])\n",
      "torch.Size([1, 1581, 1024])\n",
      "torch.Size([1, 1743, 1024])\n",
      "torch.Size([1, 3158, 1024])\n",
      "torch.Size([1, 1572, 1024])\n",
      "torch.Size([1, 1989, 1024])\n",
      "torch.Size([1, 2558, 1024])\n",
      "torch.Size([1, 7039, 1024])\n",
      "torch.Size([1, 2096, 1024])\n",
      "torch.Size([1, 4977, 1024])\n",
      "torch.Size([1, 1575, 1024])\n",
      "torch.Size([1, 3200, 1024])\n",
      "torch.Size([1, 1294, 1024])\n",
      "torch.Size([1, 4383, 1024])\n",
      "torch.Size([1, 2088, 1024])\n",
      "torch.Size([1, 1796, 1024])\n",
      "torch.Size([1, 858, 1024])\n",
      "torch.Size([1, 4308, 1024])\n",
      "torch.Size([1, 4736, 1024])\n",
      "torch.Size([1, 4986, 1024])\n",
      "torch.Size([1, 2937, 1024])\n",
      "torch.Size([1, 3459, 1024])\n",
      "torch.Size([1, 2930, 1024])\n",
      "torch.Size([1, 1033, 1024])\n",
      "torch.Size([1, 6545, 1024])\n",
      "torch.Size([1, 2357, 1024])\n",
      "torch.Size([1, 1999, 1024])\n",
      "torch.Size([1, 1263, 1024])\n",
      "torch.Size([1, 1666, 1024])\n",
      "torch.Size([1, 1115, 1024])\n",
      "torch.Size([1, 1807, 1024])\n",
      "torch.Size([1, 3284, 1024])\n",
      "torch.Size([1, 2562, 1024])\n",
      "torch.Size([1, 1356, 1024])\n",
      "torch.Size([1, 2385, 1024])\n",
      "torch.Size([1, 1955, 1024])\n",
      "torch.Size([1, 1690, 1024])\n",
      "torch.Size([1, 2846, 1024])\n",
      "torch.Size([1, 3959, 1024])\n",
      "torch.Size([1, 1462, 1024])\n",
      "torch.Size([1, 3503, 1024])\n",
      "torch.Size([1, 3379, 1024])\n",
      "torch.Size([1, 2701, 1024])\n",
      "torch.Size([1, 4227, 1024])\n",
      "torch.Size([1, 1438, 1024])\n",
      "torch.Size([1, 3141, 1024])\n",
      "torch.Size([1, 4065, 1024])\n",
      "torch.Size([1, 1711, 1024])\n",
      "torch.Size([1, 1389, 1024])\n",
      "torch.Size([1, 3214, 1024])\n",
      "torch.Size([1, 5121, 1024])\n",
      "torch.Size([1, 3037, 1024])\n",
      "torch.Size([1, 1476, 1024])\n",
      "torch.Size([1, 3089, 1024])\n",
      "torch.Size([1, 1566, 1024])\n",
      "torch.Size([1, 886, 1024])\n",
      "torch.Size([1, 1997, 1024])\n",
      "torch.Size([1, 1118, 1024])\n",
      "torch.Size([1, 1484, 1024])\n",
      "torch.Size([1, 1040, 1024])\n",
      "torch.Size([1, 1461, 1024])\n",
      "torch.Size([1, 1935, 1024])\n",
      "torch.Size([1, 1707, 1024])\n",
      "torch.Size([1, 720, 1024])\n",
      "torch.Size([1, 1533, 1024])\n",
      "torch.Size([1, 3341, 1024])\n",
      "torch.Size([1, 3992, 1024])\n",
      "torch.Size([1, 2553, 1024])\n",
      "torch.Size([1, 2935, 1024])\n",
      "torch.Size([1, 5774, 1024])\n",
      "torch.Size([1, 1501, 1024])\n",
      "torch.Size([1, 1861, 1024])\n",
      "torch.Size([1, 2461, 1024])\n",
      "torch.Size([1, 758, 1024])\n",
      "torch.Size([1, 1980, 1024])\n",
      "torch.Size([1, 1413, 1024])\n",
      "torch.Size([1, 2951, 1024])\n",
      "torch.Size([1, 2025, 1024])\n",
      "torch.Size([1, 5445, 1024])\n",
      "torch.Size([1, 1714, 1024])\n",
      "torch.Size([1, 2015, 1024])\n",
      "torch.Size([1, 1566, 1024])\n",
      "torch.Size([1, 7465, 1024])\n",
      "torch.Size([1, 1606, 1024])\n",
      "torch.Size([1, 3794, 1024])\n",
      "torch.Size([1, 1267, 1024])\n",
      "torch.Size([1, 874, 1024])\n",
      "torch.Size([1, 1470, 1024])\n",
      "torch.Size([1, 2412, 1024])\n",
      "torch.Size([1, 2216, 1024])\n",
      "torch.Size([1, 1141, 1024])\n",
      "torch.Size([1, 6979, 1024])\n",
      "torch.Size([1, 1863, 1024])\n",
      "torch.Size([1, 1818, 1024])\n",
      "torch.Size([1, 2032, 1024])\n",
      "torch.Size([1, 4332, 1024])\n",
      "torch.Size([1, 1242, 1024])\n",
      "torch.Size([1, 3600, 1024])\n",
      "torch.Size([1, 2048, 1024])\n",
      "torch.Size([1, 2015, 1024])\n",
      "torch.Size([1, 1558, 1024])\n",
      "torch.Size([1, 3255, 1024])\n",
      "torch.Size([1, 3902, 1024])\n",
      "torch.Size([1, 4060, 1024])\n",
      "torch.Size([1, 3198, 1024])\n",
      "torch.Size([1, 2815, 1024])\n",
      "torch.Size([1, 2877, 1024])\n",
      "torch.Size([1, 962, 1024])\n",
      "torch.Size([1, 1508, 1024])\n",
      "torch.Size([1, 1929, 1024])\n",
      "torch.Size([1, 2589, 1024])\n",
      "torch.Size([1, 3696, 1024])\n",
      "torch.Size([1, 2382, 1024])\n",
      "torch.Size([1, 3539, 1024])\n",
      "torch.Size([1, 2151, 1024])\n",
      "torch.Size([1, 3637, 1024])\n",
      "torch.Size([1, 2731, 1024])\n",
      "torch.Size([1, 3631, 1024])\n",
      "torch.Size([1, 3109, 1024])\n",
      "torch.Size([1, 1583, 1024])\n",
      "torch.Size([1, 5020, 1024])\n",
      "torch.Size([1, 2274, 1024])\n",
      "torch.Size([1, 1999, 1024])\n",
      "torch.Size([1, 1274, 1024])\n",
      "torch.Size([1, 3265, 1024])\n",
      "torch.Size([1, 4846, 1024])\n",
      "torch.Size([1, 2586, 1024])\n",
      "torch.Size([1, 3534, 1024])\n",
      "torch.Size([1, 1226, 1024])\n",
      "torch.Size([1, 2991, 1024])\n",
      "torch.Size([1, 1856, 1024])\n",
      "torch.Size([1, 2065, 1024])\n",
      "torch.Size([1, 4136, 1024])\n",
      "torch.Size([1, 4146, 1024])\n",
      "torch.Size([1, 4826, 1024])\n",
      "torch.Size([1, 2822, 1024])\n",
      "torch.Size([1, 1401, 1024])\n",
      "torch.Size([1, 2577, 1024])\n",
      "torch.Size([1, 2564, 1024])\n",
      "torch.Size([1, 1901, 1024])\n",
      "torch.Size([1, 2082, 1024])\n",
      "torch.Size([1, 468, 1024])\n",
      "torch.Size([1, 1497, 1024])\n",
      "torch.Size([1, 2189, 1024])\n",
      "torch.Size([1, 1865, 1024])\n",
      "torch.Size([1, 2850, 1024])\n",
      "torch.Size([1, 3355, 1024])\n",
      "torch.Size([1, 600, 1024])\n",
      "torch.Size([1, 1893, 1024])\n",
      "torch.Size([1, 4915, 1024])\n",
      "torch.Size([1, 246, 1024])\n",
      "torch.Size([1, 2060, 1024])\n",
      "torch.Size([1, 3381, 1024])\n",
      "torch.Size([1, 1846, 1024])\n",
      "torch.Size([1, 2047, 1024])\n",
      "torch.Size([1, 4531, 1024])\n",
      "torch.Size([1, 4998, 1024])\n",
      "torch.Size([1, 1763, 1024])\n",
      "torch.Size([1, 2479, 1024])\n",
      "torch.Size([1, 2942, 1024])\n",
      "torch.Size([1, 1542, 1024])\n",
      "torch.Size([1, 2525, 1024])\n",
      "torch.Size([1, 565, 1024])\n",
      "torch.Size([1, 3448, 1024])\n",
      "torch.Size([1, 1545, 1024])\n",
      "torch.Size([1, 1378, 1024])\n",
      "torch.Size([1, 2166, 1024])\n",
      "torch.Size([1, 7904, 1024])\n",
      "torch.Size([1, 1053, 1024])\n",
      "torch.Size([1, 1845, 1024])\n",
      "torch.Size([1, 2437, 1024])\n",
      "torch.Size([1, 1386, 1024])\n",
      "torch.Size([1, 1539, 1024])\n",
      "torch.Size([1, 3768, 1024])\n",
      "torch.Size([1, 1655, 1024])\n",
      "torch.Size([1, 1823, 1024])\n",
      "torch.Size([1, 1658, 1024])\n",
      "torch.Size([1, 1931, 1024])\n",
      "torch.Size([1, 2475, 1024])\n",
      "torch.Size([1, 1555, 1024])\n",
      "torch.Size([1, 2108, 1024])\n",
      "torch.Size([1, 3746, 1024])\n",
      "torch.Size([1, 495, 1024])\n",
      "torch.Size([1, 3716, 1024])\n",
      "torch.Size([1, 921, 1024])\n",
      "torch.Size([1, 924, 1024])\n",
      "torch.Size([1, 235, 1024])\n",
      "torch.Size([1, 3280, 1024])\n",
      "torch.Size([1, 3871, 1024])\n",
      "torch.Size([1, 1518, 1024])\n",
      "torch.Size([1, 1784, 1024])\n",
      "torch.Size([1, 4602, 1024])\n",
      "torch.Size([1, 2425, 1024])\n",
      "torch.Size([1, 3408, 1024])\n",
      "torch.Size([1, 1960, 1024])\n",
      "torch.Size([1, 933, 1024])\n",
      "torch.Size([1, 1453, 1024])\n",
      "torch.Size([1, 2115, 1024])\n",
      "torch.Size([1, 2308, 1024])\n",
      "torch.Size([1, 2760, 1024])\n",
      "torch.Size([1, 5939, 1024])\n",
      "torch.Size([1, 1901, 1024])\n",
      "torch.Size([1, 1827, 1024])\n",
      "torch.Size([1, 2955, 1024])\n",
      "torch.Size([1, 2274, 1024])\n",
      "torch.Size([1, 1203, 1024])\n",
      "torch.Size([1, 1164, 1024])\n",
      "torch.Size([1, 3832, 1024])\n",
      "torch.Size([1, 1509, 1024])\n",
      "torch.Size([1, 4611, 1024])\n",
      "torch.Size([1, 4455, 1024])\n",
      "torch.Size([1, 2200, 1024])\n",
      "torch.Size([1, 1990, 1024])\n",
      "torch.Size([1, 2608, 1024])\n",
      "torch.Size([1, 1310, 1024])\n",
      "torch.Size([1, 339, 1024])\n",
      "torch.Size([1, 1364, 1024])\n",
      "torch.Size([1, 4535, 1024])\n",
      "torch.Size([1, 1474, 1024])\n",
      "torch.Size([1, 3814, 1024])\n",
      "torch.Size([1, 1471, 1024])\n",
      "torch.Size([1, 1911, 1024])\n",
      "torch.Size([1, 6401, 1024])\n",
      "torch.Size([1, 2257, 1024])\n",
      "torch.Size([1, 1575, 1024])\n",
      "torch.Size([1, 1376, 1024])\n",
      "torch.Size([1, 1064, 1024])\n",
      "torch.Size([1, 3189, 1024])\n",
      "torch.Size([1, 2184, 1024])\n",
      "torch.Size([1, 5930, 1024])\n",
      "torch.Size([1, 2737, 1024])\n",
      "torch.Size([1, 3861, 1024])\n",
      "torch.Size([1, 3907, 1024])\n",
      "torch.Size([1, 2240, 1024])\n",
      "torch.Size([1, 2219, 1024])\n",
      "torch.Size([1, 1822, 1024])\n",
      "torch.Size([1, 5119, 1024])\n",
      "torch.Size([1, 5258, 1024])\n",
      "torch.Size([1, 3535, 1024])\n",
      "torch.Size([1, 3062, 1024])\n",
      "torch.Size([1, 3065, 1024])\n",
      "torch.Size([1, 3615, 1024])\n",
      "torch.Size([1, 2855, 1024])\n",
      "torch.Size([1, 3857, 1024])\n",
      "torch.Size([1, 1630, 1024])\n",
      "torch.Size([1, 705, 1024])\n",
      "torch.Size([1, 1812, 1024])\n",
      "torch.Size([1, 1752, 1024])\n",
      "torch.Size([1, 3000, 1024])\n",
      "torch.Size([1, 1904, 1024])\n",
      "torch.Size([1, 1512, 1024])\n",
      "torch.Size([1, 3179, 1024])\n",
      "torch.Size([1, 1794, 1024])\n",
      "torch.Size([1, 2010, 1024])\n",
      "torch.Size([1, 1559, 1024])\n",
      "torch.Size([1, 2856, 1024])\n",
      "torch.Size([1, 504, 1024])\n",
      "torch.Size([1, 3355, 1024])\n",
      "torch.Size([1, 974, 1024])\n",
      "torch.Size([1, 2292, 1024])\n",
      "torch.Size([1, 1946, 1024])\n",
      "torch.Size([1, 2043, 1024])\n",
      "torch.Size([1, 3450, 1024])\n",
      "torch.Size([1, 1012, 1024])\n",
      "torch.Size([1, 2752, 1024])\n",
      "torch.Size([1, 1172, 1024])\n",
      "torch.Size([1, 591, 1024])\n",
      "torch.Size([1, 2644, 1024])\n",
      "torch.Size([1, 2614, 1024])\n",
      "torch.Size([1, 1767, 1024])\n",
      "torch.Size([1, 3870, 1024])\n",
      "torch.Size([1, 2963, 1024])\n",
      "torch.Size([1, 2430, 1024])\n",
      "torch.Size([1, 1771, 1024])\n",
      "torch.Size([1, 1193, 1024])\n",
      "torch.Size([1, 750, 1024])\n",
      "torch.Size([1, 5653, 1024])\n",
      "torch.Size([1, 2834, 1024])\n",
      "torch.Size([1, 612, 1024])\n",
      "torch.Size([1, 1020, 1024])\n",
      "torch.Size([1, 1490, 1024])\n",
      "torch.Size([1, 701, 1024])\n",
      "torch.Size([1, 1224, 1024])\n",
      "torch.Size([1, 1921, 1024])\n",
      "torch.Size([1, 7433, 1024])\n",
      "torch.Size([1, 3866, 1024])\n",
      "torch.Size([1, 1216, 1024])\n",
      "torch.Size([1, 4045, 1024])\n",
      "torch.Size([1, 2118, 1024])\n",
      "torch.Size([1, 2613, 1024])\n",
      "torch.Size([1, 1839, 1024])\n",
      "torch.Size([1, 2005, 1024])\n",
      "torch.Size([1, 2618, 1024])\n",
      "torch.Size([1, 2352, 1024])\n",
      "torch.Size([1, 3107, 1024])\n",
      "torch.Size([1, 2054, 1024])\n",
      "torch.Size([1, 3149, 1024])\n",
      "torch.Size([1, 2124, 1024])\n",
      "torch.Size([1, 2493, 1024])\n",
      "torch.Size([1, 4334, 1024])\n",
      "torch.Size([1, 4585, 1024])\n",
      "torch.Size([1, 4091, 1024])\n",
      "torch.Size([1, 1736, 1024])\n",
      "torch.Size([1, 2287, 1024])\n",
      "torch.Size([1, 1394, 1024])\n",
      "torch.Size([1, 2473, 1024])\n",
      "torch.Size([1, 2891, 1024])\n",
      "torch.Size([1, 2472, 1024])\n",
      "torch.Size([1, 1623, 1024])\n",
      "torch.Size([1, 2032, 1024])\n",
      "torch.Size([1, 3015, 1024])\n",
      "torch.Size([1, 2799, 1024])\n",
      "torch.Size([1, 2371, 1024])\n",
      "torch.Size([1, 1014, 1024])\n",
      "torch.Size([1, 2404, 1024])\n",
      "torch.Size([1, 6616, 1024])\n",
      "torch.Size([1, 2344, 1024])\n",
      "torch.Size([1, 1387, 1024])\n",
      "torch.Size([1, 1459, 1024])\n",
      "torch.Size([1, 2811, 1024])\n",
      "torch.Size([1, 1330, 1024])\n",
      "torch.Size([1, 2083, 1024])\n",
      "torch.Size([1, 3321, 1024])\n",
      "torch.Size([1, 197, 1024])\n",
      "torch.Size([1, 2093, 1024])\n",
      "torch.Size([1, 1468, 1024])\n",
      "torch.Size([1, 3890, 1024])\n",
      "torch.Size([1, 3446, 1024])\n",
      "torch.Size([1, 2819, 1024])\n",
      "torch.Size([1, 1932, 1024])\n",
      "torch.Size([1, 2786, 1024])\n",
      "torch.Size([1, 1448, 1024])\n",
      "torch.Size([1, 4187, 1024])\n",
      "torch.Size([1, 2088, 1024])\n",
      "torch.Size([1, 7370, 1024])\n",
      "torch.Size([1, 5013, 1024])\n",
      "torch.Size([1, 4376, 1024])\n",
      "torch.Size([1, 2111, 1024])\n",
      "torch.Size([1, 4107, 1024])\n",
      "torch.Size([1, 4436, 1024])\n",
      "torch.Size([1, 2046, 1024])\n",
      "torch.Size([1, 1590, 1024])\n",
      "torch.Size([1, 2710, 1024])\n",
      "torch.Size([1, 1258, 1024])\n",
      "torch.Size([1, 4022, 1024])\n",
      "torch.Size([1, 2110, 1024])\n",
      "torch.Size([1, 2889, 1024])\n",
      "torch.Size([1, 1629, 1024])\n",
      "torch.Size([1, 2136, 1024])\n",
      "torch.Size([1, 3933, 1024])\n",
      "torch.Size([1, 2278, 1024])\n",
      "torch.Size([1, 3073, 1024])\n",
      "torch.Size([1, 1297, 1024])\n",
      "torch.Size([1, 1086, 1024])\n",
      "torch.Size([1, 1978, 1024])\n",
      "torch.Size([1, 1777, 1024])\n",
      "torch.Size([1, 1932, 1024])\n",
      "torch.Size([1, 2240, 1024])\n",
      "torch.Size([1, 2786, 1024])\n",
      "torch.Size([1, 5118, 1024])\n",
      "torch.Size([1, 2823, 1024])\n",
      "torch.Size([1, 3901, 1024])\n",
      "torch.Size([1, 459, 1024])\n",
      "torch.Size([1, 2907, 1024])\n",
      "torch.Size([1, 4160, 1024])\n",
      "torch.Size([1, 1943, 1024])\n",
      "torch.Size([1, 3505, 1024])\n",
      "torch.Size([1, 1741, 1024])\n",
      "torch.Size([1, 1544, 1024])\n",
      "torch.Size([1, 4166, 1024])\n",
      "torch.Size([1, 1232, 1024])\n",
      "torch.Size([1, 1374, 1024])\n",
      "torch.Size([1, 1319, 1024])\n",
      "torch.Size([1, 1474, 1024])\n",
      "torch.Size([1, 2876, 1024])\n",
      "torch.Size([1, 1606, 1024])\n",
      "torch.Size([1, 1435, 1024])\n",
      "torch.Size([1, 1939, 1024])\n",
      "torch.Size([1, 4366, 1024])\n",
      "torch.Size([1, 2422, 1024])\n",
      "torch.Size([1, 1171, 1024])\n",
      "torch.Size([1, 1031, 1024])\n",
      "torch.Size([1, 2120, 1024])\n",
      "torch.Size([1, 2278, 1024])\n",
      "torch.Size([1, 4851, 1024])\n",
      "torch.Size([1, 1064, 1024])\n",
      "torch.Size([1, 2589, 1024])\n",
      "torch.Size([1, 1314, 1024])\n",
      "torch.Size([1, 1611, 1024])\n",
      "torch.Size([1, 4714, 1024])\n",
      "torch.Size([1, 1754, 1024])\n",
      "torch.Size([1, 1696, 1024])\n",
      "torch.Size([1, 5302, 1024])\n",
      "torch.Size([1, 1633, 1024])\n",
      "torch.Size([1, 2111, 1024])\n",
      "torch.Size([1, 1328, 1024])\n",
      "torch.Size([1, 1276, 1024])\n",
      "torch.Size([1, 2013, 1024])\n",
      "torch.Size([1, 2583, 1024])\n",
      "torch.Size([1, 1554, 1024])\n",
      "torch.Size([1, 4381, 1024])\n",
      "torch.Size([1, 2315, 1024])\n",
      "torch.Size([1, 4078, 1024])\n",
      "torch.Size([1, 2036, 1024])\n",
      "torch.Size([1, 4652, 1024])\n",
      "torch.Size([1, 2642, 1024])\n",
      "torch.Size([1, 2171, 1024])\n",
      "torch.Size([1, 3209, 1024])\n",
      "torch.Size([1, 1753, 1024])\n",
      "torch.Size([1, 2695, 1024])\n",
      "torch.Size([1, 2004, 1024])\n",
      "torch.Size([1, 1343, 1024])\n",
      "torch.Size([1, 2306, 1024])\n",
      "torch.Size([1, 2118, 1024])\n",
      "torch.Size([1, 3532, 1024])\n",
      "torch.Size([1, 4070, 1024])\n",
      "torch.Size([1, 2646, 1024])\n",
      "torch.Size([1, 2326, 1024])\n",
      "torch.Size([1, 1929, 1024])\n",
      "torch.Size([1, 209, 1024])\n",
      "torch.Size([1, 1501, 1024])\n",
      "torch.Size([1, 2337, 1024])\n",
      "torch.Size([1, 5159, 1024])\n",
      "torch.Size([1, 1526, 1024])\n",
      "torch.Size([1, 3789, 1024])\n",
      "torch.Size([1, 2234, 1024])\n",
      "torch.Size([1, 5276, 1024])\n",
      "torch.Size([1, 3645, 1024])\n",
      "torch.Size([1, 5898, 1024])\n",
      "torch.Size([1, 4274, 1024])\n",
      "torch.Size([1, 1161, 1024])\n",
      "torch.Size([1, 1103, 1024])\n",
      "torch.Size([1, 1323, 1024])\n",
      "torch.Size([1, 4099, 1024])\n",
      "torch.Size([1, 3425, 1024])\n",
      "torch.Size([1, 6856, 1024])\n",
      "torch.Size([1, 1469, 1024])\n",
      "torch.Size([1, 2130, 1024])\n",
      "torch.Size([1, 3897, 1024])\n",
      "torch.Size([1, 2248, 1024])\n",
      "torch.Size([1, 1300, 1024])\n",
      "torch.Size([1, 586, 1024])\n",
      "torch.Size([1, 5029, 1024])\n",
      "torch.Size([1, 3999, 1024])\n",
      "torch.Size([1, 1493, 1024])\n",
      "torch.Size([1, 1746, 1024])\n",
      "torch.Size([1, 1791, 1024])\n",
      "torch.Size([1, 3947, 1024])\n",
      "torch.Size([1, 1493, 1024])\n",
      "torch.Size([1, 2897, 1024])\n",
      "torch.Size([1, 404, 1024])\n",
      "torch.Size([1, 1586, 1024])\n",
      "torch.Size([1, 3921, 1024])\n",
      "torch.Size([1, 3336, 1024])\n",
      "torch.Size([1, 2217, 1024])\n",
      "torch.Size([1, 1448, 1024])\n",
      "torch.Size([1, 2266, 1024])\n",
      "torch.Size([1, 1542, 1024])\n",
      "torch.Size([1, 1191, 1024])\n",
      "torch.Size([1, 1611, 1024])\n",
      "torch.Size([1, 1352, 1024])\n",
      "torch.Size([1, 2217, 1024])\n",
      "torch.Size([1, 2275, 1024])\n",
      "torch.Size([1, 3474, 1024])\n",
      "torch.Size([1, 4552, 1024])\n",
      "torch.Size([1, 2260, 1024])\n",
      "torch.Size([1, 2538, 1024])\n",
      "torch.Size([1, 2152, 1024])\n",
      "torch.Size([1, 1400, 1024])\n",
      "torch.Size([1, 2633, 1024])\n",
      "torch.Size([1, 2230, 1024])\n",
      "torch.Size([1, 1301, 1024])\n",
      "torch.Size([1, 3151, 1024])\n",
      "torch.Size([1, 2042, 1024])\n",
      "torch.Size([1, 1506, 1024])\n",
      "torch.Size([1, 1050, 1024])\n",
      "torch.Size([1, 1188, 1024])\n",
      "torch.Size([1, 3119, 1024])\n",
      "torch.Size([1, 4345, 1024])\n",
      "torch.Size([1, 4816, 1024])\n",
      "torch.Size([1, 6108, 1024])\n",
      "torch.Size([1, 1557, 1024])\n",
      "torch.Size([1, 5006, 1024])\n",
      "torch.Size([1, 3262, 1024])\n",
      "torch.Size([1, 3619, 1024])\n",
      "torch.Size([1, 376, 1024])\n",
      "torch.Size([1, 2311, 1024])\n",
      "torch.Size([1, 1165, 1024])\n",
      "torch.Size([1, 2347, 1024])\n",
      "torch.Size([1, 2802, 1024])\n",
      "torch.Size([1, 1520, 1024])\n",
      "torch.Size([1, 1199, 1024])\n",
      "torch.Size([1, 1509, 1024])\n",
      "torch.Size([1, 3011, 1024])\n",
      "torch.Size([1, 5824, 1024])\n",
      "torch.Size([1, 2024, 1024])\n",
      "torch.Size([1, 2572, 1024])\n",
      "torch.Size([1, 2063, 1024])\n",
      "torch.Size([1, 769, 1024])\n",
      "torch.Size([1, 1354, 1024])\n",
      "torch.Size([1, 1556, 1024])\n",
      "torch.Size([1, 1826, 1024])\n",
      "torch.Size([1, 2797, 1024])\n",
      "torch.Size([1, 1848, 1024])\n",
      "torch.Size([1, 3560, 1024])\n",
      "torch.Size([1, 1450, 1024])\n",
      "torch.Size([1, 3890, 1024])\n",
      "torch.Size([1, 2080, 1024])\n",
      "torch.Size([1, 2020, 1024])\n",
      "torch.Size([1, 3252, 1024])\n",
      "torch.Size([1, 4128, 1024])\n",
      "torch.Size([1, 2610, 1024])\n",
      "torch.Size([1, 638, 1024])\n",
      "torch.Size([1, 1544, 1024])\n",
      "torch.Size([1, 1998, 1024])\n",
      "torch.Size([1, 2974, 1024])\n",
      "torch.Size([1, 3025, 1024])\n",
      "torch.Size([1, 4331, 1024])\n",
      "torch.Size([1, 3669, 1024])\n",
      "torch.Size([1, 2741, 1024])\n",
      "torch.Size([1, 3007, 1024])\n",
      "torch.Size([1, 2179, 1024])\n",
      "torch.Size([1, 2796, 1024])\n",
      "torch.Size([1, 1762, 1024])\n",
      "torch.Size([1, 1769, 1024])\n",
      "torch.Size([1, 1228, 1024])\n",
      "torch.Size([1, 2113, 1024])\n",
      "torch.Size([1, 1657, 1024])\n",
      "torch.Size([1, 2881, 1024])\n",
      "torch.Size([1, 3765, 1024])\n",
      "torch.Size([1, 2008, 1024])\n",
      "torch.Size([1, 327, 1024])\n",
      "torch.Size([1, 2673, 1024])\n",
      "torch.Size([1, 1888, 1024])\n",
      "torch.Size([1, 2195, 1024])\n",
      "torch.Size([1, 380, 1024])\n",
      "torch.Size([1, 1347, 1024])\n",
      "torch.Size([1, 3287, 1024])\n",
      "torch.Size([1, 1881, 1024])\n",
      "torch.Size([1, 1676, 1024])\n",
      "torch.Size([1, 2265, 1024])\n",
      "torch.Size([1, 4142, 1024])\n",
      "torch.Size([1, 1634, 1024])\n",
      "torch.Size([1, 1567, 1024])\n",
      "torch.Size([1, 2146, 1024])\n",
      "torch.Size([1, 5082, 1024])\n",
      "torch.Size([1, 2699, 1024])\n",
      "torch.Size([1, 2622, 1024])\n",
      "torch.Size([1, 1707, 1024])\n",
      "torch.Size([1, 3111, 1024])\n",
      "torch.Size([1, 2020, 1024])\n",
      "torch.Size([1, 8870, 1024])\n",
      "torch.Size([1, 2193, 1024])\n",
      "torch.Size([1, 2074, 1024])\n",
      "torch.Size([1, 2647, 1024])\n",
      "torch.Size([1, 6562, 1024])\n",
      "torch.Size([1, 484, 1024])\n",
      "torch.Size([1, 994, 1024])\n",
      "torch.Size([1, 1541, 1024])\n",
      "torch.Size([1, 6218, 1024])\n",
      "torch.Size([1, 1957, 1024])\n",
      "torch.Size([1, 244, 1024])\n",
      "torch.Size([1, 2148, 1024])\n",
      "torch.Size([1, 910, 1024])\n",
      "torch.Size([1, 6571, 1024])\n",
      "torch.Size([1, 4336, 1024])\n",
      "torch.Size([1, 1995, 1024])\n",
      "torch.Size([1, 1917, 1024])\n",
      "torch.Size([1, 1188, 1024])\n",
      "torch.Size([1, 1382, 1024])\n",
      "torch.Size([1, 1936, 1024])\n",
      "torch.Size([1, 5357, 1024])\n",
      "torch.Size([1, 3983, 1024])\n",
      "torch.Size([1, 1712, 1024])\n",
      "torch.Size([1, 6390, 1024])\n",
      "torch.Size([1, 1584, 1024])\n",
      "torch.Size([1, 1434, 1024])\n",
      "torch.Size([1, 2451, 1024])\n",
      "torch.Size([1, 1339, 1024])\n",
      "torch.Size([1, 2335, 1024])\n",
      "torch.Size([1, 2872, 1024])\n",
      "torch.Size([1, 1617, 1024])\n",
      "torch.Size([1, 1915, 1024])\n",
      "torch.Size([1, 4600, 1024])\n",
      "torch.Size([1, 3198, 1024])\n",
      "torch.Size([1, 2603, 1024])\n",
      "torch.Size([1, 1509, 1024])\n",
      "torch.Size([1, 3435, 1024])\n",
      "torch.Size([1, 2185, 1024])\n",
      "torch.Size([1, 1652, 1024])\n",
      "torch.Size([1, 1071, 1024])\n",
      "torch.Size([1, 1509, 1024])\n",
      "torch.Size([1, 4123, 1024])\n",
      "torch.Size([1, 1000, 1024])\n",
      "torch.Size([1, 3808, 1024])\n",
      "torch.Size([1, 1937, 1024])\n",
      "torch.Size([1, 3084, 1024])\n",
      "torch.Size([1, 5259, 1024])\n",
      "torch.Size([1, 1501, 1024])\n",
      "torch.Size([1, 5679, 1024])\n",
      "torch.Size([1, 6261, 1024])\n",
      "torch.Size([1, 3448, 1024])\n",
      "torch.Size([1, 453, 1024])\n",
      "torch.Size([1, 2451, 1024])\n",
      "torch.Size([1, 2620, 1024])\n",
      "torch.Size([1, 5730, 1024])\n",
      "torch.Size([1, 1423, 1024])\n",
      "torch.Size([1, 3706, 1024])\n",
      "torch.Size([1, 2809, 1024])\n",
      "torch.Size([1, 6014, 1024])\n",
      "torch.Size([1, 2043, 1024])\n",
      "torch.Size([1, 2341, 1024])\n",
      "torch.Size([1, 3514, 1024])\n",
      "torch.Size([1, 3833, 1024])\n",
      "torch.Size([1, 1458, 1024])\n",
      "torch.Size([1, 2538, 1024])\n",
      "torch.Size([1, 1891, 1024])\n",
      "torch.Size([1, 3683, 1024])\n",
      "torch.Size([1, 3003, 1024])\n",
      "torch.Size([1, 1981, 1024])\n",
      "torch.Size([1, 2407, 1024])\n",
      "torch.Size([1, 2674, 1024])\n",
      "torch.Size([1, 799, 1024])\n",
      "torch.Size([1, 4729, 1024])\n",
      "torch.Size([1, 1997, 1024])\n",
      "torch.Size([1, 1409, 1024])\n",
      "torch.Size([1, 4634, 1024])\n",
      "torch.Size([1, 1036, 1024])\n",
      "torch.Size([1, 1322, 1024])\n",
      "torch.Size([1, 6231, 1024])\n",
      "torch.Size([1, 2097, 1024])\n",
      "torch.Size([1, 749, 1024])\n",
      "torch.Size([1, 1548, 1024])\n",
      "torch.Size([1, 1097, 1024])\n",
      "torch.Size([1, 3813, 1024])\n",
      "torch.Size([1, 1660, 1024])\n",
      "torch.Size([1, 1596, 1024])\n",
      "torch.Size([1, 1371, 1024])\n",
      "torch.Size([1, 1595, 1024])\n",
      "torch.Size([1, 3403, 1024])\n",
      "torch.Size([1, 3108, 1024])\n",
      "torch.Size([1, 4202, 1024])\n",
      "torch.Size([1, 2078, 1024])\n",
      "torch.Size([1, 4374, 1024])\n",
      "torch.Size([1, 2367, 1024])\n",
      "torch.Size([1, 2414, 1024])\n",
      "torch.Size([1, 1138, 1024])\n",
      "torch.Size([1, 936, 1024])\n",
      "torch.Size([1, 349, 1024])\n",
      "torch.Size([1, 1776, 1024])\n",
      "torch.Size([1, 2897, 1024])\n",
      "torch.Size([1, 3995, 1024])\n",
      "torch.Size([1, 2334, 1024])\n",
      "torch.Size([1, 2591, 1024])\n",
      "torch.Size([1, 1962, 1024])\n",
      "torch.Size([1, 2580, 1024])\n",
      "torch.Size([1, 1920, 1024])\n",
      "torch.Size([1, 1263, 1024])\n",
      "torch.Size([1, 3149, 1024])\n",
      "torch.Size([1, 4841, 1024])\n",
      "torch.Size([1, 4705, 1024])\n",
      "torch.Size([1, 1264, 1024])\n",
      "torch.Size([1, 3416, 1024])\n",
      "torch.Size([1, 3376, 1024])\n",
      "torch.Size([1, 2041, 1024])\n",
      "torch.Size([1, 2345, 1024])\n",
      "torch.Size([1, 7463, 1024])\n",
      "torch.Size([1, 4202, 1024])\n",
      "torch.Size([1, 2341, 1024])\n",
      "torch.Size([1, 1934, 1024])\n",
      "torch.Size([1, 3271, 1024])\n",
      "torch.Size([1, 1284, 1024])\n",
      "torch.Size([1, 1931, 1024])\n",
      "torch.Size([1, 1769, 1024])\n",
      "torch.Size([1, 1655, 1024])\n",
      "torch.Size([1, 1540, 1024])\n",
      "torch.Size([1, 1231, 1024])\n",
      "torch.Size([1, 2225, 1024])\n",
      "torch.Size([1, 2802, 1024])\n",
      "torch.Size([1, 1239, 1024])\n",
      "torch.Size([1, 468, 1024])\n",
      "torch.Size([1, 1640, 1024])\n",
      "torch.Size([1, 784, 1024])\n",
      "torch.Size([1, 1890, 1024])\n",
      "torch.Size([1, 1421, 1024])\n",
      "torch.Size([1, 2214, 1024])\n",
      "torch.Size([1, 3392, 1024])\n",
      "torch.Size([1, 847, 1024])\n",
      "torch.Size([1, 1775, 1024])\n",
      "torch.Size([1, 1955, 1024])\n",
      "torch.Size([1, 3167, 1024])\n",
      "torch.Size([1, 3498, 1024])\n",
      "torch.Size([1, 2063, 1024])\n",
      "torch.Size([1, 2409, 1024])\n",
      "torch.Size([1, 2747, 1024])\n",
      "torch.Size([1, 2789, 1024])\n",
      "torch.Size([1, 1798, 1024])\n",
      "torch.Size([1, 4910, 1024])\n",
      "torch.Size([1, 2965, 1024])\n",
      "torch.Size([1, 1254, 1024])\n",
      "torch.Size([1, 4878, 1024])\n",
      "torch.Size([1, 2181, 1024])\n",
      "torch.Size([1, 1190, 1024])\n",
      "torch.Size([1, 2515, 1024])\n",
      "torch.Size([1, 1390, 1024])\n",
      "torch.Size([1, 5602, 1024])\n",
      "torch.Size([1, 1518, 1024])\n",
      "torch.Size([1, 6438, 1024])\n",
      "torch.Size([1, 1648, 1024])\n",
      "torch.Size([1, 2932, 1024])\n",
      "torch.Size([1, 1740, 1024])\n",
      "torch.Size([1, 1877, 1024])\n",
      "torch.Size([1, 2713, 1024])\n",
      "torch.Size([1, 2832, 1024])\n",
      "torch.Size([1, 3836, 1024])\n",
      "torch.Size([1, 2432, 1024])\n",
      "torch.Size([1, 1443, 1024])\n",
      "torch.Size([1, 1536, 1024])\n",
      "torch.Size([1, 2083, 1024])\n",
      "torch.Size([1, 553, 1024])\n",
      "torch.Size([1, 4131, 1024])\n",
      "torch.Size([1, 4102, 1024])\n",
      "torch.Size([1, 2693, 1024])\n",
      "torch.Size([1, 1744, 1024])\n",
      "torch.Size([1, 1184, 1024])\n",
      "torch.Size([1, 1554, 1024])\n",
      "torch.Size([1, 2158, 1024])\n",
      "torch.Size([1, 3285, 1024])\n",
      "torch.Size([1, 1180, 1024])\n",
      "torch.Size([1, 1170, 1024])\n",
      "torch.Size([1, 1588, 1024])\n",
      "torch.Size([1, 391, 1024])\n",
      "torch.Size([1, 1962, 1024])\n",
      "torch.Size([1, 1527, 1024])\n",
      "torch.Size([1, 1005, 1024])\n",
      "torch.Size([1, 3097, 1024])\n",
      "torch.Size([1, 4096, 1024])\n",
      "torch.Size([1, 1464, 1024])\n",
      "torch.Size([1, 1952, 1024])\n",
      "torch.Size([1, 2042, 1024])\n",
      "torch.Size([1, 2600, 1024])\n",
      "torch.Size([1, 1575, 1024])\n",
      "torch.Size([1, 4664, 1024])\n",
      "torch.Size([1, 1855, 1024])\n",
      "torch.Size([1, 6337, 1024])\n",
      "torch.Size([1, 2657, 1024])\n",
      "torch.Size([1, 3568, 1024])\n",
      "torch.Size([1, 1430, 1024])\n",
      "torch.Size([1, 291, 1024])\n",
      "torch.Size([1, 2855, 1024])\n",
      "torch.Size([1, 6894, 1024])\n",
      "torch.Size([1, 5367, 1024])\n",
      "torch.Size([1, 576, 1024])\n",
      "torch.Size([1, 3024, 1024])\n",
      "torch.Size([1, 3994, 1024])\n",
      "torch.Size([1, 2272, 1024])\n",
      "torch.Size([1, 3048, 1024])\n",
      "torch.Size([1, 1950, 1024])\n",
      "torch.Size([1, 3510, 1024])\n",
      "torch.Size([1, 2982, 1024])\n",
      "torch.Size([1, 6183, 1024])\n",
      "torch.Size([1, 3031, 1024])\n",
      "torch.Size([1, 5677, 1024])\n",
      "torch.Size([1, 2744, 1024])\n",
      "torch.Size([1, 1421, 1024])\n",
      "torch.Size([1, 2452, 1024])\n",
      "torch.Size([1, 1473, 1024])\n",
      "torch.Size([1, 4852, 1024])\n",
      "torch.Size([1, 1899, 1024])\n",
      "torch.Size([1, 2005, 1024])\n",
      "torch.Size([1, 2483, 1024])\n",
      "torch.Size([1, 2335, 1024])\n",
      "torch.Size([1, 2815, 1024])\n",
      "torch.Size([1, 3965, 1024])\n",
      "torch.Size([1, 334, 1024])\n",
      "torch.Size([1, 2906, 1024])\n",
      "torch.Size([1, 3582, 1024])\n",
      "torch.Size([1, 3551, 1024])\n",
      "torch.Size([1, 2842, 1024])\n",
      "torch.Size([1, 2944, 1024])\n",
      "torch.Size([1, 1570, 1024])\n",
      "torch.Size([1, 2633, 1024])\n",
      "torch.Size([1, 3471, 1024])\n",
      "torch.Size([1, 2967, 1024])\n",
      "torch.Size([1, 2680, 1024])\n",
      "torch.Size([1, 1691, 1024])\n",
      "torch.Size([1, 5872, 1024])\n",
      "torch.Size([1, 2503, 1024])\n",
      "torch.Size([1, 2358, 1024])\n",
      "torch.Size([1, 1736, 1024])\n",
      "torch.Size([1, 1486, 1024])\n",
      "torch.Size([1, 4110, 1024])\n",
      "torch.Size([1, 5846, 1024])\n",
      "torch.Size([1, 2180, 1024])\n",
      "torch.Size([1, 764, 1024])\n",
      "torch.Size([1, 4205, 1024])\n",
      "torch.Size([1, 1445, 1024])\n",
      "torch.Size([1, 1428, 1024])\n",
      "torch.Size([1, 3140, 1024])\n",
      "torch.Size([1, 1305, 1024])\n",
      "torch.Size([1, 1171, 1024])\n",
      "torch.Size([1, 2311, 1024])\n",
      "torch.Size([1, 3679, 1024])\n",
      "torch.Size([1, 1873, 1024])\n",
      "torch.Size([1, 1596, 1024])\n",
      "torch.Size([1, 2122, 1024])\n",
      "torch.Size([1, 2207, 1024])\n",
      "torch.Size([1, 1700, 1024])\n",
      "torch.Size([1, 1294, 1024])\n",
      "torch.Size([1, 2143, 1024])\n",
      "torch.Size([1, 4032, 1024])\n",
      "torch.Size([1, 2195, 1024])\n",
      "torch.Size([1, 1771, 1024])\n",
      "torch.Size([1, 1252, 1024])\n",
      "torch.Size([1, 1731, 1024])\n",
      "torch.Size([1, 5110, 1024])\n",
      "torch.Size([1, 1412, 1024])\n",
      "torch.Size([1, 1721, 1024])\n",
      "torch.Size([1, 1422, 1024])\n",
      "torch.Size([1, 1047, 1024])\n",
      "torch.Size([1, 4693, 1024])\n",
      "torch.Size([1, 1068, 1024])\n",
      "torch.Size([1, 3795, 1024])\n",
      "torch.Size([1, 8450, 1024])\n",
      "torch.Size([1, 1043, 1024])\n",
      "torch.Size([1, 3190, 1024])\n",
      "torch.Size([1, 2907, 1024])\n",
      "torch.Size([1, 469, 1024])\n",
      "torch.Size([1, 785, 1024])\n",
      "torch.Size([1, 1640, 1024])\n",
      "torch.Size([1, 2091, 1024])\n",
      "torch.Size([1, 1538, 1024])\n",
      "torch.Size([1, 2702, 1024])\n",
      "torch.Size([1, 2214, 1024])\n",
      "torch.Size([1, 3917, 1024])\n",
      "torch.Size([1, 2544, 1024])\n",
      "torch.Size([1, 2644, 1024])\n",
      "torch.Size([1, 2211, 1024])\n",
      "torch.Size([1, 3135, 1024])\n",
      "torch.Size([1, 2865, 1024])\n",
      "torch.Size([1, 1257, 1024])\n",
      "torch.Size([1, 1741, 1024])\n",
      "torch.Size([1, 1089, 1024])\n",
      "torch.Size([1, 2790, 1024])\n",
      "torch.Size([1, 2132, 1024])\n",
      "torch.Size([1, 3130, 1024])\n",
      "torch.Size([1, 1692, 1024])\n",
      "torch.Size([1, 1616, 1024])\n",
      "torch.Size([1, 3161, 1024])\n",
      "torch.Size([1, 6192, 1024])\n",
      "torch.Size([1, 1542, 1024])\n",
      "torch.Size([1, 1673, 1024])\n",
      "torch.Size([1, 3446, 1024])\n",
      "torch.Size([1, 3450, 1024])\n",
      "torch.Size([1, 5371, 1024])\n",
      "torch.Size([1, 2934, 1024])\n",
      "torch.Size([1, 1782, 1024])\n",
      "torch.Size([1, 1893, 1024])\n",
      "torch.Size([1, 6466, 1024])\n",
      "torch.Size([1, 1587, 1024])\n",
      "torch.Size([1, 6781, 1024])\n",
      "torch.Size([1, 2566, 1024])\n",
      "torch.Size([1, 1675, 1024])\n",
      "torch.Size([1, 2979, 1024])\n",
      "torch.Size([1, 2039, 1024])\n",
      "torch.Size([1, 1442, 1024])\n",
      "torch.Size([1, 3526, 1024])\n",
      "torch.Size([1, 2907, 1024])\n",
      "torch.Size([1, 6121, 1024])\n",
      "torch.Size([1, 1739, 1024])\n",
      "torch.Size([1, 3718, 1024])\n",
      "torch.Size([1, 6194, 1024])\n",
      "torch.Size([1, 1811, 1024])\n",
      "torch.Size([1, 4292, 1024])\n",
      "torch.Size([1, 1504, 1024])\n",
      "torch.Size([1, 2810, 1024])\n",
      "torch.Size([1, 3157, 1024])\n",
      "torch.Size([1, 3367, 1024])\n",
      "torch.Size([1, 3361, 1024])\n",
      "torch.Size([1, 1806, 1024])\n",
      "torch.Size([1, 4370, 1024])\n",
      "torch.Size([1, 4424, 1024])\n",
      "torch.Size([1, 1549, 1024])\n",
      "torch.Size([1, 2255, 1024])\n",
      "torch.Size([1, 2473, 1024])\n",
      "torch.Size([1, 2026, 1024])\n",
      "torch.Size([1, 1688, 1024])\n",
      "torch.Size([1, 3540, 1024])\n",
      "torch.Size([1, 2362, 1024])\n",
      "torch.Size([1, 1350, 1024])\n",
      "torch.Size([1, 2568, 1024])\n",
      "torch.Size([1, 2061, 1024])\n",
      "torch.Size([1, 1768, 1024])\n",
      "torch.Size([1, 1708, 1024])\n",
      "torch.Size([1, 1930, 1024])\n",
      "torch.Size([1, 1287, 1024])\n",
      "torch.Size([1, 3103, 1024])\n",
      "torch.Size([1, 3174, 1024])\n",
      "torch.Size([1, 1942, 1024])\n",
      "torch.Size([1, 2443, 1024])\n",
      "torch.Size([1, 5190, 1024])\n",
      "torch.Size([1, 3225, 1024])\n",
      "torch.Size([1, 2214, 1024])\n",
      "torch.Size([1, 2539, 1024])\n",
      "torch.Size([1, 2766, 1024])\n",
      "torch.Size([1, 1795, 1024])\n",
      "torch.Size([1, 5982, 1024])\n",
      "torch.Size([1, 1536, 1024])\n",
      "torch.Size([1, 3735, 1024])\n",
      "torch.Size([1, 1692, 1024])\n",
      "torch.Size([1, 3341, 1024])\n",
      "torch.Size([1, 2405, 1024])\n",
      "torch.Size([1, 2856, 1024])\n",
      "torch.Size([1, 1285, 1024])\n",
      "torch.Size([1, 1643, 1024])\n",
      "torch.Size([1, 1680, 1024])\n",
      "torch.Size([1, 2109, 1024])\n",
      "torch.Size([1, 1854, 1024])\n",
      "torch.Size([1, 2379, 1024])\n",
      "torch.Size([1, 4214, 1024])\n",
      "torch.Size([1, 3344, 1024])\n",
      "torch.Size([1, 1497, 1024])\n",
      "torch.Size([1, 2715, 1024])\n",
      "torch.Size([1, 1409, 1024])\n",
      "torch.Size([1, 1047, 1024])\n",
      "torch.Size([1, 2430, 1024])\n",
      "torch.Size([1, 1949, 1024])\n",
      "torch.Size([1, 1912, 1024])\n",
      "torch.Size([1, 977, 1024])\n",
      "torch.Size([1, 2462, 1024])\n",
      "torch.Size([1, 6864, 1024])\n",
      "torch.Size([1, 2481, 1024])\n",
      "torch.Size([1, 2520, 1024])\n",
      "torch.Size([1, 1709, 1024])\n",
      "torch.Size([1, 1628, 1024])\n",
      "torch.Size([1, 1837, 1024])\n",
      "torch.Size([1, 1748, 1024])\n",
      "torch.Size([1, 5702, 1024])\n",
      "torch.Size([1, 1373, 1024])\n",
      "torch.Size([1, 3078, 1024])\n",
      "torch.Size([1, 6028, 1024])\n",
      "torch.Size([1, 661, 1024])\n",
      "torch.Size([1, 4169, 1024])\n",
      "torch.Size([1, 1429, 1024])\n",
      "torch.Size([1, 1076, 1024])\n",
      "torch.Size([1, 1659, 1024])\n",
      "torch.Size([1, 2102, 1024])\n",
      "torch.Size([1, 2095, 1024])\n",
      "torch.Size([1, 3573, 1024])\n",
      "torch.Size([1, 3122, 1024])\n",
      "torch.Size([1, 2610, 1024])\n",
      "torch.Size([1, 1864, 1024])\n",
      "torch.Size([1, 2144, 1024])\n",
      "torch.Size([1, 4473, 1024])\n",
      "torch.Size([1, 1933, 1024])\n",
      "torch.Size([1, 2579, 1024])\n",
      "torch.Size([1, 1787, 1024])\n",
      "torch.Size([1, 1683, 1024])\n",
      "torch.Size([1, 1418, 1024])\n",
      "torch.Size([1, 2121, 1024])\n",
      "torch.Size([1, 3726, 1024])\n",
      "torch.Size([1, 2061, 1024])\n",
      "torch.Size([1, 1492, 1024])\n",
      "torch.Size([1, 6304, 1024])\n",
      "torch.Size([1, 2396, 1024])\n",
      "torch.Size([1, 1324, 1024])\n",
      "torch.Size([1, 2381, 1024])\n",
      "torch.Size([1, 2223, 1024])\n",
      "torch.Size([1, 1317, 1024])\n",
      "torch.Size([1, 3989, 1024])\n",
      "torch.Size([1, 2465, 1024])\n",
      "torch.Size([1, 2327, 1024])\n",
      "torch.Size([1, 2518, 1024])\n",
      "torch.Size([1, 1952, 1024])\n",
      "torch.Size([1, 1183, 1024])\n",
      "torch.Size([1, 3720, 1024])\n",
      "torch.Size([1, 3575, 1024])\n",
      "torch.Size([1, 4909, 1024])\n",
      "torch.Size([1, 3908, 1024])\n",
      "torch.Size([1, 2140, 1024])\n",
      "torch.Size([1, 2184, 1024])\n",
      "torch.Size([1, 3348, 1024])\n",
      "torch.Size([1, 4766, 1024])\n",
      "torch.Size([1, 2130, 1024])\n",
      "torch.Size([1, 1991, 1024])\n",
      "torch.Size([1, 1987, 1024])\n",
      "torch.Size([1, 2624, 1024])\n",
      "torch.Size([1, 5518, 1024])\n",
      "torch.Size([1, 1508, 1024])\n",
      "torch.Size([1, 6395, 1024])\n",
      "torch.Size([1, 2358, 1024])\n",
      "torch.Size([1, 3066, 1024])\n",
      "torch.Size([1, 2321, 1024])\n",
      "torch.Size([1, 1614, 1024])\n",
      "torch.Size([1, 2482, 1024])\n",
      "torch.Size([1, 2326, 1024])\n",
      "torch.Size([1, 4125, 1024])\n",
      "torch.Size([1, 1893, 1024])\n",
      "torch.Size([1, 1970, 1024])\n",
      "torch.Size([1, 1953, 1024])\n",
      "torch.Size([1, 2443, 1024])\n",
      "torch.Size([1, 2176, 1024])\n",
      "torch.Size([1, 4320, 1024])\n",
      "torch.Size([1, 857, 1024])\n",
      "torch.Size([1, 1019, 1024])\n",
      "torch.Size([1, 1849, 1024])\n",
      "torch.Size([1, 5798, 1024])\n",
      "torch.Size([1, 3383, 1024])\n",
      "torch.Size([1, 3293, 1024])\n",
      "torch.Size([1, 1628, 1024])\n",
      "torch.Size([1, 2722, 1024])\n",
      "torch.Size([1, 1440, 1024])\n",
      "torch.Size([1, 2341, 1024])\n",
      "torch.Size([1, 1530, 1024])\n",
      "torch.Size([1, 929, 1024])\n",
      "torch.Size([1, 1485, 1024])\n",
      "torch.Size([1, 2959, 1024])\n",
      "torch.Size([1, 2210, 1024])\n",
      "torch.Size([1, 2100, 1024])\n",
      "torch.Size([1, 1064, 1024])\n",
      "torch.Size([1, 1234, 1024])\n",
      "torch.Size([1, 3105, 1024])\n",
      "torch.Size([1, 2708, 1024])\n",
      "torch.Size([1, 5049, 1024])\n",
      "torch.Size([1, 2251, 1024])\n",
      "torch.Size([1, 1826, 1024])\n",
      "torch.Size([1, 1614, 1024])\n",
      "torch.Size([1, 5623, 1024])\n",
      "torch.Size([1, 2640, 1024])\n",
      "torch.Size([1, 3085, 1024])\n",
      "torch.Size([1, 5902, 1024])\n",
      "torch.Size([1, 1873, 1024])\n",
      "torch.Size([1, 2342, 1024])\n",
      "torch.Size([1, 6880, 1024])\n",
      "torch.Size([1, 2507, 1024])\n",
      "torch.Size([1, 1704, 1024])\n",
      "torch.Size([1, 3310, 1024])\n",
      "torch.Size([1, 2098, 1024])\n",
      "torch.Size([1, 3312, 1024])\n",
      "torch.Size([1, 4090, 1024])\n",
      "torch.Size([1, 1084, 1024])\n",
      "torch.Size([1, 3323, 1024])\n",
      "torch.Size([1, 366, 1024])\n",
      "torch.Size([1, 3067, 1024])\n",
      "torch.Size([1, 530, 1024])\n",
      "torch.Size([1, 4591, 1024])\n",
      "torch.Size([1, 2430, 1024])\n",
      "torch.Size([1, 1448, 1024])\n",
      "torch.Size([1, 1334, 1024])\n",
      "torch.Size([1, 733, 1024])\n",
      "torch.Size([1, 1321, 1024])\n",
      "torch.Size([1, 1652, 1024])\n",
      "torch.Size([1, 1938, 1024])\n",
      "torch.Size([1, 1765, 1024])\n",
      "torch.Size([1, 2713, 1024])\n",
      "torch.Size([1, 1926, 1024])\n",
      "torch.Size([1, 2272, 1024])\n",
      "torch.Size([1, 2897, 1024])\n",
      "torch.Size([1, 3205, 1024])\n",
      "torch.Size([1, 2432, 1024])\n"
     ]
    }
   ],
   "source": [
    "for lst in emb_list:\n",
    "    print(lst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 1758, 1024] at entry 0 and [1, 4477, 1024] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stacked_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStacked embeddings shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacked_embeddings\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 1758, 1024] at entry 0 and [1, 4477, 1024] at entry 1"
     ]
    }
   ],
   "source": [
    "stacked_embeddings = torch.stack(emb_list, dim=0)\n",
    "print(\"Stacked embeddings shape:\", stacked_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(stacked_embeddings, 'emb_47_per_gene.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'concatenate_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconcatenate_embeddings\u001b[49m(emb_list)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'concatenate_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "concatenate_embeddings(emb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1758, 1024])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_cell = prepare_cell(cell, \"mlm\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,  36, 211,  ..., 259, 262,   1]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_cell[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  0,  36, 211,  ..., 259, 262,   1]]),\n",
       " 'token_type_ids': tensor([[    0,     1,     4,  ..., 58604, 58607,     0]]),\n",
       " 'attention_mask': tensor([[True, True, True,  ..., True, True, True]])}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_cell = data_collator([prepared_cell])\n",
    "batched_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prepared_cell \u001b[38;5;241m=\u001b[39m prepare_cell(cell, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlm\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer)\n\u001b[0;32m----> 2\u001b[0m latent_space \u001b[38;5;241m=\u001b[39m \u001b[43mget_latent_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepared_cell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatent space representation:\u001b[39m\u001b[38;5;124m\"\u001b[39m, latent_space\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[37], line 5\u001b[0m, in \u001b[0;36mget_latent_space\u001b[0;34m(prepared_cell, model)\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 5\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_cell\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_cell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoken_type_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_cell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# outputs.last_hidden_state contains the latent space representations\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/perturbgene/model.py:134\u001b[0m, in \u001b[0;36mGeneBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, token_type_ids)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(input_shape, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# (bs, seq_length)\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:571\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    563\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    564\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    565\u001b[0m         hidden_state,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m         output_attentions,\n\u001b[1;32m    569\u001b[0m     )\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 571\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:497\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;124;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    506\u001b[0m     sa_output, sa_weights \u001b[38;5;241m=\u001b[39m sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:205\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    187\u001b[0m     query: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m     output_attentions: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    193\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[1;32m    194\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    Parameters:\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m        query: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m        seq_length, dim) Contextualized layer. Optional: only if `output_attentions=True`\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     bs, q_length, dim \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    206\u001b[0m     k_length \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# assert dim == self.dim, f'Dimensions do not match: {dim} input vs {self.dim} configured'\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# assert key.size() == value.size()\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "prepared_cell = prepare_cell(cell, \"mlm\", tokenizer)\n",
    "batched_cell = data_collator([prepared_cell])\n",
    "latent_space = get_latent_space(prepared_cell, model)\n",
    "print(\"Latent space representation:\", latent_space.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
